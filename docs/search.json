[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GradAB R Intro 2024",
    "section": "",
    "text": "Welcome!\nIntroduction to R for GradAB and IAB people.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#course-dates",
    "href": "index.html#course-dates",
    "title": "GradAB R Intro 2024",
    "section": "Course dates",
    "text": "Course dates\n\n   E09\n   11.09.2024      10:45 – 16:00\n   13.09.2024      8:30 – 15:30",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Getting started with R",
    "section": "",
    "text": "1.1 Installing and Setting Up R & RStudio\nR is a completely free program that you can download from CRAN. The RStudio extension is also free and can be downloaded here. RStudio enhances R by providing a significantly more informative and appealing interface, help, and auto-completion when writing syntax, as well as an overall improved user interface. However, RStudio is an extension of R, so you need both programs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#installing-and-setting-up-r-rstudio",
    "href": "01_intro.html#installing-and-setting-up-r-rstudio",
    "title": "1  Getting started with R",
    "section": "",
    "text": "Install R first and then RStudio, so that RStudio recognizes the installed R version, and the two programs usually connect automatically. R is essentially the engine, and RStudio is our cockpit. We could work directly with R, but RStudio offers a more comfortable option and a better overview.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.1: R and RStudio",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#setting-up-rstudio",
    "href": "01_intro.html#setting-up-rstudio",
    "title": "1  Getting started with R",
    "section": "1.2 Setting Up RStudio",
    "text": "1.2 Setting Up RStudio\nAfter successful installation, open the RStudio application  and you should see the following view:\n\nTo avoid problems when working with R in the future, please disable the automatic saving and loading of the workspace. To do this, go to the appropriate menu under the “Tools -&gt; Global options” tab, disable “Restore .RData into workspace at startup,” and set “Save workspace to .RData on exit:” to Never. Otherwise, RStudio will save all loaded objects when you end the session and automatically load them the next time you open the program, which can lead to problems.\n\nConfirm the settings with “Apply” and close the window with “OK.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#first-steps-in-r",
    "href": "01_intro.html#first-steps-in-r",
    "title": "1  Getting started with R",
    "section": "1.3 First Steps in R",
    "text": "1.3 First Steps in R\nAfter these basic settings, we can start with the first steps in R. To do this, first open a script by clicking on the white icon in the top left corner or pressing CTRL/Command + Shift + N simultaneously.\n\nA fourth window opens, so you should now see the following view:\n\nThis script editor is where we will create and execute commands. The script editor serves as a collection of all commands to be executed. We can save these collections to revisit them later, and, more importantly, we can share command collections with others or use scripts from others for ourselves. So, we first draft a calculation in the script editor:\n\nTo execute it, click on the line to be executed so that the cursor is in that line, and then press CTRL and Enter simultaneously (Mac users: Command and Enter):\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Shortcuts for Calculations\n\n\n\nR outputs the results in the console below:\n\nThis also works for multiple calculations at once by selecting multiple lines and then pressing CTRL and Enter again (Mac users: Command and Enter):\n\nInputs from the script editor and results from the console will be presented like this in the future:\n\n2+5\n\n[1] 7\n\n3-4\n\n[1] -1\n\n5*6\n\n[1] 30\n\n7/8\n\n[1] 0.875\n\n\nOf course, R also handles longer calculations, such as following the order of operations:\n\n2+3*2\n\n[1] 8\n\n(2+3)*2\n\n[1] 10\n\n\nOther operations are also possible:\n\n4^2 ## 4²\nsqrt(4) ## Square root \nexp(1) ## Exponential function (Euler's number)\nlog(5) ## Natural logarithm\nlog(exp(5)) ## log and exp cancel each other out\n\nWe can create sequences of numbers using seq() or ::\n\n2:6\n\n[1] 2 3 4 5 6\n\nseq(2,11,3)\n\n[1]  2  5  8 11\n\n\n\n1.3.1 Creating Objects\nSo far, we have always displayed our calculations directly. For more extensive calculations—since we want to work with datasets starting in the next chapter—we want to save the intermediate steps.\nResults can be saved as objects under any name using &lt;-. R will then not display the result but will repeat the command in the console:\n\nx &lt;- 4/2\n\nIn the “Environment” window at the top right, you can now see the stored object x:\n\nWe can retrieve it later:\n\nx\n\n[1] 2\n\n\nAdditionally, we can use objects in calculations—we simply use x and create, for example, y:\n\ny &lt;- x * 5\ny\n\n[1] 10\n\n\n\n\n\n1.3.2 Storing Multiple Values\nWith c(), we can store multiple values under one object, and these can also be used in calculations:\n\nx1 &lt;- c(1,2,3)\nx1\n\n[1] 1 2 3\n\nx1* 2\n\n[1] 2 4 6\n\n\nWith length(), we can check the number of stored values:\n\nlength(x1)\n\n[1] 3\n\n\n\ny1 &lt;- c(10,11,9)\ny1\n\n[1] 10 11  9\n\ny1/x1\n\n[1] 10.0  5.5  3.0\n\n\n\n\n1.3.3 Deleting Values\nOf course, we can also delete objects using rm(). If we try to call a non-existent object, we will get an error message:\n\nrm(x1)\nx1\n\nError in eval(expr, envir, enclos): Objekt 'x1' nicht gefunden\n\n\nWith rm(list = ls()), all objects can be removed from the environment.\n\n\n1.3.4 Saving Scripts\nWe can save the script to call it again later.\n\nIt is important to give the saved file the extension “.R”, for example, “01_Script.R”.\n\n\n1.3.5 Comments\nBesides the actual commands, comments are a central part of a data analysis syntax. This allows future users (especially ourselves in 3 weeks or 2 years) to understand what is happening. Comments in R can be added with #:\n\n2+ 5 # this is a comment\n\n[1] 7\n\n2+ # a comment can also be placed here\n  5\n\n[1] 7\n\n\n\n( 2 + # a \n    3) * # comment\n  2 # across multiple lines\n\n[1] 10\n\n\nTip: It’s best to create a folder right away where you can store all R scripts and datasets from this course.\n\n\n1.3.6 Structuring Scripts\n\n# Heading 1 ----\n\n## Section 1.1 ----\n3+2*4\n3+2*3\n## Section 1.2 ----\n3+2*sqrt(3)\n\n# Heading 2 ----\nx &lt;- c(2,6,8,2,35)\ny &lt;- seq(2,10,2)\n\ny/x",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#exercises",
    "href": "01_intro.html#exercises",
    "title": "1  Getting started with R",
    "section": "1.4 Exercises",
    "text": "1.4 Exercises\n\nCreate a sequence of numbers from 7 to 13. How can you adjust the sequence with seq() so that only the odd numbers are generated?\nStore the number of students at the University of Oldenburg (15643) in stud.\nStore the number of professorships at the University of Oldenburg (210) in prof.\nCalculate the number of students per professorship at the University of Oldenburg using the objects stud and prof.\nStore the result in studprof and recall the object again!\nDo you see the created variables in the Environment window?\nStore the student numbers of the University of Bremen (19173), University of Vechta (5333), and University of Oldenburg (15643) together in studs.\nStore the number of professors at the University of Bremen (322), University of Vechta (67), and University of Oldenburg (210) together in profs.\nCalculate the number of students per professorship for all three universities.\nYou also want to include the student numbers (14000) and professorships (217) of the University of Osnabrück in studs and profs. How would you do that?\nCalculate the ratio of students to professorships for all four universities!\nDelete the object stud. How can you tell that it worked?\nDelete all objects from the Environment. How can you tell that it worked?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "02_intro.html",
    "href": "02_intro.html",
    "title": "2  Working with Datasets",
    "section": "",
    "text": "2.1 Data Structures in R: data.frame\nIn the previous chapter, we combined the student numbers of the University of Bremen (19173), University of Vechta (5333), and University of Oldenburg (15643) under studs and related them to the professor numbers stored in profs. While this works fine, it is more organized to store related values together. For this, R provides the data.frame. We can store the two objects in a dataset by entering them into data.frame and storing the new object under dat1. When we call dat1, we see that the values have been combined row by row:\nstuds &lt;- c(19173, 5333, 15643)  # Store student numbers under \"studs\"\nprofs &lt;- c(322, 67, 210)        # Store professor numbers under \"profs\"\ndat1_orig &lt;- data.frame(studs, profs)\ndat1_orig\n\n  studs profs\n1 19173   322\n2  5333    67\n3 15643   210\ndat1 &lt;- data.frame(studs = c(19173, 5333, 15643), \n                   profs = c(322, 67, 210),\n                   gegr  = c(1971, 1830, 1973)) # Without intermediate objects\ndat1    # Display the entire dataset\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\nIn the first row, we see the values for the University of Bremen, in the second row for the University of Vechta, and so on. We can access the columns using dataset_name$variable_name. For example, we can display the profs column:\ndat1$profs \n\n[1] 322  67 210\nWe can display the variable/column names of the dataset with colnames()/names(). Additionally, we can call the number of rows and columns using nrow and ncol:\ncolnames(dat1) ## Display variable/column names\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nnames(dat1) ## Display variable/column names\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nncol(dat1) ## Number of columns/variables\n\n[1] 3\n\nnrow(dat1) ## Number of rows/cases\n\n[1] 3\nWe can add new variables to the dataset by using dataset_name$new_variable:\ndat1$stu_prof &lt;- dat1$studs/dat1$profs\n## dat1 now has one more column:\nncol(dat1) \n\n[1] 4\n\ndat1\n\n  studs profs gegr stu_prof\n1 19173   322 1971 59.54348\n2  5333    67 1830 79.59701\n3 15643   210 1973 74.49048\nWe can also store one or more words in a variable, but letters/words must always be enclosed in \"\".\ndat1$uni &lt;- c(\"Uni Bremen\", \"Uni Vechta\", \"Uni Oldenburg\")\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\nWith View(dat1), a new window opens where we can view the entire dataset:\nView(dat1)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#data-types-in-r",
    "href": "02_intro.html#data-types-in-r",
    "title": "2  Working with Datasets",
    "section": "2.2 Data Types in R",
    "text": "2.2 Data Types in R\nSo far, we have encountered two variable types: numeric (contains numbers) and character (contains text or numbers that are understood as text). We also learned an organization method: data.frame.\nThe following variable types in R are important for us:2\n\n\n\n\n\n\n\n\n\n\n\n\nVectors (Variables)\n\n\n\n\ninteger  double\nNumeric values (numeric)\n\n\ncharacter\nText (or numbers understood as text)\n\n\nfactor\nText or numbers understood as text with predefined sorting and fixed value universe\n\n\nlogical\nTRUE or FALSE—mostly the result of a comparison (greater/less/equal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombined Vectors\n\n\n\n\ndata.frame  tibble\nTwo-dimensional data structure organized in tabular form—tibble is an enhancement of data.frame in the tidyverse (more on this later)\n\n\nlist\nOrdered collection of vectors of different types—can contain other value types, data.frame, or even other lists\n\n\n\n\n\n\n\nFor now, we focus on character and numeric variables. We will discuss the other types when they are needed. With class(), we can examine the type of a variable, or with is.numeric() or is.character(), we can check whether a variable belongs to a certain type:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\nclass(dat1$uni)\n\n[1] \"character\"\n\nis.numeric(dat1$profs)\n\n[1] TRUE\n\nis.character(dat1$profs)\n\n[1] FALSE\n\n\nWe can enforce a type change with as.character() or as.numeric():\n\nas.character(dat1$profs) ## The \"\" indicate that the variable is defined as character\n\n[1] \"322\" \"67\"  \"210\"\n\n\nThis does not change the original variable dat1$profs:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\n\nIf we want to keep this conversion for dat1$profs, we need to overwrite the variable:\n\ndat1$profs &lt;- as.character(dat1$profs)\ndat1$profs \n\n[1] \"322\" \"67\"  \"210\"\n\nclass(dat1$profs)\n\n[1] \"character\"\n\n\nWe cannot perform calculations with character variables, even if they contain numbers:\n\ndat1$profs / 2 \n\nError in dat1$profs/2: nicht-numerisches Argument für binären Operator\n\n\nHowever, we can convert dat1$profs to numeric on the fly to perform calculations:\n\nas.numeric(dat1$profs)\n\n[1] 322  67 210\n\nas.numeric(dat1$profs) / 2\n\n[1] 161.0  33.5 105.0\n\n\nIf we convert text variables to numeric, calculations result in NA. NA in R stands for missing values:\n\nas.numeric(dat1$uni)\n\nWarning: NAs durch Umwandlung erzeugt\n\n\n[1] NA NA NA\n\n\nR, understandably, does not know how to convert university names into numbers.\n\n\n\n\n\n\nA common issue in calculations is due to incorrect variable types.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#selecting-rows-columns",
    "href": "02_intro.html#selecting-rows-columns",
    "title": "2  Working with Datasets",
    "section": "2.3 Selecting Rows & Columns",
    "text": "2.3 Selecting Rows & Columns\nA typical task when working with datasets is selecting rows (“cases”) and columns (“variables”).\nFor this, R in its base version3 provides a selection method using []. The basic structure is [row_selection, column_selection]. Leaving out the part before or after the comma selects all rows/columns. Be careful: forgetting the comma is a common source of errors in R.\n\ndat1 # complete dataset\ndat1[1,1] # first row, first column\ndat1[1,]  # first row, all columns\ndat1[,1]  # all rows, first column (equivalent to dat1$studs)\ndat1[,\"studs\"] # all rows, column named studs -&gt; note: \"\"\n\nIn these square brackets, you can also write conditions to make selections from dat1.\n\ndat1[dat1$studs &gt; 10000, ] # rows where studs is greater than 10000, all columns\ndat1[dat1$studs &gt; 10000 & dat1$profs &lt; 300, ] # & means AND\ndat1$profs[dat1$studs &gt; 10000] # Only see the number of professors: no comma\n\n\n2.3.1 Exercise\nRepetitive use of the dataset name in the [] makes the syntax quite long and somewhat tedious. Therefore, there is a better/more convenient solution. We use the {dplyr} package4.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#packages",
    "href": "02_intro.html#packages",
    "title": "2  Working with Datasets",
    "section": "2.4 Packages in R",
    "text": "2.4 Packages in R\nPackages are extensions for R that include additional functions.  Packages need to be installed once and then loaded before use in a new session (i.e., after every restart of R/RStudio). install.packages() performs the installation, and library() loads the packages:\n\ninstall.packages(\"Package\") # only needed once on your PC\nlibrary(Package) # needed after every restart\n\nOften, when using install.packages(), not only the specified package is downloaded but also a number of other packages, the so-called “dependencies”. These are packages used in the background to enable the functions of the desired package. So don’t be surprised if the installation takes a bit longer.\nWith install.packages() we essentially screw in the light bulb in R, with library() we flip the switch so we can use the functions from the package. Each restart turns the light bulb off again, and we need to turn it back on with library(). The advantage is that we don’t have to turn on all the light bulbs at once when starting R.\n\n\n\n\n\nSource: Dianne Cook\n\n\n\n\n\n\n\n\n\n\ninstall.packages() in the IAB Network\n\n\n\nPackages in R are typically installed from CRAN. This is not possible on the servers at IAB due to isolation from the internet. This restricts package installation in R to the collection maintained by DIM under N:/Ablagen/D01700-Allgemein/R/bin/windows/contrib/.\nA central challenge in installing from local zip files is handling dependencies: packages that the desired package relies on. When installing from the internet, dependencies are automatically installed, but with a local installation, this is not the case.\nAt IAB, some workarounds exist, and currently, I have a solution in progress at FDZ based on a .Rprofile file that provides the fdz_install() command, which behaves like the standard install.packages() command (or should, at least).\nThe most recent version of the .Rprofile file can be found under N:\\Ablagen\\D01700-Quickablage\\Filser\\R_2024\\prog.\nPlace the .Rprofile file in C:\\Users\\*YOUR_USERNAME*\\Documents and restart R (CTRL + F10), you should then see a similar message in the console:\n\n----------------------------------------\nIAB-FDZ .Rprofile\nVersion 0.5\n----------------------------------------\n- Local repository: N:/Ablagen/D01700-Allgemein/R/bin/windows/contrib/4.2\n- Working directory: N:/Ablagen/D01700-FDZ/Quickablage/AndreasF/R-Kurs\n \n- Default package library: C:/Users/FilserA001.IAB/AppData/Local/R/win-library/4.2\n- HOME directory: C:/Users/FilserA001.IAB/Documents\n- R_home directory: C:/PROGRA~1/R/R-4.2.1\n----------------------------------------\n\nMore about RProfile\n\n\n\n\n\n\n\n\nLoading packages once\n\n\n\n\n\nIn addition to library(), you can also call functions from packages using :::\n\npackage::function()\n\nThis option is often used when only one function from a package is used or to clarify which package the function comes from. It can also help with issues if a command from another package has the same name—this will override the previous command (usually with a warning), which might look like:\n\nThe following objects are masked from ‘package:dplyr’:\n\n    between, first, last\n\nThe following object is masked from ‘package:purrr’:\n\n    transpose\n\nThis can be avoided by not fully loading certain packages but only calling the necessary functions with ::.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#tidyverse",
    "href": "02_intro.html#tidyverse",
    "title": "2  Working with Datasets",
    "section": "2.5 {tidyverse}",
    "text": "2.5 {tidyverse}\nIn this course, we will mainly work with packages from the {tidyverse}. The tidyverse is a collection of packages that share common syntax logic and thus harmonize particularly well and cover a broad range of use cases. With\n\ninstall.packages(\"tidyverse\")\nfdz_install(\"tidyverse\") # on IAB servers with .Rprofile\n\nthe following packages are installed:\nbroom, conflicted, cli, dbplyr, dplyr, dtplyr, forcats, ggplot2, googledrive, googlesheets4, haven, hms, httr, jsonlite, lubridate, magrittr, modelr, pillar, purrr, ragg, readr, readxl, reprex, rlang, rstudioapi, rvest, stringr, tibble, tidyr, xml2, tidyverse\nWe will get to know some of them during the course. The initially most important one is {dplyr}, which makes selecting cases and variables easier:\n\n\n\n\n\nIllustration based on the {dplyr} Cheatsheet\n\n\n\n\nBut installation is only the first step; we need to load the package with library():\n\nlibrary(tidyverse) # after once using install.packages(\"tidyverse\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#selecting-rows-with-slice",
    "href": "02_intro.html#selecting-rows-with-slice",
    "title": "2  Working with Datasets",
    "section": "2.6 Selecting Rows with slice()",
    "text": "2.6 Selecting Rows with slice()\nA first function from {tidyverse} is slice(), which allows us to select rows:\n\nslice(dat1,1) # first row\nslice(dat1,2:3) # rows 2-3\nslice(dat1,c(1,3)) # rows 1 and 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#filter",
    "href": "02_intro.html#filter",
    "title": "2  Working with Datasets",
    "section": "2.7 Selecting Observations with filter()",
    "text": "2.7 Selecting Observations with filter()\nWith filter(), we can select rows from dat1 based on conditions:\n\nfilter(dat1,uni == \"Uni Oldenburg\", studs &gt; 1000)\n\n  studs profs gegr stu_prof           uni\n1 15643   210 1973 74.49048 Uni Oldenburg\n\n\nThe selection does not change the original object dat1:\n\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\nIf we want to keep the result of our selection with filter() for further steps, we can store it in a new data.frame object:\n\nover_10k &lt;- filter(dat1, studs &gt; 10000)\nover_10k\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n\n\n\n2.7.1 filter() helpers\n{dplyr} provides a number of helpers for filter():\n\ngreater/smaller than or equal to: &lt;= &gt;=\nor: |\none of: %in%\nwithin a given range: between()\n\n\nfilter(dat1, studs &gt;= 10000)\nfilter(dat1, studs &lt;= 10000)\nfilter(dat1,studs &gt; 10000 | profs &lt; 200) # more than 10.000 Students *or* less than 200 professors\nfilter(dat1, gegr %in% c(1971,1830)) # founded 1971 or 1830\nfilter(dat1, between(gegr,1971,1830)) # founded between 1971 and 1830 (including)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#select",
    "href": "02_intro.html#select",
    "title": "2  Working with Datasets",
    "section": "2.8 Selecting variables with select()",
    "text": "2.8 Selecting variables with select()\nselect() allows us to select specific columns:\n\nselect(dat1,uni,studs) # columns uni and studs\n\n            uni studs\n1    Uni Bremen 19173\n2    Uni Vechta  5333\n3 Uni Oldenburg 15643\n\n\n\nselect(dat1, 1:3) # column 1-3\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\n\nselect(dat1, !profs) # all but profs\n\n  studs gegr stu_prof           uni\n1 19173 1971 59.54348    Uni Bremen\n2  5333 1830 79.59701    Uni Vechta\n3 15643 1973 74.49048 Uni Oldenburg\n\n\nWe can also select columns by name or position and reorder them:\n\nselect(dat1,uni,studs,profs) # columns in a specific order\n\n            uni studs profs\n1    Uni Bremen 19173   322\n2    Uni Vechta  5333    67\n3 Uni Oldenburg 15643   210\n\nselect(dat1,-studs) # all columns except for \"studs\"\n\n  profs gegr stu_prof           uni\n1   322 1971 59.54348    Uni Bremen\n2    67 1830 79.59701    Uni Vechta\n3   210 1973 74.49048 Uni Oldenburg",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#pipe",
    "href": "02_intro.html#pipe",
    "title": "2  Working with Datasets",
    "section": "2.9 Chaining Commands with %>%",
    "text": "2.9 Chaining Commands with %&gt;%\nIn R, dplyr and other {tidyverse} packages use %&gt;% (the pipe operator) to chain commands. This is a way to streamline commands and improve readability:\n\ndat1 %&gt;%\n  filter(studs &gt; 10000) %&gt;%\n  select(uni,studs)\n\n            uni studs\n1    Uni Bremen 19173\n2 Uni Oldenburg 15643\n\n\nHere, %&gt;% takes the output of one function and passes it as an input to the next function. This operator allows you to read and write code that closely resembles natural language.\nIf we want to select some rows and some columns, we can combine filter() and select():\n\nselect(filter(dat1, studs &lt; 10000), uni)\n\n         uni\n1 Uni Vechta\n\n\nWe can simplify this command chain using the so-called pipe %&gt;%. %&gt;% simply stands for “and then”. The pipe comes from the {magrittr} package, which is part of the tidyverse and is automatically loaded with {dplyr}.\n\ndat1 %&gt;% filter(.,studs &lt; 10000) %&gt;% select(.,uni) # the dot represents the result of the previous step\n\n         uni\n1 Uni Vechta\n\ndat1 %&gt;% filter(studs &lt; 10000) %&gt;% select(uni)\n\n         uni\n1 Uni Vechta\n\n\n\nCall dat1 and then (%&gt;%)\nSelect only rows where studs &lt; 10000 and then (%&gt;%)\nKeep only the uni column\n\n\n\n\n\n\n\nThe shortcut for %&gt;% is STRG+SHIFT+m (cmd+shift+m on Mac)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#variable-type-factor",
    "href": "02_intro.html#variable-type-factor",
    "title": "2  Working with Datasets",
    "section": "2.10 Variable type factor",
    "text": "2.10 Variable type factor\nAnother common task in data analysis is sorting datasets. For this, we use arrange():\n\ndat1 %&gt;% arrange(studs)\n\n  studs profs gegr stu_prof           uni\n1  5333    67 1830 79.59701    Uni Vechta\n2 15643   210 1973 74.49048 Uni Oldenburg\n3 19173   322 1971 59.54348    Uni Bremen\n\n\nThis also works for string variables:\n\ndat1 %&gt;% arrange(uni)\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n3  5333    67 1830 79.59701    Uni Vechta\n\n\nBut what if we want to assign a specific order that doesn’t follow numeric or alphabetical order? For example, if we want to order the universities as follows: 1) Uni Oldenburg, 2) Uni Bremen, and 3) Uni Vechta.\nThis is where a third variable type comes in: factor.\nWith the levels = argument, we can define an order:\n\nfactor(dat1$uni, levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\n[1] Uni Bremen    Uni Vechta    Uni Oldenburg\nLevels: Uni Oldenburg Uni Bremen Uni Vechta\n\ndat1$uni_fct &lt;- factor(dat1$uni, \n                       levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\nIf we now sort by uni_fct, the order of the levels is respected:\n\nclass(dat1$uni_fct)\n\n[1] \"factor\"\n\ndat1 %&gt;% arrange(uni_fct)\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n\n\nWith desc(), we can sort in reverse order:\n\ndat1 %&gt;% arrange(desc(uni_fct))\n\n  studs profs gegr stu_prof           uni       uni_fct\n1  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\nThis may seem trivial at the moment but is very useful later for ordering variables in plots or setting the reference category in regression models.\nOf course, we can also sort by multiple variables; we just add more to arrange():\n\ndat1 %&gt;% arrange(desc(uni_fct), gegr, studs)\n\n  studs profs gegr stu_prof           uni       uni_fct\n1  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\n(This doesn’t make much sense in this example.)\n\n2.10.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#rproj",
    "href": "02_intro.html#rproj",
    "title": "2  Working with Datasets",
    "section": "2.11 Setting up a project",
    "text": "2.11 Setting up a project\nIn general, it’s worth setting up projects in RStudio. Projects are .Rproj files  that automatically set the working directory to where they are saved. This simplifies collaborative work: no matter who is working on a project or on which device, the project file ensures all paths are always relative to the project directory. Furthermore, version control via git, e.g., github, and other functions can be set in the project file for all users. Also, the last open scripts remain open, making it easier to work on multiple projects.\n\n\n\n\n\n\n\n\n\nWith getwd(), we can check if it worked:\n\ngetwd()\n\n\n\n[1] \"D:/Courses/R-Course\"\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, we could create an .Rproj project with the following command (here’s an example of calling a package with ::):\n\nrstudioapi::initializeProject(path = \"D:/Courses/R-Course\")\n\nWe can open the project with:\n\nrstudioapi::openProject(path = \"D:/Courses/R-Course\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#import",
    "href": "02_intro.html#import",
    "title": "2  Working with Datasets",
    "section": "2.12 Importing datasets",
    "text": "2.12 Importing datasets\nIn most cases, we’ll use datasets that are already saved in a file and just need to be imported. There are countless ways to do this.\nIn this seminar, we’ll work with the Campus-File of PASS, whose parts are available as Stata files.\nTo import the dataset into R, we need to tell R the file path where the dataset is located. The file path depends on your device’s folder structure; in this case, it would be “D:/Courses/R-Course/”.\nOf course, the file path depends on where you saved the dataset:\n\n\n\n\n\n\n\n\n\nWe need to inform R of this file path.\n\n2.12.1 The import command\nNow we can use the actual import command read.table. For the path, we can just enter the quotation marks after file = and press the Tab key. Then we’ll see all subdirectories and tables in the project folder.5\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\") \n\nThe import process consists of two parts: first, we specify the object name as pend, under which R will store the dataset. After the &lt;- is the actual read_dta() command, which contains several options. First, we specify the exact dataset name, including the file extension.\n\n\n\n\n\n\nR has problems with Windows-style \\ in file paths\n\n\n\n\n\nUnfortunately, Windows systems use \\ in file paths, which causes problems in R. Therefore, file paths must always be specified with / or alternatively with \\\\. RStudio can help a bit with the CTRL + F/Search & Replace function.\n\n\n\nThe object created is a data.frame:\n\nclass(pend)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTechnically, it’s a tibble—an enhanced version of data.frame in the tidyverse that includes labels and provides additional information in its display, such as variable classes in the first row.\nIf we were to simply type pend here, the entire dataset would be displayed. For an overview, we can use head:\n\nhead(pend)\n\n# A tibble: 6 × 123\n         pnr      hnr welle   pintjahr pintmon pintmod  zpsex   palter PD0400   \n       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt;\n1 1000001901 10000019 1 [Wel… 2007     5 [Mai]  1 [CAP… 2 [Wei… 36       2 [Ehe…\n2 1000001902 10000019 1 [Wel… 2007     5 [Mai] NA       1 [Mae… 39       2 [Ehe…\n3 1000001901 10000019 3 [Wel… 2009     3 [Mae…  1 [CAP… 2 [Wei… 38      -9 [Ite…\n4 1000002001 10000020 1 [Wel… 2007     4 [Apr…  1 [CAP… 1 [Mae… 66     -10 [Ite…\n5 1000002002 10000020 1 [Wel… 2007     4 [Apr…  1 [CAP… 2 [Wei… 61       3 [Ehe…\n6 1000002002 10000020 2 [Wel… 2008     5 [Mai]  1 [CAP… 2 [Wei… 62       3 [Ehe…\n# ℹ 114 more variables: PA0100 &lt;dbl+lbl&gt;, PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nWith nrow and ncol, we can check if it worked. The dataset should have 28424 rows and 123 columns:\n\nnrow(pend)\n\n[1] 28424\n\nncol(pend)\n\n[1] 123\n\n\nOf course, we can also select rows and columns from this much larger dataset as we did before. For example, we can select the data from 2006 and store it under pend06:\n\npend06 &lt;- pend %&gt;% filter(pintjahr == 2006)\n\nNaturally, pend06 has significantly fewer rows than pend:\n\nnrow(pend06)\n\n[1] 168\n\n\nIf we want to see the exact ages of the respondents from pend06, we can call up the corresponding column with pend06$palter:\n\npend06$palter\n\n&lt;labelled&lt;double&gt;[168]&gt;: Alter (Welle 1: gen. aus P1; ab Welle 2: beste Inf.), generiert\n  [1] 71 66 64 64 63 51 64 65 26 38 41 63 58 58 69 45 59 37 28 63 56 29 29 49 47\n [26] 66 34 22 21 37 36 58 56 80 44 65 61 66 40 53 34 70 69 54 65 62 58 54 51 57\n [51] 72 52 25 34 55 44 68 73 46 87 74 83 46 40 62 58 66 41 53 71 66 79 54 42 68\n [76] 68 81 92 70 66 68 77 44 66 66 67 62 43 35 35 52 54 20 48 48 20 41 24 22 33\n[101] 55 41 50 36 19 52 25 36 37 29 37 36 43 49 16 59 28 19 43 44 30 43 50 50 53\n[126] 52 71 43 58 58 58 38 49 30 27 50 58 26 36 44 28 19 42 44 23 20 33 24 31 32\n[151] 31 44 50 58 45 57 37 62 46 52 50 47 40 62 40 19 28 35\n\nLabels:\n value                                   label\n   -10 Item in Fragebogenversion nicht erhoben\n    -9             Item in Welle nicht erhoben\n    -8                       Unplausibler Wert\n    -4        Frage irrtuemlich nicht gestellt\n    -3                Trifft nicht zu (Filter)\n    -2                            Keine Angabe\n    -1                             Weiss nicht\n\n\nAs we’ve seen, there are many more variables in PASS than just palter, and not all have such meaningful names—like PD0400. To understand these variable names and the meaning of the values, we need the codebook.\nWe can also access a variable’s attributes()—more on labels later.\n\n\n2.12.2 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#exporting-objects",
    "href": "02_intro.html#exporting-objects",
    "title": "2  Working with Datasets",
    "section": "2.13 Exporting objects",
    "text": "2.13 Exporting objects\n\n\n\n\n\n\nThe term save can sometimes lead to misunderstandings in R: does it mean\n\nsaving a dataset or other object to disk as .csv, .dta, .sav for access by other programs, or\nsimply storing the results internally in R under an object name?\n\nI avoid the word save and instead speak of exporting (Case 1: writing to a file) or storing (Case 2: storing results/values within R in an object).\n\n\n\nThe proprietary format in R for exporting data.frames and reloading afterwards is .RData (comparable to dta in Stata):\n\nsaveRDS(pend06, file = \"./data/pend06.RData\")\nrm(pend06) # delete pend06 from memory\n\npend06_neu &lt;- readRDS(file = \"./data/pend06.RData\")\nhead(pend06) # does not exist anymore -&gt; rm()\n\nError in eval(expr, envir, enclos): Objekt 'pend06' nicht gefunden\n\nhead(pend06_neu,n=1)\n\n# A tibble: 1 × 123\n         pnr      hnr welle   pintjahr pintmon  pintmod zpsex   palter PD0400   \n       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt;\n1 1000402601 10004026 1 [Wel… 2006     12 [Dez… 0 [CAT… 1 [Mae… 71     -10 [Ite…\n# ℹ 114 more variables: PA0100 &lt;dbl+lbl&gt;, PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nWe can also export and restore other objects. However, we need to load() them, which will result in restoring the previous object name:\n\nsave(studs, file = \"./data/stud_vektor.RData\")\nrm(studs)\nstuds\nload(file = \"./data/stud_vektor.RData\") # studs is back with the same object name\nstuds\n\nThis also works for multiple Objects:\n\nsave(studs,profs, file = \"./data/meine_vektoren.RData\")\nrm(studs,profs)\nstuds\nprofs\nload(file = \"./data/meine_vektoren.RData\") # studs & profs restored with the same name\nstuds\nprofs\n\n\n2.13.1 Übung",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#overview-importing-and-exporting-data-sets",
    "href": "02_intro.html#overview-importing-and-exporting-data-sets",
    "title": "2  Working with Datasets",
    "section": "2.14 Overview: Importing and exporting data sets",
    "text": "2.14 Overview: Importing and exporting data sets\nImporting data sets\n\nExplanantionsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nfile type\nR function\nR package\nComment\n\n\n\n\n.csv\nread.table()\n-\nset delimiter with `sep = \";\"`\n\n\n.Rdata (R format)\nreadRDS\n-\n\n\n\ngroße .csv\nvroom()\n{vroom}\nset delimiter using `delim = \";\"`\n\n\n.dta (Stata)\nread_dta()\n{haven}\n\n\n\n.dta (Stata - große Dateien)\nread.dta13()\n{readstata13}\nuse convert.factors = F to import only numeric values\nalso imports files from newer Stata versions\n\n\n.dat (SPSS)\nread_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nread_xlsx()\n{readxl}\nuse `sheet = 1`to specifiy which sheet you want\n\n\n\n\n\n\n\n\n\n\n# csv file\ndat1 &lt;- read.table(file = \"Dateiname.csv\",sep = \";\")\n\n# Rdata\ndat1 &lt;- readRDS(file = \"Dateiname.Rdata\")\n\n# large csv\nlibrary(vroom)\ndat1 &lt;- vroom(file = \"Dateiname.csv\",delim = \";\")\n\n# Stata dta\nlibrary(haven)\ndat1 &lt;- read_dta(file = \"Dateiname.dta\")\n\n# Stata large files\n# faster than read_dta(), but without labels\nlibrary(readstata13)\ndat1 &lt;- read.dta13(file = \"Dateiname.dta\",convert.factors = F) \n\n# SPSS sav\ndat1 &lt;- read_sav(file = \"Dateiname.sav\")\n\n# Excel\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"1\")\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"Tabellenblatt1\")\n\n\n\n\nExporting data sets\n\nExplanantionsCode\n\n\n\n\n\n\n\nfile type\nR function\nR package\nComment\n\n\n\n\n.Rdata (R format)\nsaveRDS()\n-\nall variable properties remain\n\n\n.csv\nwrite.table()\n-\nuse `sep = \";\"` to set delimiter br&gt;use row.names= F to suppress row numbering\n\n\n.dta (Stata)\nwrite_dta()\n{haven}\n\n\n\n.dat (SPSS)\nwrite_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nwrite.xlsx()\n{xlsx}\nmit `sheetName` ggf. Tabellenblattname angeben\n\n\n\n\n\n\n\n\n\n\n# Rdata\nsaveRDS(dat1,file = \"Dateiname.Rdata\")\n# csv\nwrite.table(dat1,file = \"Dateiname.csv\",sep = \";\",row.names = F)\n# dta\nlibrary(haven)\nwrite_dta(dat1,path = \"Dateiname.dta\")\n# sav\nlibrary(haven)\nwrite_sav(dat1,path = \"Dateiname.sav\")\n# xlsx\nlibrary(xlsx)\nwrite.xlsx(dat1,file = \"Dateiname.xlsx\", sheetName = \"Tabellenblatt 1\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#hilfe-zu-paketen-und-funktionen",
    "href": "02_intro.html#hilfe-zu-paketen-und-funktionen",
    "title": "2  Working with Datasets",
    "section": "2.15 Hilfe zu Paketen und Funktionen",
    "text": "2.15 Hilfe zu Paketen und Funktionen\nR packages (often) come with very detailed help pages, which can either be called up directly from RStudio:\n\n# help for packages\nvignette(\"dplyr\")\nvignette(package = \"dplyr\")\nvignette(\"rowwise\")\nhelp(\"dplyr\")\nhelp(package = \"dplyr\")\n\n\n# help for a specific function\n?select()\n\nAlternatively, googling the package and function mostly gives you what you need R dplyr select()\nOr refer to the CRAN site:\n\n\n\n\n\nCRAN-Seite für {dplyr}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#exercises",
    "href": "02_intro.html#exercises",
    "title": "2  Working with Datasets",
    "section": "2.16 Exercises",
    "text": "2.16 Exercises\n\n2.16.1 Exercise 1\n\nCreate a data.frame object called dat2:\n\n\ndat2 &lt;- data.frame(studs = c(14954,47269 ,23659,9415 ,38079), \n                   profs = c(250,553,438 ,150,636),\n                   prom_recht = c(FALSE,TRUE,TRUE,TRUE,FALSE),\n                   gegr  = c(1971,1870,1457,1818,1995))\n\n\nDo you see dat2 in your environment?\nPrint dat2 in the console.\nAdd the names of the universities as a new column to the dataset. The names are in this order:\n\n\nc(\"FH Aachen\",\"RWTH Aachen\",\"Uni Freiburg\",\"Uni Bonn\",\"FH Bonn-Rhein-Sieg\")\n\n[1] \"FH Aachen\"          \"RWTH Aachen\"        \"Uni Freiburg\"      \n[4] \"Uni Bonn\"           \"FH Bonn-Rhein-Sieg\"\n\n\n\nDisplay dat2 - either in the console or using View().\nCalculate the ratio of students per professor and store the results in a new variable. Check the result.\nDisplay only the third row of dat2.\nDisplay only the third column of dat2.\n\nWhat would you do to copy dat2 into an object called df_unis?\nBack to top\n\n\n\n2.16.2 Exercise 2\n\nCreate a .Rprofile for the package installation in C:\\Users\\*USERNAME*\\Documents.\nInstall the tidyverse packages using fdz_install(\"tidyverse\") after placing the .Rprofile file under C:\\Users\\*USERNAME*\\Documents.\nUse the data.frame dat2 from Exercise 1.\nUse filter to display only the universities with fewer than 10,000 students. (Remember to install and load {tidyverse} with library()).\nDisplay only the gegr column.\nDisplay only the rows of universities with the right to award doctorates (prom_recht).\n\nBack to top\n\n\n\n2.16.3 Exercise 3\n\nContinue using the dataset from Exercises 1 & 2.\nDisplay only the universities that were founded in 1971, 1457, or 1995, and for these cases, show only the name and founding year.\nSort the dataset according to the following order. (Create a factor variable that defines this order.)\n\n\nc(\"RWTH Aachen\", \"Uni Freiburg\", \"Uni Bonn\", \"FH Aachen\", \"FH Bonn-Rhein-Sieg\")\n\n[1] \"RWTH Aachen\"        \"Uni Freiburg\"       \"Uni Bonn\"          \n[4] \"FH Aachen\"          \"FH Bonn-Rhein-Sieg\"\n\n\nBack to top\n\n\n\n2.16.4 Exercise 4\n\nCreate an R project in your directory for this course.\nSave the personal data from the PASS-CampusFile (PENDDAT_cf_W13.dta) in your directory in the subfolder orig.\nRead the dataset PENDDAT_cf_W13.dta as shown above into R and assign it to the object name pend.\nUse head() and View() to get an overview of the dataset.\nHow many respondents (rows) does the dataset contain?\nDisplay the variable names of pend using names()!\nHow can you display the rows that contain the respondent with the pnr 1000908201?\nSelect all respondents older than 60 (Age: palter) and save this selection as ue_1960.\nHow do you need to adjust the command so that ue_1960 contains only the variables pnr, hnr, welle, pintjahr, and palter?\nHow many columns does ue_1960 have? How many rows?\n\nBonus Exercises:\n\n\nHow old is the respondent with the pnr 1000908201 in welle 10 (in pintjahr 2016)?\nCreate a new variable with the birth year of the respondents (based on the age palter and the interview year pintjahr).\n\n\nBack to top\n\n\n\n2.16.5 Exercise 5\n\nExport the data.frame with the smaller dataset version (ue_1960) created in the previous exercise as an .Rdata file.\nLoad the exported .Rdata file under a different name, e.g., ue_1960_neu.\nDid everything work? Compare the newly loaded object with the original one: identical(ue_1960, ue_1960_neu) - are both objects identical?\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#appendix",
    "href": "02_intro.html#appendix",
    "title": "2  Working with Datasets",
    "section": "2.17 Appendix",
    "text": "2.17 Appendix\n\n2.17.1 Alternatives to R Projects\nBesides setting up a project, you can also set the path using setwd() or directly specify it within read_dta() or other read...() commands. However, this approach is less portable to other machines. When someone else opens the .Rproj file, R automatically sets paths relative to the file’s location. This is also true if the directory is moved on your device—R will automatically adjust the working directory.\nTo set the working directory with setwd(), insert the folder path within the parentheses. Make sure to replace any \\ with /:\n\nsetwd(\"D:/Kurse/R_IAB\")\n\nYou can check if it worked with getwd():\n\ngetwd()\n\nThe path you set with setwd() should appear.\nAlternatively, you can provide the full path directly in read_dta():\n\npend &lt;- haven::read_dta(\"C:/Kurse/R_IAB/orig/PENDDAT_cf_W13.dta\")\n\n\n\n2.17.2 Selecting Rows & Columns Without {dplyr}\nBase R (without extensions like {dplyr}) can also filter datasets using square brackets []:\n\ndat1[1, 1] # first row, first column\n\n[1] 19173\n\ndat1[1, ]  # first row, all columns\n\n  studs profs gegr stu_prof        uni    uni_fct\n1 19173   322 1971 59.54348 Uni Bremen Uni Bremen\n\ndat1[, 1]  # all rows, first column (equivalent to dat1$studs)\n\n[1] 19173  5333 15643\n\ndat1[, \"studs\"] # all rows, column named studs -&gt; note the \"\"\n\n[1] 19173  5333 15643\n\n\nYou can also select multiple rows or columns by using c():\n\ndat1[c(1, 2), ]  ## 1st & 2nd row, all columns\ndat1[, c(1, 3)]  ## all rows, 1st & 3rd column (equivalent to dat1$studs & dat1$stu_prof)\ndat1[, c(\"studs\", \"uni\")] ## all rows, columns named studs and uni\n\nYou can also write conditions in these square brackets to make selections from dat1.\n\ndat1 # full dataset\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\ndat1[dat1$uni == \"Uni Oldenburg\", ] # Rows where uni equals \"Uni Oldenburg\", all columns\n\n  studs profs gegr stu_prof           uni       uni_fct\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\ndat1$studs[dat1$uni == \"Uni Oldenburg\"] # Just check the student count: no comma needed\n\n[1] 15643\n\n\nThis works as expected, and we can expand it:\n\ndat1[dat1$uni == \"Uni Oldenburg\" & dat1$studs &gt; 10000, ] # & means AND\n\n  studs profs gegr stu_prof           uni       uni_fct\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\nYou can also use the OR operator:\n\ndat1[dat1$uni == \"Uni Oldenburg\" | dat1$studs &gt; 10000, ]\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\n\n\n2.17.3 select() vs $\nWhen you use select() to pick a specific variable, it preserves the data structure as a data.frame(), whereas dat1$variablename extracts the column as a vector (a series of values):\n\ndat1$studs\n\n[1] 19173  5333 15643\n\nclass(dat1$studs)\n\n[1] \"numeric\"\n\ndat1$studs / 20\n\n[1] 958.65 266.65 782.15\n\n\nselect() keeps the values as a column in a data.frame:\n\ndat1 %&gt;% select(studs)\n\n  studs\n1 19173\n2  5333\n3 15643\n\ndat1 %&gt;% select(studs) %&gt;% class()\n\n[1] \"data.frame\"\n\ndat1 %&gt;% select(studs) / 20\n\n   studs\n1 958.65\n2 266.65\n3 782.15",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#footnotes",
    "href": "02_intro.html#footnotes",
    "title": "2  Working with Datasets",
    "section": "",
    "text": "In many other programming languages, these are called libraries.↩︎\nThere are more, and this enumeration ignores technical details—for an advanced introduction to vectors in R, click here.↩︎\nWe will see soon how packages can make working in R easier.↩︎\nIt has become common in the R community to write packages with {} to distinguish them more clearly from functions. I follow this convention in this script.↩︎\nSometimes the dataset is not in the project’s subfolder, in which case the entire path can be specified in read_dta(): pend &lt;- read_dta(file = \"D:/Courses/R-Course/data/PENDDAT_cf_W13.dta\")↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "03_desc.html",
    "href": "03_desc.html",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "3.1 Frequency Counts\nWe have various commands available to create a frequency count:\nThe simplest command for counting frequencies is the table() command. For example, with the variable statakt representing the education status of respondents:\ntable(pend$statakt)\n\n\n -10   -9   -5    1    2    3 \n3765 3289  280 9470 6139 5481\nHere, we see the absolute frequencies displayed. The first row lists the different values, and the second row shows the frequencies.\nHowever, the labels are ignored in the output of table(). A look into the PASS data report or using attributes() reveals the value labels:\nattributes(pend$statakt)\n\n$label\n[1] \"Aktueller Hauptstatus, generiert (ab Welle 2)\"\n\n$format.stata\n[1] \"%46.0g\"\n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n$labels\nItem fuer Fragebogenversion nicht relevant \n                                       -10 \n               Item in Welle nicht erhoben \n                                        -9 \n   Generierung nicht mgl. (fehlende Werte) \n                                        -5 \n                             Erwerbstaetig \n                                         1 \n        Arbeitslos (Gemeldet und sonstige) \n                                         2 \n                                   Inaktiv \n                                         3\nt1 &lt;- table(pend$statakt)\n9470 respondents are employed, 5481 respondents are inactive, etc. (More on labels and working with value labels in R later.)\nWith count() from {dplyr}, we get the labels displayed directly. Again, we use the pipe %&gt;%:\npend %&gt;% count(statakt)\n\n# A tibble: 6 × 2\n  statakt                                              n\n  &lt;dbl+lbl&gt;                                        &lt;int&gt;\n1 -10 [Item fuer Fragebogenversion nicht relevant]  3765\n2  -9 [Item in Welle nicht erhoben]                 3289\n3  -5 [Generierung nicht mgl. (fehlende Werte)]      280\n4   1 [Erwerbstaetig]                               9470\n5   2 [Arbeitslos (Gemeldet und sonstige)]          6139\n6   3 [Inaktiv]                                     5481\nWe can also store tables under a freely chosen name and call them up later:\nt1 &lt;- table(pend$statakt)\nt2 &lt;- pend %&gt;% count(statakt)\nWe see here that the table with table() creates a new object form, a table. With count(), however, a data.frame is created.\nclass(t1)\n\n[1] \"table\"\n\nclass(t2)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#frequency-counts",
    "href": "03_desc.html#frequency-counts",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "table()\ncount() from {dplyr}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#NA03",
    "href": "03_desc.html#NA03",
    "title": "3  Getting an Overview",
    "section": "3.2 Missing Values in R: NA",
    "text": "3.2 Missing Values in R: NA\nNegative values are a bit annoying.\nTo mark the values like -5 as missing data in R, we need to set them to NA in pend. To do this, we call pend$statakt and filter with [] only the values for statakt equal to -1. In the previous chapter, we learned how to call specific values this way:\n\npend$statakt[pend$statakt == -5] # only call statakt = -5\n\n&lt;labelled&lt;double&gt;[280]&gt;: Aktueller Hauptstatus, generiert (ab Welle 2)\n  [1] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [26] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [51] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [76] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[101] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[126] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[151] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[176] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[201] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[226] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[251] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[276] -5 -5 -5 -5 -5\n\nLabels:\n value                                      label\n   -10 Item fuer Fragebogenversion nicht relevant\n    -9                Item in Welle nicht erhoben\n    -5    Generierung nicht mgl. (fehlende Werte)\n     1                              Erwerbstaetig\n     2         Arbeitslos (Gemeldet und sonstige)\n     3                                    Inaktiv\n\n\n(Here, we get the labels again, which is somewhat suboptimal for clarity.)\nIf we then assign a new value with &lt;-, the called values will be overwritten - here, we overwrite all values for statakt == -1 with NA:\n\npend$statakt[pend$statakt == -5]  &lt;- NA\n\nNA is the code for missing data in R, and they will not be listed in table():\n\ntable(pend$statakt)\n\n\n -10   -9    1    2    3 \n3765 3289 9470 6139 5481 \n\n\nBut we can explicitly request the count of NA with the option exclude = NULL:\n\ntable(pend$statakt,exclude = NULL)\n\n\n -10   -9    1    2    3 &lt;NA&gt; \n3765 3289 9470 6139 5481  280 \n\n\nHowever, we have not yet overwritten all the negative values; -10 and -9 are still missing. Of course, it would be possible this way, but it’s a bit cumbersome:\n\npend$statakt[pend$statakt == -9 ]  &lt;- NA\npend$statakt[pend$statakt == -10]  &lt;- NA\n\nFor the PASS data, it’s shorter to use &lt; 0, because all missing codes are less than 0:1\n\npend$statakt[pend$statakt &lt; 0 ]  &lt;- NA\n\nNow we are done with statakt:\n\ntable(pend$statakt)\n\n\n   1    2    3 \n9470 6139 5481 \n\ntable(pend$statakt,exclude = NULL)\n\n\n   1    2    3 &lt;NA&gt; \n9470 6139 5481 7334 \n\n\nIn count(), NA is also counted:\n\npend %&gt;% count(statakt)\n\n# A tibble: 4 × 2\n  statakt                                     n\n  &lt;dbl+lbl&gt;                               &lt;int&gt;\n1  1 [Erwerbstaetig]                       9470\n2  2 [Arbeitslos (Gemeldet und sonstige)]  6139\n3  3 [Inaktiv]                             5481\n4 NA                                       7334\n\n\nIf we want to avoid this, we use filter() again - with is.na(), we can identify NA. By prefixing with !, we can request that all non-NA values be retained with TRUE:\n\npend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt)\n\n# A tibble: 3 × 2\n  statakt                                    n\n  &lt;dbl+lbl&gt;                              &lt;int&gt;\n1 1 [Erwerbstaetig]                       9470\n2 2 [Arbeitslos (Gemeldet und sonstige)]  6139\n3 3 [Inaktiv]                             5481\n\n\nMore about missing values can be found, for example, in The missing book by Nicholas Tierney & Allison Horst.\n\n3.2.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#other-table-values",
    "href": "03_desc.html#other-table-values",
    "title": "3  Getting an Overview",
    "section": "3.3 Other Table Values",
    "text": "3.3 Other Table Values\nWith the help of additional functions, we can customize the frequency tables:\n\nprop.table(): relative values/percentages\n\n\ntable(pend$statakt) %&gt;% prop.table(.) \n\n\n        1         2         3 \n0.4490280 0.2910858 0.2598862 \n\n\n29.109% of respondents are unemployed.\n\ncumsum(): cumulative values\n\n\ntable(pend$statakt) %&gt;% cumsum(.)\n\n    1     2     3 \n 9470 15609 21090 \n\n\n15609 respondents are employed or unemployed.\n\nprop.table() with cumsum(): cumulative relative frequencies\n\n\ntable(pend$statakt) %&gt;% prop.table() %&gt;% cumsum()\n\n        1         2         3 \n0.4490280 0.7401138 1.0000000 \n\n\n74.011% of respondents are employed or unemployed (and not inactive).\n\n\n\n\n\n\nMultiple Metrics in One Table\n\n\n\n\n\nMany are probably familiar with the following view from Stata with tab statakt:\n\n\n   Aktueller Hauptstatus, generiert (ab |\n                               Welle 2) |      Freq.     Percent        Cum.\n----------------------------------------+-----------------------------------\n                          Erwerbstaetig |      9,470       33.32       33.32\n     Arbeitslos (Gemeldet und sonstige) |      6,139       21.60       54.91\n                                Inaktiv |      5,481       19.28       74.20\n                                      . |      7,334       25.80      100.00\n----------------------------------------+-----------------------------------\n                                  Total |     28,424      100.00\n\n\nBy default, table() or count() only provide one type of metric. However, since we get the counts as a data.frame() with count(), we can simply add the relative and cumulative frequencies as new variables.\nWe use dat1$var &lt;- ...., which we learned in the previous chapter. To add a new column pct to our data.frame with the counts, we proceed as follows: + First, we create a data.frame with the count using count():\n\ntab_statakt &lt;- pend %&gt;% count(statakt) # base command\ntab_statakt\n\n# A tibble: 4 × 2\n  statakt                                     n\n  &lt;dbl+lbl&gt;                               &lt;int&gt;\n1  1 [Erwerbstaetig]                       9470\n2  2 [Arbeitslos (Gemeldet und sonstige)]  6139\n3  3 [Inaktiv]                             5481\n4 NA                                       7334\n\n\n\nThen we add a new column for the relative frequencies, calculated with prop.table():\n\n\ntab_statakt$pct &lt;- prop.table(tab_statakt$n)\n\nIf we now want to create cumulative frequencies, we can apply cumsum() to pct:\n\ntab_statakt$Cum &lt;- cumsum(tab_statakt$pct)\ntab_statakt\n\n# A tibble: 4 × 4\n  statakt                                     n   pct   Cum\n  &lt;dbl+lbl&gt;                               &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1 [Erwerbstaetig]                       9470 0.333 0.333\n2  2 [Arbeitslos (Gemeldet und sonstige)]  6139 0.216 0.549\n3  3 [Inaktiv]                             5481 0.193 0.742\n4 NA                                       7334 0.258 1    \n\n\nThe NA is still somewhat annoying as it represents missing data and should not be included. We can exclude it simply with !is.na() in filter():\n\ntab_statakt2 &lt;- pend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt) \ntab_statakt2$pct &lt;- prop.table(tab_statakt2$n)\ntab_statakt2\n\n# A tibble: 3 × 3\n  statakt                                    n   pct\n  &lt;dbl+lbl&gt;                              &lt;int&gt; &lt;dbl&gt;\n1 1 [Erwerbstaetig]                       9470 0.449\n2 2 [Arbeitslos (Gemeldet und sonstige)]  6139 0.291\n3 3 [Inaktiv]                             5481 0.260\n\ntab_statakt2$cum &lt;- cumsum(tab_statakt2$pct)\ntab_statakt2\n\n# A tibble: 3 × 4\n  statakt                                    n   pct   cum\n  &lt;dbl+lbl&gt;                              &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1 [Erwerbstaetig]                       9470 0.449 0.449\n2 2 [Arbeitslos (Gemeldet und sonstige)]  6139 0.291 0.740\n3 3 [Inaktiv]                             5481 0.260 1    \n\n\n\n\n\n\n3.3.1 Creating a Contingency Table\nContingency tables allow us to explore how frequently combinations of different variables occur together. Let’s look at two ways to create contingency tables in R.\nUsing the table() function, we create a contingency table by inserting two variables. For instance, if we want to see the frequencies of employment status (statakt) by gender (zpsex), we can use the following command:\n\ntable(pend$zpsex, pend$statakt)\n\n   \n       1    2    3\n  1 4685 3240 2047\n  2 4785 2899 3434\n\n\nThis table shows the counts of respondents by gender and employment status. For example, if zpsex=2 represents females and statakt=3 represents inactivity, the table displays how many female respondents are inactive.\nTo add row and column totals, use the addmargins() function:\n\ntable(pend$zpsex, pend$statakt) %&gt;% addmargins()\n\n     \n          1     2     3   Sum\n  1    4685  3240  2047  9972\n  2    4785  2899  3434 11118\n  Sum  9470  6139  5481 21090\n\n\nIf you want to compute the relative frequencies instead of absolute counts, use the prop.table() function:\n\ntable(pend$zpsex, pend$statakt) %&gt;% prop.table()\n\n   \n             1          2          3\n  1 0.22214320 0.15362731 0.09706022\n  2 0.22688478 0.13745851 0.16282598\n\n\nFor row-wise percentages (within each gender, how many fall into each employment status), use:\n\ntable(pend$zpsex, pend$statakt) %&gt;% prop.table(margin = 1)\n\n   \n            1         2         3\n  1 0.4698155 0.3249097 0.2052748\n  2 0.4303832 0.2607483 0.3088685\n\n\nFor column-wise percentages (within each employment status, how many are male or female), use:\n\ntable(pend$zpsex, pend$statakt) %&gt;% prop.table(margin = 2)\n\n   \n            1         2         3\n  1 0.4947202 0.5277733 0.3734720\n  2 0.5052798 0.4722267 0.6265280\n\n\n\n\n3.3.2 Working with count() from {dplyr}\nAnother approach to generate frequency tables is using count() from the {dplyr} package. It provides a more readable output with labeled variables:\n\npend %&gt;% count(zpsex, statakt)\n\n# A tibble: 8 × 3\n  zpsex         statakt                                     n\n  &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt;                               &lt;int&gt;\n1 1 [Maennlich]  1 [Erwerbstaetig]                       4685\n2 1 [Maennlich]  2 [Arbeitslos (Gemeldet und sonstige)]  3240\n3 1 [Maennlich]  3 [Inaktiv]                             2047\n4 1 [Maennlich] NA                                       3555\n5 2 [Weiblich]   1 [Erwerbstaetig]                       4785\n6 2 [Weiblich]   2 [Arbeitslos (Gemeldet und sonstige)]  2899\n7 2 [Weiblich]   3 [Inaktiv]                             3434\n8 2 [Weiblich]  NA                                       3779",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#summary-statistics",
    "href": "03_desc.html#summary-statistics",
    "title": "3  Getting an Overview",
    "section": "3.4 Summary Statistics",
    "text": "3.4 Summary Statistics\nFor numerical variables, such as income (netges), we often compute summary statistics like the mean, median, or quantiles. To get a quick overview, use summary():\n\nsummary(pend$netges)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n    -5.0     -3.0     -3.0    567.9    990.0 111419.0 \n\n\n\n3.4.1 Handling Missing Data\nNegative values in the data (like -5 for netges) typically represent missing data. We can convert these to NA:\n\npend$netges[pend$netges &lt; 0] &lt;- NA\n\n\n\n3.4.2 Calculating Specific Statistics\nTo calculate specific statistics, we can use:\n\nMinimum: min()\nMaximum: max()\nMean: mean()\nMedian: median()\nQuantiles: quantile()\nVariance: var()\nStandard Deviation: sd()\n\nFor instance, the mean of income ignoring missing values:\n\nmean(pend$netges, na.rm = TRUE)\n\n[1] 1562.3\n\n\n\n\n3.4.3 Custom Summary with summarise()\nYou can use summarise() from {dplyr} to create custom summary tables:\n\npend %&gt;% summarise(\n  Minimum = min(netges, na.rm = TRUE),\n  Median = median(netges, na.rm = TRUE),\n  Mean = mean(netges, na.rm = TRUE),\n  Maximum = max(netges, na.rm = TRUE)\n)\n\n# A tibble: 1 × 4\n  Minimum   Median  Mean Maximum  \n  &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n1 0           1320 1562. 111419   \n\n\n\n\n3.4.4 Comparing Across Groups\nTo compare statistics across groups, use .by in summarise():\n\npend %&gt;% summarise(\n  Minimum = min(netges, na.rm = TRUE),\n  Median = median(netges, na.rm = TRUE),\n  Mean = mean(netges, na.rm = TRUE),\n  Maximum = max(netges, na.rm = TRUE),\n  .by = welle\n) %&gt;% arrange(welle)\n\n# A tibble: 13 × 5\n   welle                    Minimum   Median  Mean Maximum  \n   &lt;dbl+lbl&gt;                &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n 1  1 [Welle 1 (2006/2007)] 1          1200  1525. 111419   \n 2  2 [Welle 2 (2007/2008)] 0          1320  1529.   7200   \n 3  3 [Welle 3 (2008/2009)] 0          1298. 1498.  12000   \n 4  4 [Welle 4 (2010)]      0          1210  1447.  10800   \n 5  5 [Welle 5 (2011)]      0          1250  1494.  33363   \n 6  6 [Welle 6 (2012)]      0          1215  1459.  15950   \n 7  7 [Welle 7 (2013)]      0          1250  1539.  87835   \n 8  8 [Welle 8 (2014)]      0          1255  1456.   9000   \n 9  9 [Welle 9 (2015)]      0          1280  1613. 110451   \n10 10 [Welle 10 (2016)]     0          1375  1541.   6300   \n11 11 [Welle 11 (2017)]     0          1500  1748.  44440   \n12 12 [Welle 12 (2018)]     0          1500  1667.   7150   \n13 13 [Welle 13 (2019)]     0          1550  1816.  88453   \n\n\nYou can also filter for specific waves if needed:\n\npend %&gt;% \n  filter(welle %in% c(1, 10)) %&gt;% \n  summarise(\n    Minimum = min(netges, na.rm = TRUE),\n    Median = median(netges, na.rm = TRUE),\n    Mean = mean(netges, na.rm = TRUE),\n    Maximum = max(netges, na.rm = TRUE),\n    .by = welle\n  )\n\n# A tibble: 2 × 5\n  welle                    Minimum   Median  Mean Maximum  \n  &lt;dbl+lbl&gt;                &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n1  1 [Welle 1 (2006/2007)] 1           1200 1525. 111419   \n2 10 [Welle 10 (2016)]     0           1375 1541.   6300   \n\n\nThese methods allow for thorough analysis of both categorical and numerical data in R.\n\n\n3.4.5 Exercise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#übungen",
    "href": "03_desc.html#übungen",
    "title": "3  Getting an Overview",
    "section": "3.5 Übungen",
    "text": "3.5 Übungen\n\nAlle Übungen beziehen sich auf das PASS CampusFile PENDDAT_cf_W13.dta:\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nZur Erinnerung: hier geht’s zur Übersicht der Einlesebefehle\n\n3.5.1 Übung 1\nWir interessieren uns für die Variable famstand, welche den Familienstand der Befragten enthält:\n\n\n\n\n\n\n\n\nFamilienstand, generiert\nFamilienstand, generiert\n\n\n\n\n-8\nUnplausibler Wert\n\n\n-4\nFrage irrtuemlich nicht gestellt\n\n\n-3\nTrifft nicht zu (Filter)\n\n\n-2\nKeine Antwort\n\n\n1\nLedig\n\n\n2\nVerheiratet/eing. Lebensp., zus. lebd.\n\n\n3\nVerheiratet/eing. Lebensp., getr. lebd.\n\n\n4\nGeschieden\n\n\n5\nVerwitwet\n\n\n\n\n\n\n\n\nLassen Sie sich eine Tabelle mit den absoluten Häufigkeiten anzeigen, nutzen Sie dafür sowohl table() als auch count() (Denken Sie daran, {tidyverse} zu laden für count()).\nÜberschreiben Sie Missing-Codes mit NA.\nHat das Überschreiben der Missings mit NA geklappt? Erstellen Sie die Tabelle erneut.\nLassen Sie sich der relativen Häufigkeiten (Anteile) ausgeben. Verwenden Sie prop.table() auf Basis des table().\nErstellen Sie eine Kontingenztabelle, indem Sie neben famstand auch das Geschlecht zpsex (2 = Frauen, 1 = Männer) mit einbeziehen\n\nZurück nach oben\n\n\n3.5.2 Übung 2\n\n\nErstellen Sie eine Kontingenztabelle für famstand und zpsex\nWie viel Prozent der Befragten sind geschiedene Frauen?\nWie viel Prozent der befragten Frauen sind geschieden? Nutzen Sie die margin =-Option\nWie viel Prozent der befragten Geschiedenen sind Frauen? Nutzen Sie die margin =-Option\n\nZurück nach oben\n\n\n3.5.3 Übung 3\nBeschreiben Sie das Alter der Befragten (palter) mit summary und erstellen Sie selbst einen Überblick mit Hilfe von summarise(), der einen Vergleich des Befragtenalters nach Familienstand erlaubt.\n\nÜberschreiben Sie zunächst die Missings mit NA:\n\n\npend$palter[pend$palter&lt;0] &lt;- NA\npend$famstand[pend$famstand&lt;0] &lt;- NA\n\n\nErstellen Sie einen Überblick mit summary()\nErstellen Sie einen Überblick mit dem Minimum, Median, arith. Mittel, Varianz und Maximum der Alterswerte mit Hilfe von summarise()\nErweitern Sie diesen Überblick dann so, dass sie einen Vergleich der Kennzahlen für die verschiedenen famstand-Kategorien ausgegeben bekommen.\n\nZurück nach oben",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#hinweise",
    "href": "03_desc.html#hinweise",
    "title": "3  Getting an Overview",
    "section": "3.6 Hinweise",
    "text": "3.6 Hinweise\n\n3.6.1 Runden mit round()\nErläuterung: Sie können mit round(x , 3) Werte auf eine gewisse Zahl von Ziffern runden. Die zweite Zahl in der Klammer (nach dem Komma) gibt an, wieviele Dezimalstellen wir möchten:\n\nround(21.12121123,digits = 3)\n\n[1] 21.121\n\nround(21.12121123,digits = 5)\n\n[1] 21.12121\n\nround(21.12121123,digits = 0)\n\n[1] 21\n\n\nWir können also die relativen Häufigkeiten runden und so die Tabelle von oben übersichtlicher machen:\n\nxtabs(~zpsex+statakt, data = pend) %&gt;% \n  prop.table(.,margin = 1) %&gt;% \n  round(.,3)\n\n     statakt\nzpsex     1     2     3\n    1 0.470 0.325 0.205\n    2 0.430 0.261 0.309",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#footnotes",
    "href": "03_desc.html#footnotes",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "For non-systematic values, we can use the %in% operator that we already learned about in connection with filter(): pend$var1[pend$var1 %in% c(-9,2,124) ]  &lt;- NA (this is just an example).↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html",
    "href": "04_data_wrangle.html",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "4.1 Creating Variables\nLet’s take a closer look at creating variables in R. There are two basic ways to add variables to a data.frame:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#var",
    "href": "04_data_wrangle.html#var",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "Base R: ...$newvar &lt;-\n{dplyr}: mutate(new_var= )\n\n\n4.1.1 Base R: ...$newvar &lt;-\n\ndat3$studs_to_mean &lt;- dat3$studs - mean(dat3$studs)\ndat3\n\n  studs profs gegr prom_recht                uni studs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625\n4 14954   250 1971      FALSE          FH Aachen     -6736.625\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375\n\n\nYou can also delete variables using &lt;- NULL:\n\ndat3$studs_to_mean &lt;- NULL\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\n\n\n4.1.2 {dplyr}: mutate(new_var= )\nAn alternative way to create variables is using mutate(new_variable = ) from {dplyr} ({tidyverse}):\n\ndat3 %&gt;% mutate(studs_to_mean = studs - mean(studs))\n\n  studs profs gegr prom_recht                uni studs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625\n4 14954   250 1971      FALSE          FH Aachen     -6736.625\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375\n\n\nYou can also create multiple variables within a single mutate() command:\n\ndat3 %&gt;% mutate(\n  studs_to_mean = studs - mean(studs),\n  profs_to_mean = profs - mean(profs)\n)\n\n  studs profs gegr prom_recht                uni studs_to_mean profs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625         -6.25\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625       -261.25\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625       -118.25\n4 14954   250 1971      FALSE          FH Aachen     -6736.625        -78.25\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375        224.75\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375        109.75\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625       -178.25\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375        307.75\n\n\nOr variables can be reused within mutate():\n\ndat3 %&gt;% mutate(\n  rel_to_mean = studs - mean(studs),\n  above_mean = rel_to_mean &gt; 0\n)\n\n  studs profs gegr prom_recht                uni rel_to_mean above_mean\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625      FALSE\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625      FALSE\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625      FALSE\n4 14954   250 1971      FALSE          FH Aachen   -6736.625      FALSE\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375       TRUE\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375       TRUE\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625      FALSE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375       TRUE\n\n\nThe original dataset remains unchanged:\n\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\nTo keep the results, store them in an object:\n\ndat4 &lt;- dat3 %&gt;% mutate(\n  rel_to_mean = studs - mean(studs),\n  above_mean = rel_to_mean &gt; 0\n)\n\ndat4\n\n  studs profs gegr prom_recht                uni rel_to_mean above_mean\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625      FALSE\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625      FALSE\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625      FALSE\n4 14954   250 1971      FALSE          FH Aachen   -6736.625      FALSE\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375       TRUE\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375       TRUE\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625      FALSE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375       TRUE\n\n\n\n\n\n\n\n\nCreating Dummy Variables with as.numeric()\n\n\n\n\n\nYou can convert logical variables into numeric dummy variables (0/1) using as.numeric():\n\ndat3 %&gt;% mutate(\n  prom_dummy = as.numeric(prom_recht),\n  over10k = as.numeric(studs &gt; 10000)\n)\n\n  studs profs gegr prom_recht                uni prom_dummy over10k\n1 19173   322 1971       TRUE         Uni Bremen          1       1\n2  5333    67 1830       TRUE         Uni Vechta          1       0\n3 15643   210 1973       TRUE      Uni Oldenburg          1       1\n4 14954   250 1971      FALSE          FH Aachen          0       1\n5 47269   553 1870       TRUE        RWTH Aachen          1       1\n6 23659   438 1457       TRUE       Uni Freiburg          1       1\n7  9415   150 1818       TRUE           Uni Bonn          1       0\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg          0       1\n\n\n\n\n\n\n\n4.1.3 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#group_by",
    "href": "04_data_wrangle.html#group_by",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.2 Grouping with .by=",
    "text": "4.2 Grouping with .by=\nThe true power of mutate() becomes apparent when combined with other {dplyr} functions. A common task in data preparation involves grouped values.\nWe’ll make our example dataset a bit smaller:\n\ndat5 &lt;- dat3 %&gt;% \n  select(-uni,-gegr) # to ensure everything is visible\n\nSince {dplyr} version 1.1.1, we can specify a grouping directly in mutate() using the .by= argument. This .by= grouping is applied only to the immediate calculations within mutate():\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  mutate(m_studs2 = mean(studs),\n         .by = prom_recht) %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n  studs profs prom_recht  m_studs m_profs m_studs2 m_profs2\n1 19173   322       TRUE 21690.62  328.25  20082.0   328.25\n2  5333    67       TRUE 21690.62  328.25  20082.0   328.25\n3 15643   210       TRUE 21690.62  328.25  20082.0   328.25\n4 14954   250      FALSE 21690.62  328.25  26516.5   328.25\n5 47269   553       TRUE 21690.62  328.25  20082.0   328.25\n6 23659   438       TRUE 21690.62  328.25  20082.0   328.25\n7  9415   150       TRUE 21690.62  328.25  20082.0   328.25\n8 38079   636      FALSE 21690.62  328.25  26516.5   328.25\n\n\nUsing summarise() instead of mutate() provides an overview:\n\ndat5 %&gt;%\n  summarise(m_studs = mean(studs),.by = prom_recht)\n\n  prom_recht m_studs\n1       TRUE 20082.0\n2      FALSE 26516.5\n\n\n\n\n\n\n\n\ngroup_by()\n\n\n\n\n\nBefore {dplyr} 1.1.1, grouping a dataset relied on group_by(). After setting group_by() along the values of a variable, all subsequent mutate() calculations are performed only within those groups:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs),\n         m_profs2 = mean(profs))\n\n# A tibble: 8 × 7\n# Groups:   prom_recht [2]\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 19173   322 TRUE        21691.    328.   20082       290\n2  5333    67 TRUE        21691.    328.   20082       290\n3 15643   210 TRUE        21691.    328.   20082       290\n4 14954   250 FALSE       21691.    328.   26516.      443\n5 47269   553 TRUE        21691.    328.   20082       290\n6 23659   438 TRUE        21691.    328.   20082       290\n7  9415   150 TRUE        21691.    328.   20082       290\n8 38079   636 FALSE       21691.    328.   26516.      443\n\n\nAfter using group_by(), it’s good practice to remove the grouping with ungroup() once it’s no longer needed:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs)) %&gt;% \n  ungroup() %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n# A tibble: 8 × 7\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 19173   322 TRUE        21691.    328.   20082      328.\n2  5333    67 TRUE        21691.    328.   20082      328.\n3 15643   210 TRUE        21691.    328.   20082      328.\n4 14954   250 FALSE       21691.    328.   26516.     328.\n5 47269   553 TRUE        21691.    328.   20082      328.\n6 23659   438 TRUE        21691.    328.   20082      328.\n7  9415   150 TRUE        21691.    328.   20082      328.\n8 38079   636 FALSE       21691.    328.   26516.     328.\n\n\n\n\n\n\n\n4.2.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#across",
    "href": "04_data_wrangle.html#across",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.3 across(): Processing Multiple Variables",
    "text": "4.3 across(): Processing Multiple Variables\nA highly versatile addition to mutate() and summarise() is across(). This allows us to apply a function to multiple columns simultaneously, without repeating code:\n\ndat3 %&gt;%\n  summarise(studs = mean(studs),\n            profs = mean(profs))\n\n     studs  profs\n1 21690.62 328.25\n\n\nHere, across() offers a much shorter syntax for variable selection, and we can use ?select_helpers like matches():\n\ndat3 %&gt;%\n  summarise(across(.cols = matches(\"studs|profs\"),.fns = ~mean(.x)))\n\n     studs  profs\n1 21690.62 328.25\n\n\nThis is also compatible with .by=:\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), ~mean(.x)), .by= prom_recht)\n\n  prom_recht   studs profs\n1       TRUE 20082.0   290\n2      FALSE 26516.5   443\n\n\nWe can apply multiple functions by placing them in a list():\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), list(mean = ~mean(.x), sd = ~sd(.x))), .by= prom_recht)\n\n  prom_recht studs_mean studs_sd profs_mean profs_sd\n1       TRUE    20082.0 14857.84        290 183.2081\n2      FALSE    26516.5 16351.84        443 272.9432\n\n\nYou can define this list() in advance and use it later:\n\nwert_liste &lt;- list(MEAN = ~mean(.x), SD = ~sd(.x))\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), wert_liste), .by= prom_recht)\n\n  prom_recht studs_MEAN studs_SD profs_MEAN profs_SD\n1       TRUE    20082.0 14857.84        290 183.2081\n2      FALSE    26516.5 16351.84        443 272.9432\n\n\nThe .names() argument allows us to control the naming of columns. {.fn} stands for the function being applied, and {.col} represents the name of the variable being processed.\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), \n                   wert_liste,\n                   .names = \"{.fn}_{.col}\"),\n            .by= prom_recht)\n\n  prom_recht MEAN_studs SD_studs MEAN_profs SD_profs\n1       TRUE    20082.0 14857.84        290 183.2081\n2      FALSE    26516.5 16351.84        443 272.9432\n\n\nAll these functions also work with mutate():\n\ndat3 %&gt;%\n  mutate(across(matches(\"studs|profs\"),\n                wert_liste, \n                .names = \"{.col}XX{.fn}\"))\n\n  studs profs gegr prom_recht                uni studsXXMEAN studsXXSD\n1 19173   322 1971       TRUE         Uni Bremen    21690.62  14309.16\n2  5333    67 1830       TRUE         Uni Vechta    21690.62  14309.16\n3 15643   210 1973       TRUE      Uni Oldenburg    21690.62  14309.16\n4 14954   250 1971      FALSE          FH Aachen    21690.62  14309.16\n5 47269   553 1870       TRUE        RWTH Aachen    21690.62  14309.16\n6 23659   438 1457       TRUE       Uni Freiburg    21690.62  14309.16\n7  9415   150 1818       TRUE           Uni Bonn    21690.62  14309.16\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg    21690.62  14309.16\n  profsXXMEAN profsXXSD\n1      328.25  199.0827\n2      328.25  199.0827\n3      328.25  199.0827\n4      328.25  199.0827\n5      328.25  199.0827\n6      328.25  199.0827\n7      328.25  199.0827\n8      328.25  199.0827\n\n\nMore examples in the across() documentation\n\n4.3.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#custom-functions",
    "href": "04_data_wrangle.html#custom-functions",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.4 Custom Functions",
    "text": "4.4 Custom Functions\nWhat’s with the ~1 in across()? Let’s take a look at the basics of functions in R to understand.\nTo do so, let’s examine three satisfaction variables for respondents in rows 12-16:\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nImportant regarding job\n\n\n\n\nPEO0300a\nTo earn a lot of money\n\n\nPEO0300b\nA job, that is fun\n\n\nPEO0300c\nGood career opportunities\n\n\nPEO0300d\nJob security\n\n\nPEO0300e\nJob where you can show off your abilities\n\n\n\n\n\n\n\n\n\n\n\n\n\n-10 bis -1\n1\n2\n3\n4\n\n\n\n\nt.n.z./k.A.\nVery important\nRather important\nRather not important\nNot important at all\n\n\n\n\n\n\n\n\npend &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nsat_small &lt;- \n  pend %&gt;% \n    filter(welle == 1) %&gt;% \n    select(matches(\"PEO0300(a|b|c)\")) %&gt;% \n    slice(12:16) %&gt;% \n    haven::zap_labels() %&gt;% haven::zap_label() # remove labels\nsat_small\n\n# A tibble: 5 × 3\n  PEO0300a PEO0300b PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\n\n\nsat_small &lt;- sat_small %&gt;% mutate(across(everything(),~as.numeric(.x)))\n\nSometimes we want to process multiple variables in the same way. Above, we saw how to handle this with across() for existing functions. But what if we want to perform a calculation that isn’t as simple as applying mean(), sd(), etc.?\n\nsat_small %&gt;% \n  mutate(dmean_PEO0300a = PEO0300a - mean(PEO0300a,na.rm = T),\n         dmean_PEO0300c = PEO0300c - mean(PEO0300c,na.rm = T))\n\n# A tibble: 5 × 5\n  PEO0300a PEO0300b PEO0300c dmean_PEO0300a dmean_PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1        2        3        2            0.6         -0.200\n2        1        1        3           -0.4          0.8  \n3        1        1        3           -0.4          0.8  \n4        2        1        1            0.6         -1.2  \n5        1        1        2           -0.4         -0.200\n\n\n…and now what about F1450_06? Typing this out three times would violate the “DRY” principle2, especially considering the PASS CampusFile contains 5 columns of similar satisfaction variables. Copying and pasting is not a practical option.\nCustom functions allow us to adhere to the DRY principle in R. We’ll make our calculation steps part of a function() and apply it to the desired variables. A function takes an input, defined as a placeholder within the (). This placeholder is used within the function, and we return the result with return(). Only one output can be returned:\n\ndtomean &lt;- function(x){\n  d_x &lt;- x - mean(x,na.rm = T)\n  return(d_x)\n}\n\nHow can we now apply our function dtomean() to the variables from our sat_small?\nIn principle, we saw at the beginning that a data.frame is simply a combined collection of vectors (the variables).\nAccordingly, we can now apply our dtomean() to a variable (a vector) by calling it with data.frame$variablename:\n\ndtomean(sat_small$PEO0300a)\n\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n\nTo apply our function to each variable of a data.frame, we can use lapply() - the output will then be a list, with elements named after the variable names:\n\nlapply(sat_small,FUN = dtomean)\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\nres &lt;- lapply(sat_small,FUN = dtomean)\nclass(res)\n\n[1] \"list\"\n\n\nmap() from {purrr} is an alternative to lapply:\n\nsat_small %&gt;% map(~dtomean(.x))\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\n\nThis formula syntax can also be found in across() - additionally, with .names = we have the option to modify the variable names for the results:\n\nsat_small %&gt;% \n  mutate(across(matches(\"PEO0300\"),~dtomean(.x),.names = \"dmean_{.col}\"))\n\n# A tibble: 5 × 6\n  PEO0300a PEO0300b PEO0300c dmean_PEO0300a dmean_PEO0300b dmean_PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1        2        3        2            0.6            1.6         -0.200\n2        1        1        3           -0.4           -0.4          0.8  \n3        1        1        3           -0.4           -0.4          0.8  \n4        2        1        1            0.6           -0.4         -1.2  \n5        1        1        2           -0.4           -0.4         -0.200\n\n\n\n4.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#helper-functions-ifelse-and-case_when",
    "href": "04_data_wrangle.html#helper-functions-ifelse-and-case_when",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.5 Helper functions ifelse() and case_when()",
    "text": "4.5 Helper functions ifelse() and case_when()\nifelse() is a great help for all recoding tasks: we formulate a condition and if it is met, the first value is used; if not, the second value is used. Here we check whether studs-mean(studs) is greater than 0 - if so, above is used, otherwise below:\n\ndat3 %&gt;% mutate(rel_to_mean = studs-mean(studs),\n                ab_mean_lab = ifelse(rel_to_mean &gt; 0,\"above\",\"below\"))\n\n  studs profs gegr prom_recht                uni rel_to_mean ab_mean_lab\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625       below\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625       below\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625       below\n4 14954   250 1971      FALSE          FH Aachen   -6736.625       below\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375       above\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375       above\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625       below\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375       above\n\n\ncase_when() ({dplyr}) extends this principle, allowing us to specify more than two options.\nThe syntax is slightly different: first, we specify the condition, then after a ~ the values to be used:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 ~ \"very old\",\n                                gegr &lt; 1900 ~ \"old\"))\n\n  studs profs gegr prom_recht                uni      age\n1 19173   322 1971       TRUE         Uni Bremen     &lt;NA&gt;\n2  5333    67 1830       TRUE         Uni Vechta      old\n3 15643   210 1973       TRUE      Uni Oldenburg     &lt;NA&gt;\n4 14954   250 1971      FALSE          FH Aachen     &lt;NA&gt;\n5 47269   553 1870       TRUE        RWTH Aachen      old\n6 23659   438 1457       TRUE       Uni Freiburg very old\n7  9415   150 1818       TRUE           Uni Bonn      old\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     &lt;NA&gt;\n\n\nWith TRUE, we can address all cases that have not met any conditions so far:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 ~ \"very old\",\n                                gegr &lt; 1900 ~ \"old\",\n                                TRUE ~ \"relatively new\"))\n\n  studs profs gegr prom_recht                uni            age\n1 19173   322 1971       TRUE         Uni Bremen relatively new\n2  5333    67 1830       TRUE         Uni Vechta            old\n3 15643   210 1973       TRUE      Uni Oldenburg relatively new\n4 14954   250 1971      FALSE          FH Aachen relatively new\n5 47269   553 1870       TRUE        RWTH Aachen            old\n6 23659   438 1457       TRUE       Uni Freiburg       very old\n7  9415   150 1818       TRUE           Uni Bonn            old\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg relatively new\n\n\nThis doesn’t have to be limited to one variable:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 & prom_recht  == T ~ \"very old university\",\n                                gegr &lt; 1900 & prom_recht  == T ~ \"old university\",\n                                gegr &gt; 1900 & prom_recht  == T ~ \"young university\",\n                                gegr &lt; 1900 & prom_recht  == F ~ \"old college\",\n                                gegr &gt; 1900 & prom_recht  == F ~ \"young college\"))\n\n  studs profs gegr prom_recht                uni                 age\n1 19173   322 1971       TRUE         Uni Bremen    young university\n2  5333    67 1830       TRUE         Uni Vechta      old university\n3 15643   210 1973       TRUE      Uni Oldenburg    young university\n4 14954   250 1971      FALSE          FH Aachen       young college\n5 47269   553 1870       TRUE        RWTH Aachen      old university\n6 23659   438 1457       TRUE       Uni Freiburg very old university\n7  9415   150 1818       TRUE           Uni Bonn      old university\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg       young college\n\n\n\n4.5.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#exercises",
    "href": "04_data_wrangle.html#exercises",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.6 Exercises",
    "text": "4.6 Exercises\n\n4.6.1 Exercise\n\nCreate dat3 as shown above from dat1 and dat2.\nCalculate the student-to-professor ratio (students per professor studs/profs) at the universities relative to the mean of the ratio (rel_studprofs).\nIs the ratio above or below the mean? How can you adjust the command so that the variable rel_studprofs only contains TRUE or FALSE instead of numeric values?\nConvert rel_studprofs into a dummy variable with 0/1 values instead of TRUE/FALSE.\n\n\n\n\n\n\n\nA rule of thumb to decide whether mutate() or ...$newvar &lt;- is more suitable: Whenever it’s just about quickly creating/deleting a variable, ...$newvar &lt;- is the simpler choice. When it goes beyond that, mutate() offers significant advantages (next section).\n\n\n\nBack to top\n\n\n4.6.2 Exercise\n\nContinue using the university dataset.\nCalculate the student-to-professor ratio (studprofs) relative to the mean, separated by universities with and without the right to award doctorates, and add this as a new column.\nTest both the group_by() and .by = variants.\n\nBack to top\n\n\n4.6.3 Exercise\n\nUse the pend_small dataset:\n\n\npend_small &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"welle\",\"zpsex\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"PEO0400d\")\n                               ) %&gt;% \n  filter(welle == 2) %&gt;% \n  slice(1:15)\n\n\nCalculate the mean for the variables PEO0400a, PEO0400b, PEO0400c, and PEO0400d:\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlab\n\n\n\n\nPEO0400a\nFamily/job: Woman should be willing to reduce her working hours for family\n\n\nPEO0400b\nFamily/job: What women really want is a home and children\n\n\nPEO0400c\nFamily/job: Working mother can have an equally warm relationship with her childr\n\n\nPEO0400d\nFamily/job: Responsibility of husband: To earn money; responsibility of wife: Ho\n\n\n\n\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n11     2     1        4        3        2        3\n12     2     2        2        3        2        3\n13     2     1        2        3        2        3\n14     2     1        1        2        1        1\n15     2     1        1        1        1        2\n\n\n\nUse across() to calculate the means for all four variables.\nCalculate the means separately by gender (zpsex) using .by =.\nAlso add the variance (var()), and use .names= to name the columns following the pattern metric.variable.\n\nBack to top\n\n\n4.6.4 Exercise\nContinue using pend_small:\n\npend_small\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n11     2     1        4        3        2        3\n12     2     2        2        3        2        3\n13     2     1        2        3        2        3\n14     2     1        1        2        1        1\n15     2     1        1        1        1        2\n\n\n\nStandardize the variables PEO0400a - PEO0400d from pend_small using the following pattern:\n\n\npend_small %&gt;% \n  mutate(std_PEO0400b = (PEO0400b - mean(PEO0400b,na.rm = T))/sd(PEO0400b,na.rm = T))\n\n\nUse a function so that you don’t have to repeatedly enter the same steps.\nAdditionally, use across() to apply the function to the desired variables.\n\nBack to top\n\n\n4.6.5 Exercise\n\nWork on pend_small2:\n\n\npend_small2 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                         col_select = c(\"palter\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"statakt\")) \npend_small2 &lt;- pend_small2 %&gt;% slice(5624:5640)\npend_small2\n\n# A tibble: 17 × 5\n   palter    PEO0400a                       PEO0400b          PEO0400c statakt  \n   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;                      &lt;dbl+lbl&gt;         &lt;dbl+lb&gt; &lt;dbl+lbl&gt;\n 1 77         1 [Completely agree]           3 [Rather not a…  3 [Rat… -10 [Ite…\n 2 78        -9 [Item not surveyed in wave] -9 [Item not sur… -9 [Ite… -10 [Ite…\n 3 51         2 [Rather agree]               4 [Do not agree…  1 [Com…  -9 [Ite…\n 4 23         3 [Rather not agree]           3 [Rather not a…  2 [Rat…  -9 [Ite…\n 5 17         3 [Rather not agree]           2 [Rather agree]  1 [Com…  -9 [Ite…\n 6 47         3 [Rather not agree]           2 [Rather agree]  2 [Rat…  -9 [Ite…\n 7 24         3 [Rather not agree]           4 [Do not agree…  1 [Com…   1 [In …\n 8 52         2 [Rather agree]               3 [Rather not a…  1 [Com…   1 [In …\n 9 19         2 [Rather agree]               3 [Rather not a…  2 [Rat…   3 [Pup…\n10 48         2 [Rather agree]               3 [Rather not a…  1 [Com…   1 [In …\n11 49        -9 [Item not surveyed in wave] -9 [Item not sur… -9 [Ite…  -5 [Can…\n12 47         2 [Rather agree]               3 [Rather not a…  1 [Com…  -9 [Ite…\n13 48         2 [Rather agree]               3 [Rather not a…  1 [Com…   1 [In …\n14 49        -9 [Item not surveyed in wave] -9 [Item not sur… -9 [Ite…   1 [In …\n15 39         4 [Do not agree at all]        3 [Rather not a…  1 [Com…  -9 [Ite…\n16 37         3 [Rather not agree]           4 [Do not agree…  1 [Com…  -9 [Ite…\n17 38         3 [Rather not agree]           3 [Rather not a…  1 [Com…   1 [In …\n\n\n\nUse ifelse() to label people 50 years and older as “ü50” - for those under 50, label them as “u50”.\nCreate a three-way division: people under 40 are labeled “u40”, people under 50 “u50”, and people 50 and older as “ü50”. How would you approach this with case_when()?\nUse ifelse() to overwrite values &lt; 0 in the variables PEO0400a, PEO0400b, PEO0400c, and statakt in pend_small2 with NA.\nFirst, write an ifelse() function that overwrites all values &lt; 0 in PEO0400a with NA and otherwise keeps the original value PEO0400a.\nHow would the function look if you applied it to PEO0400a, PEO0400b, PEO0400c, and statakt at the same time using across()?\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#appendix",
    "href": "04_data_wrangle.html#appendix",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.7 Appendix",
    "text": "4.7 Appendix\n\n4.7.1 Renaming variables\nTo rename variables, use rename(new_name = old_name)\n\nsat_small %&gt;% rename(newname = PEO0300a)\n\n# A tibble: 5 × 3\n  newname PEO0300b PEO0300c\n    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       2        3        2\n2       1        1        3\n3       1        1        3\n4       2        1        1\n5       1        1        2\n\n\nFor advanced transformations, it’s worth looking into rename_with(). This allows us to use Regular Expressions, for example from {stringr}. Here’s just an example:\n\nsat_small %&gt;% rename_with(~tolower(.))\n\n# A tibble: 5 × 3\n  peo0300a peo0300b peo0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\nsat_small %&gt;% rename_with(~str_remove(.x,\"PEO0300\"))\n\n# A tibble: 5 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2     3     2\n2     1     1     3\n3     1     1     3\n4     2     1     1\n5     1     1     2\n\nsat_small %&gt;% rename_with(~str_replace(.x,\"PEO0300\",\"Occupation_\"))\n\n# A tibble: 5 × 3\n  Occupation_a Occupation_b Occupation_c\n         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1            2            3            2\n2            1            1            3\n3            1            1            3\n4            2            1            1\n5            1            1            2\n\n\n\n\n4.7.2 Creating Classes with cut()\n\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\nA common task in data preparation is classifying a continuous variable, such as the number of professors. We want to group profs in steps of 150. To create these classes, we use cut() and specify the class boundaries with breaks. We can use seq() to generate the breakpoints. In seq(), we specify the lower and upper limits along with the step size.\n\ncut(dat3$profs,breaks = c(50, 200, 350, 500, 650))\n\n[1] (200,350] (50,200]  (200,350] (200,350] (500,650] (350,500] (50,200] \n[8] (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\ncut(dat3$profs,breaks = seq(50,650,150))\n\n[1] (200,350] (50,200]  (200,350] (200,350] (500,650] (350,500] (50,200] \n[8] (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\n\nWe store these values in a new variable in the dat3 dataset:\n\ndat3$prof_class &lt;- cut(dat3$profs,breaks = seq(50,650,150))\ndat3\n\n  studs profs gegr prom_recht                uni prof_class\n1 19173   322 1971       TRUE         Uni Bremen  (200,350]\n2  5333    67 1830       TRUE         Uni Vechta   (50,200]\n3 15643   210 1973       TRUE      Uni Oldenburg  (200,350]\n4 14954   250 1971      FALSE          FH Aachen  (200,350]\n5 47269   553 1870       TRUE        RWTH Aachen  (500,650]\n6 23659   438 1457       TRUE       Uni Freiburg  (350,500]\n7  9415   150 1818       TRUE           Uni Bonn   (50,200]\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  (500,650]\n\n\nFor this new variable, we can request a frequency table using count():\n\ndat3 %&gt;% count(prof_class)\n\n  prof_class n\n1   (50,200] 2\n2  (200,350] 3\n3  (350,500] 1\n4  (500,650] 2\n\n\nThe parentheses ( indicate exclusion, while the brackets ] indicate inclusion. There are 3 universities in the dataset that have more than 200 and up to 350 professors.\nFor the following examples, we delete the prof_class variable again:\n\ndat3$prof_class &lt;- NULL\n\nSome useful options for cut() in the appendix\n\nbsp &lt;- c(1990,1998,2001,2009)\nbsp\n\n[1] 1990 1998 2001 2009\n\ncut(bsp,breaks = c(1990,2000,2010)) \n\n[1] &lt;NA&gt;             (1.99e+03,2e+03] (2e+03,2.01e+03] (2e+03,2.01e+03]\nLevels: (1.99e+03,2e+03] (2e+03,2.01e+03]\n\n# Specify the number of digits in the labels\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4) \n\n[1] &lt;NA&gt;        (1990,2000] (2000,2010] (2000,2010]\nLevels: (1990,2000] (2000,2010]\n\n# Include the lower boundary\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4,include.lowest = T) \n\n[1] [1990,2000] [1990,2000] (2000,2010] (2000,2010]\nLevels: [1990,2000] (2000,2010]\n\n# Number the categories instead of labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = FALSE)\n\n[1] NA  1  2  2\n\n# Specify your own labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = c(\"90s\",\"00s\"))\n\n[1] &lt;NA&gt; 90s  00s  00s \nLevels: 90s 00s\n\n\n\n\n4.7.3 String Functions for regex\n{stringr} provides a series of very useful string functions with regular expressions. You can get an overview from this cheatsheet.\n\ndat3 %&gt;% mutate(uni_fh = str_detect(uni,\"Uni\"))\n\n  studs profs gegr prom_recht                uni uni_fh\n1 19173   322 1971       TRUE         Uni Bremen   TRUE\n2  5333    67 1830       TRUE         Uni Vechta   TRUE\n3 15643   210 1973       TRUE      Uni Oldenburg   TRUE\n4 14954   250 1971      FALSE          FH Aachen  FALSE\n5 47269   553 1870       TRUE        RWTH Aachen  FALSE\n6 23659   438 1457       TRUE       Uni Freiburg   TRUE\n7  9415   150 1818       TRUE           Uni Bonn   TRUE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  FALSE\n\ndat3 %&gt;% mutate(bula = case_when(str_detect(uni,\"Bremen\")~ \"HB\",\n                                 str_detect(uni,\"Oldenb|Vechta\")~ \"NDS\",\n                                 str_detect(uni,\"Bonn|Aachen\")~ \"NRW\",\n                                 str_detect(uni,\"Freiburg\")~ \"BW\"\n                                 ))\n\n  studs profs gegr prom_recht                uni bula\n1 19173   322 1971       TRUE         Uni Bremen   HB\n2  5333    67 1830       TRUE         Uni Vechta  NDS\n3 15643   210 1973       TRUE      Uni Oldenburg  NDS\n4 14954   250 1971      FALSE          FH Aachen  NRW\n5 47269   553 1870       TRUE        RWTH Aachen  NRW\n6 23659   438 1457       TRUE       Uni Freiburg   BW\n7  9415   150 1818       TRUE           Uni Bonn  NRW\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  NRW\n\ndat3 %&gt;% mutate(ort = str_remove(uni,\"Uni |FH |RWTH \"))\n\n  studs profs gegr prom_recht                uni             ort\n1 19173   322 1971       TRUE         Uni Bremen          Bremen\n2  5333    67 1830       TRUE         Uni Vechta          Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg       Oldenburg\n4 14954   250 1971      FALSE          FH Aachen          Aachen\n5 47269   553 1870       TRUE        RWTH Aachen          Aachen\n6 23659   438 1457       TRUE       Uni Freiburg        Freiburg\n7  9415   150 1818       TRUE           Uni Bonn            Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg Bonn-Rhein-Sieg",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#footnotes",
    "href": "04_data_wrangle.html#footnotes",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "“tilde”:  Windows: Press Alt Gr + * (The asterisk is on the same key as the plus sign).  macOS: Press Alt (Option) + N, then press the space bar to insert the tilde.↩︎\nDo not repeat yourself, see Wickham et al: “You should consider writing a function whenever you’ve copied and pasted a block of code more than twice (i.e. you now have three copies of the same code).”↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html",
    "href": "05_merge_pivot.html",
    "title": "5  Merging & reshaping",
    "section": "",
    "text": "5.1 Joining/merging data sets\nA quick illustration:1\nEs gibt natürlich auch right_join() oder anti_join(). Für eine tiefergehende Einführung lohnt sich das Kapitel Relational Data aus R for Data Science.\nEine sehr hilfreiche Option in den ..._join() ist die Verbindung unterschiedlicher Variablen. Bspw. haben wir hier einige Fälle aus der ETB18 und\nCode\nids_df &lt;-  data.frame(pnr = sample(1:9,4),\n                       Bula = c(2,1,14,15))\n\nset.seed(90459)\nalo_bula &lt;- data.frame(bundesland = seq(1:8),\n                       Werte = sample(letters,size = 8) # mit sample() kann eine zufällige Auswahl getroffen werden \n                       )\nids_df\n\n#&gt;   pnr Bula\n#&gt; 1   6    2\n#&gt; 2   4    1\n#&gt; 3   8   14\n#&gt; 4   7   15\n\nalo_bula\n\n#&gt;   bundesland Werte\n#&gt; 1          1     g\n#&gt; 2          2     m\n#&gt; 3          3     n\n#&gt; 4          4     z\n#&gt; 5          5     w\n#&gt; 6          6     r\n#&gt; 7          7     t\n#&gt; 8          8     h\n\nids_df %&gt;% left_join(alo_bula,by = c(\"Bula\"=\"bundesland\"))\n\n#&gt;   pnr Bula Werte\n#&gt; 1   6    2     m\n#&gt; 2   4    1     g\n#&gt; 3   8   14  &lt;NA&gt;\n#&gt; 4   7   15  &lt;NA&gt;\nEin sehr hilfreiche Checkmöglichkeit, die ich häufig verwende:\ntable(ids_df$Bula %in% alo_bula$bundesland)\n\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;     2     2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#join",
    "href": "05_merge_pivot.html#join",
    "title": "5  Merging & reshaping",
    "section": "",
    "text": "A mutating join allows you to combine variables from two tables. It first matches observations by their keys, then copies across variables from one table to the other.\nR for Data Science: Mutating joins\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.1 Übung",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#reshape-pivot_longer-pivot_wider",
    "href": "05_merge_pivot.html#reshape-pivot_longer-pivot_wider",
    "title": "5  Merging & reshaping",
    "section": "5.2 Reshape: pivot_longer() & pivot_wider()",
    "text": "5.2 Reshape: pivot_longer() & pivot_wider()\n\nbsp_df &lt;- \n  data.frame(\n    bula    = c(\"NRW\",\"NDS\"),\n    alo2018 = c(2,2),\n    alo2017 = c(1,1)\n    )\n\nbsp_df\n\n#&gt;   bula alo2018 alo2017\n#&gt; 1  NRW       2       1\n#&gt; 2  NDS       2       1\n\n\nMit pivot_longer() können wir aus einem wide shape data.frame einen long shape machen:\n\nbsp_df %&gt;% pivot_longer(cols = c(\"alo2018\",\"alo2017\"),names_to = \"year\",values_to = \"alo\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   bula  year      alo\n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 NRW   alo2018     2\n#&gt; 2 NRW   alo2017     1\n#&gt; 3 NDS   alo2018     2\n#&gt; 4 NDS   alo2017     1\n\n\nMit names_prefix = \"alo\" können wir das alo direkt löschen lassen:\n\nbsp_df %&gt;% pivot_longer(cols = c(\"alo2018\",\"alo2017\"),names_to = \"year\",values_to = \"alo\",names_prefix = \"alo\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   bula  year    alo\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 NRW   2018      2\n#&gt; 2 NRW   2017      1\n#&gt; 3 NDS   2018      2\n#&gt; 4 NDS   2017      1\n\n\nMit pivot_wider() können wir den umgekehrten Weg gehen:\n\nbsp_df2 &lt;- \n  data.frame(land = c(\"NRW\",\"NDS\",\"NRW\",\"NDS\"),\n             alo = c(2.1,1.8,2.4,2.2),\n             alter = c(\"age_1825\",\"age_1825\",\"age_2630\",\"age_2630\"))\nbsp_df2\n\n#&gt;   land alo    alter\n#&gt; 1  NRW 2.1 age_1825\n#&gt; 2  NDS 1.8 age_1825\n#&gt; 3  NRW 2.4 age_2630\n#&gt; 4  NDS 2.2 age_2630\n\n\n\nbsp_df2 %&gt;% pivot_wider(names_from = alter,values_from = alo)\n\n#&gt; # A tibble: 2 × 3\n#&gt;   land  age_1825 age_2630\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 NRW        2.1      2.4\n#&gt; 2 NDS        1.8      2.2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#übungen",
    "href": "05_merge_pivot.html#übungen",
    "title": "5  Merging & reshaping",
    "section": "5.3 Übungen",
    "text": "5.3 Übungen\n\n5.3.1 Übung 1\nVerknüpfen Sie die ausgewählten Beobachtungen des PASS CF mit der Haushalts-Information, in welcher Region (region) die Befragten wohnen. Mergen Sie dazu die region aus HHENDDAT_cf_W13.dta basierend auf der hnr und welle.\n\npend_ue11 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                             col_select = c(\"pnr\",\"welle\")) %&gt;%\n  slice(1:10)\n\npend_ue11\n\n#&gt; # A tibble: 10 × 2\n#&gt;           pnr welle                 \n#&gt;         &lt;dbl&gt; &lt;dbl+lbl&gt;             \n#&gt;  1 1000001901 1 [Wave 1 (2006/2007)]\n#&gt;  2 1000001902 1 [Wave 1 (2006/2007)]\n#&gt;  3 1000001901 3 [Wave 3 (2008/2009)]\n#&gt;  4 1000002001 1 [Wave 1 (2006/2007)]\n#&gt;  5 1000002002 1 [Wave 1 (2006/2007)]\n#&gt;  6 1000002002 2 [Wave 2 (2007/2008)]\n#&gt;  7 1000002001 2 [Wave 2 (2007/2008)]\n#&gt;  8 1000002002 3 [Wave 3 (2008/2009)]\n#&gt;  9 1000002001 3 [Wave 3 (2008/2009)]\n#&gt; 10 1000002001 4 [Wave 4 (2010)]\n\nhh_dat &lt;- haven::read_dta(\"./orig/HHENDDAT_cf_W13.dta\", col_select = c(\"hnr\",\"welle\",\"region\"))\n\n\n\n5.3.2 Übung 2\n\npend_ue11b &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                             col_select = c(\"pnr\",\"welle\",\"famstand\")) %&gt;%\n  slice(200:210) %&gt;% \n  filter(welle %in% 2:3)\n\n\npend_ue11b\n\n#&gt; # A tibble: 6 × 3\n#&gt;          pnr welle                  famstand                                    \n#&gt;        &lt;dbl&gt; &lt;dbl+lbl&gt;              &lt;dbl+lbl&gt;                                   \n#&gt; 1 1000014501 2 [Wave 2 (2007/2008)] -4 [Question mistakenly not asked]          \n#&gt; 2 1000014501 3 [Wave 3 (2008/2009)]  3 [Married/civil partnership, not living t…\n#&gt; 3 1000014701 2 [Wave 2 (2007/2008)]  2 [Married/civil partnership, living toget…\n#&gt; 4 1000014702 2 [Wave 2 (2007/2008)]  2 [Married/civil partnership, living toget…\n#&gt; 5 1000014702 3 [Wave 3 (2008/2009)]  2 [Married/civil partnership, living toget…\n#&gt; 6 1000014701 3 [Wave 3 (2008/2009)]  2 [Married/civil partnership, living toget…\n\n\nBringen Sie pend_ue11b in das long shape:\n\n\n#&gt; # A tibble: 3 × 3\n#&gt;          pnr `2`                                             `3`                \n#&gt;        &lt;dbl&gt; &lt;dbl+lbl&gt;                                       &lt;dbl+lbl&gt;          \n#&gt; 1 1000014501 -4 [Question mistakenly not asked]              3 [Married/civil p…\n#&gt; 2 1000014701  2 [Married/civil partnership, living together] 2 [Married/civil p…\n#&gt; 3 1000014702  2 [Married/civil partnership, living together] 2 [Married/civil p…\n\n\nTipp: mit ,names_prefix = \"wave\" in pivot_wider() können wir ein Präfix angeben:\n\n\n#&gt; # A tibble: 3 × 3\n#&gt;          pnr wave2                                           wave3              \n#&gt;        &lt;dbl&gt; &lt;dbl+lbl&gt;                                       &lt;dbl+lbl&gt;          \n#&gt; 1 1000014501 -4 [Question mistakenly not asked]              3 [Married/civil p…\n#&gt; 2 1000014701  2 [Married/civil partnership, living together] 2 [Married/civil p…\n#&gt; 3 1000014702  2 [Married/civil partnership, living together] 2 [Married/civil p…",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#footnotes",
    "href": "05_merge_pivot.html#footnotes",
    "title": "5  Merging & reshaping",
    "section": "",
    "text": "Using tidyexplain↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html",
    "href": "06_labels_factor.html",
    "title": "6  Labels & factors",
    "section": "",
    "text": "6.1 Labels from Other Programs in R\nIn many software packages like Stata or SPSS, labels are often retained through various operations and then displayed automatically. This is not the case in R. Instead, in R, we can assign labels using the factor variable type. This approach might seem unusual for those who have worked extensively with Stata or SPSS, but it is quite useful in practice if you get accustomed to the workflow.\nGenerally, you can use value labels from other software packages in are. For example, when we create a count summary with count(), the labels from the .dta-file are displayed:\n# Counting occurrences and showing labels\npend_kap5 %&gt;% \n  count(PSM0100)\n\n# A tibble: 3 × 2\n  PSM0100                            n\n  &lt;dbl+lbl&gt;                      &lt;int&gt;\n1 -5 [Does not use the internet]    28\n2  1 [Yes]                         318\n3  2 [No]                          337\nThese are assigned as attributes() variables:\nattributes(pend_kap5$PSM0100)\n\n$label\n[1] \"Usage of social networks\"\n\n$format.stata\n[1] \"%39.0f\"\n\n$labels\nItem not surveyed in wave Does not use the internet           Details refused \n                       -9                        -5                        -2 \n               Don't know                       Yes                        No \n                       -1                         1                         2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"\nenframe() from the {tibble} (part of the {tidyverse}) package helps to get data.frame with an overview of all value labels stored in an attribute:\nattributes(pend_kap5$PSM0100)$labels %&gt;% enframe(value = \"variable_value\",name = \"label\")\n\n# A tibble: 6 × 2\n  label                     variable_value\n  &lt;chr&gt;                              &lt;dbl&gt;\n1 Item not surveyed in wave             -9\n2 Does not use the internet             -5\n3 Details refused                       -2\n4 Don't know                            -1\n5 Yes                                    1\n6 No                                     2\nHowever, managing attributes() is tedious and sometimes causes problems when working with the labelled variables.\nR’s native way to work with labels are factor variables. As mentioned in chapter 2, factor variables are strings with a predefined universe and ordering.\nHow can we use the attributes()-labels as factor to save typing?\n{haven} includes the function as_factor1, which allows us to directly create a factor variable from labels:\npend_kap5$PSM0100_fct &lt;- as_factor(pend_kap5$PSM0100) # create factor variable from attributes and values\n\n# view:\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 2\n  PSM0100                        PSM0100_fct              \n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                    \n1  2 [No]                        No                       \n2  1 [Yes]                       Yes                      \n3  2 [No]                        No                       \n4 -5 [Does not use the internet] Does not use the internet\n5 -5 [Does not use the internet] Does not use the internet\n6 -5 [Does not use the internet] Does not use the internet",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#creating-or-editing-factor-manually",
    "href": "06_labels_factor.html#creating-or-editing-factor-manually",
    "title": "6  Labels & factors",
    "section": "6.2 Creating or editing factor manually",
    "text": "6.2 Creating or editing factor manually\nAlternatively, we can also label with factor() using the levels and labels options ourselves. The labels are assigned in order to the numbers from levels. Additionally, all unspecified levels automatically become NA:\n\npend_kap5$PSM0100_fct2 &lt;- factor(pend_kap5$PSM0100,\n                               levels = c(1,2),\n                               labels = c(\"Yes\",\"No\"))\n\n# view:\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 3\n  PSM0100                        PSM0100_fct               PSM0100_fct2\n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                     &lt;fct&gt;       \n1  2 [No]                        No                        No          \n2  1 [Yes]                       Yes                       Yes         \n3  2 [No]                        No                        No          \n4 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n5 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n6 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n\n\nOr we can use the functions from {forcats} to recode a factor. {forcats} is part of the {tidyverse}. With fct_recode(), we can change the levels:\n\nlevels(pend_kap5$PSM0100_fct)\n\n[1] \"Item not surveyed in wave\" \"Does not use the internet\"\n[3] \"Details refused\"           \"Don't know\"               \n[5] \"Yes\"                       \"No\"                       \n\npend_kap5$PSM0100_fct3 &lt;- fct_recode(pend_kap5$PSM0100_fct,\n  `Uses social networks` =  \"Ja\", # use `` around words with spaces\n  )\n\nWarning: Unknown levels in `f`: Ja\n\nlevels(pend_kap5$PSM0100_fct3)\n\n[1] \"Item not surveyed in wave\" \"Does not use the internet\"\n[3] \"Details refused\"           \"Don't know\"               \n[5] \"Yes\"                       \"No\"                       \n\n\n\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 4\n  PSM0100                        PSM0100_fct           PSM0100_fct2 PSM0100_fct3\n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                 &lt;fct&gt;        &lt;fct&gt;       \n1  2 [No]                        No                    No           No          \n2  1 [Yes]                       Yes                   Yes          Yes         \n3  2 [No]                        No                    No           No          \n4 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n5 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n6 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n\n\nMore fct_....() functions from {forcats} can be found in this Cheatsheet.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#creating-label-data.frame-and-merging-with-data",
    "href": "06_labels_factor.html#creating-label-data.frame-and-merging-with-data",
    "title": "6  Labels & factors",
    "section": "6.3 Creating label data.frame and merging with data",
    "text": "6.3 Creating label data.frame and merging with data\nAn alternative approach involves creating a small label data.frame and left_join() (more on left_join() later.)\n\ntab2 &lt;- pend_kap5 %&gt;% count(PSM0100)\ntab2\n\n# A tibble: 3 × 2\n  PSM0100                            n\n  &lt;dbl+lbl&gt;                      &lt;int&gt;\n1 -5 [Does not use the internet]    28\n2  1 [Yes]                         318\n3  2 [No]                          337\n\n\n\nlab_df &lt;- data.frame(PSM0100=1:2)\nlab_df\n\n  PSM0100\n1       1\n2       2\n\nlab_df$PD0400_lab &lt;- factor(lab_df$PSM0100,\n                            levels = 1:2,\n                            labels = c(\"Uses social networks\",\n                                       \"Does not use social networks\"))\nlab_df\n\n  PSM0100                   PD0400_lab\n1       1         Uses social networks\n2       2 Does not use social networks\n\n\n\ntab2 %&gt;% \n  left_join(lab_df,by = \"PSM0100\")\n\n# A tibble: 3 × 3\n  PSM0100                            n PD0400_lab                  \n  &lt;dbl+lbl&gt;                      &lt;int&gt; &lt;fct&gt;                       \n1 -5 [Does not use the internet]    28 &lt;NA&gt;                        \n2  1 [Yes]                         318 Uses social networks        \n3  2 [No]                          337 Does not use social networks\n\n\n…or if you have multiple variables, create an Excel sheet and merge it:\n\n  pend_kap5 %&gt;% \n    select(zpsex,PSM0100) %&gt;% \n    distinct() %&gt;%  \n    pivot_longer(cols = everything()) %&gt;% \n    distinct() %&gt;% \n    arrange(name,value) %&gt;% \n  data.frame() %&gt;% \n  xlsx::write.xlsx(file = \"./data/label.xlsx\",row.names = F)\n\nWarning: `zpsex` and `PSM0100` have conflicting value labels.\nℹ Labels for these values will be taken from `zpsex`.\n✖ Values: 1 and 2\n\nlab_df2 &lt;- \n  xlsx::read.xlsx(file = \"./data/label_read.xlsx\",sheetIndex = 1)\n\n\npend_kap5 %&gt;% \n    count(zpsex,PSM0100) \n\n# A tibble: 6 × 3\n  zpsex      PSM0100                            n\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                      &lt;int&gt;\n1 1 [Male]   -5 [Does not use the internet]    13\n2 1 [Male]    1 [Yes]                         150\n3 1 [Male]    2 [No]                          161\n4 2 [Female] -5 [Does not use the internet]    15\n5 2 [Female]  1 [Yes]                         168\n6 2 [Female]  2 [No]                          176\n\nlab_df2 %&gt;% pivot_wider(names_from = name)\n\n# A tibble: 5 × 3\n  label                     PSM0100 zpsex\n  &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt;\n1 &lt;NA&gt;                      -5      &lt;NA&gt; \n2 Uses Social Media         1       &lt;NA&gt; \n3 Does not use social media 2       &lt;NA&gt; \n4 Men                       &lt;NA&gt;    1    \n5 Women                     &lt;NA&gt;    2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#exercise",
    "href": "06_labels_factor.html#exercise",
    "title": "6  Labels & factors",
    "section": "6.4 Exercise",
    "text": "6.4 Exercise\n\npend_ue5 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"pnr\",\"welle\",\"PD0400\")) %&gt;% \n  filter(PD0400&gt;0)\n\nEdit the value labels of PD0400: Religiousness, self-rating\n\n\nvaluelabel1Not at all religious2Rather not religious3Rather religious4Very religious\n\n\n\nFirst, use head() and a count with count() to get an overview.\nHow can you use the labels from the attributes() with as_factor() to create a variable PD0400_fct?\nCreate a factor() variable F411_01_fct2 with value labels: 1 = Not at all, 2 = Rather not, 3 = Rather yes, 4 = Very much\n\nBonus exercise: Use the labeled variable for a bar chart.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#appendix",
    "href": "06_labels_factor.html#appendix",
    "title": "6  Labels & factors",
    "section": "6.5 Appendix",
    "text": "6.5 Appendix\n\n6.5.1 Remove labels with zap_... from {haven}\nThe label attributes() often cause problems in further processing. With haven::zap_labels(), we can remove value labels from a dataset, and with haven::zap_label(), we can remove variable labels.\n\npend_kap5\n\n# A tibble: 683 × 6\n          pnr welle             zpsex      PSM0100                 azges1 palter\n        &lt;dbl&gt; &lt;dbl+lbl&gt;         &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;               &lt;dbl+&gt; &lt;dbl+&gt;\n 1 1000002601 8 [Wave 8 (2014)] 2 [Female]  2 [No]                 22     34    \n 2 1000010402 8 [Wave 8 (2014)] 2 [Female]  1 [Yes]                40     30    \n 3 1000019102 8 [Wave 8 (2014)] 1 [Male]    2 [No]                 40     34    \n 4 1000031403 8 [Wave 8 (2014)] 1 [Male]   -5 [Does not use the i… 44     52    \n 5 1000032801 8 [Wave 8 (2014)] 2 [Female] -5 [Does not use the i… 44     58    \n 6 1000032802 8 [Wave 8 (2014)] 1 [Male]   -5 [Does not use the i… 43     62    \n 7 1000038201 8 [Wave 8 (2014)] 1 [Male]    1 [Yes]                43     61    \n 8 1000040003 8 [Wave 8 (2014)] 1 [Male]    2 [No]                 36     40    \n 9 1000051801 8 [Wave 8 (2014)] 2 [Female]  2 [No]                 31     44    \n10 1000053101 8 [Wave 8 (2014)] 1 [Male]    1 [Yes]                27     47    \n# ℹ 673 more rows\n\npend_kap5 %&gt;% \n  haven::zap_labels() # remove value labels\n\n# A tibble: 683 × 6\n          pnr welle zpsex PSM0100 azges1 palter\n        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 1000002601     8     2       2     22     34\n 2 1000010402     8     2       1     40     30\n 3 1000019102     8     1       2     40     34\n 4 1000031403     8     1      -5     44     52\n 5 1000032801     8     2      -5     44     58\n 6 1000032802     8     1      -5     43     62\n 7 1000038201     8     1       1     43     61\n 8 1000040003     8     1       2     36     40\n 9 1000051801     8     2       2     31     44\n10 1000053101     8     1       1     27     47\n# ℹ 673 more rows\n\n\n\n\n6.5.2 Creating labels in R and exporting to Stata\nIf we want to label a dataset for Stata, for example, {labelled} comes in handy again:\n\nlibrary(labelled)\n\nError in library(labelled): es gibt kein Paket namens 'labelled'\n\n\n\npend_kap5$zpsex_num2 &lt;- as.numeric(pend_kap5$zpsex)\nattributes(pend_kap5$zpsex_num2)\n\nNULL\n\nval_labels(pend_kap5$zpsex_num2) &lt;- c(\"Men\"=1,\"Women\"=2)\n\nError in val_labels(pend_kap5$zpsex_num2) &lt;- c(Men = 1, Women = 2): konnte Funktion \"val_labels&lt;-\" nicht finden\n\nattributes(pend_kap5$zpsex_num2)\n\nNULL\n\npend_kap5 %&gt;% count(zpsex_num2)\n\n# A tibble: 2 × 2\n  zpsex_num2     n\n       &lt;dbl&gt; &lt;int&gt;\n1          1   324\n2          2   359\n\n\n\npend_kap5 %&gt;% \n  select(zpsex_num2) %&gt;% \n  haven::write_dta(.,path = \"./data/pend_kap5.dta\")\n\n…in Stata:\n\nuse \"./data/pend_kap5.dta\" \ntab zpsex_num2 \n\n(PASS V3, 2006-2019, 21 Jul 2021, PENDDAT)\n\n\n zpsex_num2 |      Freq.     Percent        Cum.\n------------+-----------------------------------\n     Männer |        324       47.44       47.44\n     Frauen |        359       52.56      100.00\n------------+-----------------------------------\n      Total |        683      100.00\n\n\nMore on labels in {labelled}.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#footnotes",
    "href": "06_labels_factor.html#footnotes",
    "title": "6  Labels & factors",
    "section": "",
    "text": "Not to be confused with as.factor() from base R – the _ makes a difference!↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html",
    "href": "06_viz_translated.html",
    "title": "7  Visualization with {ggplot2}",
    "section": "",
    "text": "7.1 ggplot2 and the Grammar of Graphics\nggplot2 is the implementation of the concept of “layered grammar of graphics” in R. The idea of this visualization system is to break down data visualization into parameters: the underlying dataset, the variables to be displayed, the choice of display shapes, the coordinate system, scales, and statistical transformations. A standard command in ggplot2 looks something like this:\nggplot(data = dataset, aes(x = var1, y = var2, color = var3)) +\n  geom_point() +\n  labs(title= \"Title\", subtitle = \"Subtitle\") +\n  theme_minimal()\nSo we first call up a plot with ggplot(). Further arguments then define additional aspects:\nNow we will work through the individual layers of the graphic:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#ggplot2-and-the-grammar-of-graphics",
    "href": "06_viz_translated.html#ggplot2-and-the-grammar-of-graphics",
    "title": "7  Visualization with {ggplot2}",
    "section": "",
    "text": "With data =, we specify the data.frame we want to visualize.\nThe aesthetics aes() specify which variables are to be displayed: here var1 on the x-axis, var2 on the y-axis, and var3 for coloring.\nThe layers geom_.. specify the type of display, e.g., geom_point() for point plots and geom_bar() for bar charts.\nWith labs, we can add labels, such as a title or axis labels.\nThe themes theme_... set the design of the graphic, e.g., black and white axes and background colors with theme_bw().\n\n\n\n7.1.1 data =\nIn data =, we specify the data.frame that contains the information to be visualized. We start our ggplot with:\n\nggplot(data = pend_small)\n\n\n\n\n\n\n\n\n\n\n7.1.2 aes\nWe want to visualize these values in a scatterplot, with age on the x-axis and weekly working hours on the y-axis:\n\nggplot(data = pend_small, aes(x = palter, y = azges1))\n\n\n\n\n\n\n\n\n\n\n7.1.3 geom\nIf we only provide these details, we will get an empty coordinate system—why? Because we haven’t yet specified what form of display we want. For this, we must specify a geom_, such as geom_col() for bar charts, which we attach to the ggplot command with +:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point()\n\n\n\n\n\n\n\n\nWith color =, we can also change the color of the points:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point(color = \"orange\")\n\n\n\n\n\n\n\n\nHere is an overview of all color names that are recognized, though there are many more colors—see Appendix.\n\n\n7.1.4 aes() Part II\nThis already looks pretty good, but the points are not yet separated by gender. To do this, we need to include the gender information (zpsex) in aes(). In addition to the axes, aes() also specifies the variables for the appearance of the geom_s—this can include not only color but also shape, size, or transparency. Here’s an overview.\nGender should determine the color of the points, which we can specify in aes with color:\n\n# results in an error due to labels:\nggplot(data = pend_small, aes(x = palter, y = azges1, color = zpsex )) + \n  geom_point()\n\nError in UseMethod(\"rescale\"): nicht anwendbare Methode für 'rescale' auf Objekt der Klasse \"c('haven_labelled', 'vctrs_vctr', 'double')\" angewendet\n\n\nA numeric variable for color = results in a color gradient, while a factor/character variable results in a discrete color scale:\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.numeric(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.character(zpsex))) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also specify custom colors with scale_color_manual1, and a list of possible colors can be found here.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"))\n\n\n\n\n\n\n\n\n\n\n7.1.5 Labels\nWith the breaks and labels options, we can also edit the legend labels. To do this, we first specify the levels of the gender variable in breaks and then the corresponding labels in the same order:\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\n\n\n\n\n\n\n\n\nFinally, we adjust the labels with labs, where we have the following options:\n\ntitle: Title for the graphic\nsubtitle: Subtitle for the title\ncaption: Annotation below the graphic\nx: x-axis label\ny: y-axis label\nfill: Legend label when fill is specified in aes()\ncolor: Legend label when color is specified in aes()\nlinetype: Legend label when linetype is specified in aes()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#combination-of-all-options",
    "href": "06_viz_translated.html#combination-of-all-options",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.2 Combination of all options",
    "text": "7.2 Combination of all options\n\nggplot(data = pend_small, aes(x = palter, y = azges1, \n                               shape = as.factor(zpsex),\n                               color = as.factor(zpsex))) + \n  geom_point(size = 4) + \n  scale_color_manual(values = c(\"lightskyblue\",\"orange\"),\n                     breaks = c(1,2), labels = c(\"Men\", \"Women\")\n                     ) +\n  scale_shape_manual(values = c(18,20),\n                     breaks = c(1,2), labels = c(\"Men\", \"Women\")\n                     ) +\n  labs(color = \"Gender\", \n       shape = \"Gender\",\n       y = \"Hours/Week\",\n       x = \"Age\",\n       title = \"Working hours and age\",\n       subtitle = \"By Gender\",\n       caption = \"Soruce: PASS CF 0619\"\n       ) \n\n\n\n\n\n\n\n\nÜbersicht zu shapes",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#visualizing-distributions",
    "href": "06_viz_translated.html#visualizing-distributions",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.3 Visualizing distributions",
    "text": "7.3 Visualizing distributions\nWith the following syntax we can create a boxplot using ggplot2. Since we are only considering one variable, we only need to specify y = or x = depending on whether the box should be oriented vertically or horizontally.\nggplot(data = pend_small, aes(y = azges1)) + geom_boxplot()\nggplot(data = pend_small, aes(x = azges1)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also create separate boxplots for men and women by specifying a variable for the other axis:\n\nggplot(data = pend_small, aes(y = azges1, x = factor(zpsex))) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n7.3.1 Histogram\nWe can also describe distributions using a histogram using the geom_histogram() function. If we want to change the color, fill = is the correct option instead of color =:\nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram()  \nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram(fill = \"sienna1\")  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo split the histogram by gender, we can again specify fill as an aesthetic. With position = position_dodge(), we can place the bars side by side:\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram() \nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe scale_...manual commands still work here, but as scale_fill_manual instead of scale_color_manual:\n\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) +\n  scale_fill_manual(values = c(\"sienna1\",\"dodgerblue4\"),\n                    breaks = 1:2, labels = c(\"Männer\",\"Frauen\")) +\n  labs(fill = \"Geschlecht\")\n\n\n\n\n\n\n\n\n\n\n7.3.2 Exercise",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#categorical-features",
    "href": "06_viz_translated.html#categorical-features",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.4 Categorical Features",
    "text": "7.4 Categorical Features\nNext, we’ll look at a way to visualize the contingency table from Chapter 2:\n\npend_small$PD0400[pend_small$PD0400&lt;0] &lt;- NA # exclude missings\npend_small %&gt;% \n  count(zpsex, PD0400) \n\n# A tibble: 10 × 3\n   zpsex         PD0400                              n\n   &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt;                       &lt;int&gt;\n 1 1 [Maennlich]  1 [Ueberhaupt nicht religioes]    40\n 2 1 [Maennlich]  2 [Eher nicht religioes]          41\n 3 1 [Maennlich]  3 [Eher religioes]                49\n 4 1 [Maennlich]  4 [Sehr religioes]                22\n 5 1 [Maennlich] NA                                780\n 6 2 [Weiblich]   1 [Ueberhaupt nicht religioes]    26\n 7 2 [Weiblich]   2 [Eher nicht religioes]          34\n 8 2 [Weiblich]   3 [Eher religioes]                40\n 9 2 [Weiblich]   4 [Sehr religioes]                16\n10 2 [Weiblich]  NA                                816\n\n\nWith geom_bar(), we can create bars by setting the height as the count of observations with ..count.. for y:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = ..count..)) +\n  geom_bar(position = position_dodge()) \n\n\n\n\n\n\n\n\nHow do we get relative frequencies? We adjust our aes to y = (..count..)/sum(..count..). With scale_y_continuous(labels = scales::label_percent(accuracy = 1)), we can also display percentages on the y-axis. To create a bar chart instead of a column chart, simply swap x and y and adjust the percentage labels using scale_x_continuous:\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = (..count..)/sum(..count..) )) +\n  geom_bar(position = position_dodge()) +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1)) \npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(y = as_factor(PD0400), fill = factor(zpsex),\n                       x = (..count..)/sum(..count..) )) +\n  geom_bar(position = position_dodge()) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese charts can also be customized with scale_... and labeled in detail using labs()—all options are consistent across different types of visualizations. Additionally, we can label the categories ourselves with breaks = and labels = if we don’t like the default labels:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(y = PD0400, fill = factor(zpsex),\n                       x = (..count..)/sum(..count..) )) +\n  geom_bar(position=position_dodge()) +\n  scale_fill_manual(values = c(\"navajowhite\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\")) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  scale_y_continuous(breaks = 1:4, \n                     labels = c(\"Überhaupt nicht\",\n                                \"Eher nicht\",\n                                \"Eher schon\",\n                                \"Sehr\")) +\n  labs(title = \"Religiösität nach Geschlecht\",\n       subtitle = \"Relative Häufigkeiten\",\n       caption = \"Quelle: PASS-CF 0619\",\n       y = \"Religiösität\",\n       x = \"Relative Häufigkeit\",\n       fill = \"Geschlecht\" ) \n\n\n\n\n\n\n\n\n\n7.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#exercises",
    "href": "06_viz_translated.html#exercises",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.5 Exercises",
    "text": "7.5 Exercises\nFor all tasks, use the first 150 observations (pend_small) to keep the plot simple. Remember to exclude missing values with filter(); you can use the following command:\n\npend &lt;- \n  haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\", \n    col_select = c(\"zpsex\", \"welle\", \"bilzeit\", \"PA0445\", \"PG1270\", \"PEO0400c\")\n  )\n\n\n7.5.1 Exercise 1\n\npend_u41 &lt;- \n  pend %&gt;% \n  filter(welle == 13, bilzeit &gt; 0, PA0445 &gt; 0) \n\n\nCreate a scatter plot for the variables “Duration of total unemployment experience in months” (PA0445, y-axis) and “Duration of education” (bilzeit, x-axis).\nSet the color to differentiate between men and women (zpsex).\nChange the colors to goldenrod1 and dodgerblue4 (or any other from this list).\nLabel the axes and legend!\n\nBack to top\n\n\n7.5.2 Exercise 2\n\npend_u42 &lt;- \n  pend %&gt;% \n  filter(welle == 9, PG1270 &gt; 0) \n\n\nCreate a boxplot or histogram for the distribution of the number of cigarettes and cigarillos smoked per day (in the last week) (PG1270).\nCustomize this graphic so that the distributions for men and women are shown separately.\nHow can you also set the colors based on gender? (Remember color = and fill =).\nChange the bar colors using scale_fill_manual, scale_fill_brewer, or scale_fill_viridis (see the sections Colors, ColorBrewer, and viridis under “other options”).\n\nBack to top\n\n\n7.5.3 Exercise 3\n\npend_u43 &lt;- \n  pend %&gt;% \n  filter(welle == 11, PEO0400c &gt; 0) \n\n\nCreate a bar chart for the responses to the question, “A working mother can have just as close a relationship with her children as a mother who is not employed.” (PEO0400c).\nCreate a bar chart for PEO0400c separated by the migration variable, so set the bar colors based on migration. The migration variable captures whether the respondents have a migration background:\n\n\n\nVariablevaluelabel`PEO0400c`1Stimme voll und ganz zu2Stimme eher zu3Stimme eher nicht zu4Stimme ueberhaupt nicht zu`migration`1Kein Migrationshintergrund2selbst / mind. 1 Elternteil zugezogen3Mind. 1 Elternteil zugezogen4Mind. 1 Grosselt. zugez., Elt. in D geb.\n\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#more-options-for-ggplot2",
    "href": "06_viz_translated.html#more-options-for-ggplot2",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.6 More options for {ggplot2}",
    "text": "7.6 More options for {ggplot2}\n\n7.6.1 Aesthetics\n\n\n\n\n\n\n\n\n\n\n\n7.6.2 themes\nWith so-called themes, we can change the layout of the graphic. Other themes include theme_light(), theme_classic(), or theme_void(). A full list can be found here. Additionally, the {ggthemes} package (install.packages('ggthemes')) offers a wide selection.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) + \n  theme_minimal()\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) +\n  theme_dark()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.6.3 Farben\n\np1 &lt;- ggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 3) \n\nNeben den im Beispiel verwendeten Farben für fill können natürlich auch noch unzählige weitere Farben in scale_fill_manual und scale_color_manual verwendet werden:\n\nHier findet sich eine Übersicht mit allen Farbnamen, die verstanden werden\nAlternativ können auch sog. HEX-Codes angeben werden, die bspw. mit dem Adobe Color Wheel oder Color Hex erstellt werden können.\n\np1 +  scale_color_manual(values = c(\"dodgerblue4\",\"sienna1\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\np1 +  scale_color_manual(values = c(\"#005b96\",\"#6497b1\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.6.3.1 ColorBreweR\nAlternativ zur manuellen Auswahl der Farben mit scale_fill_manual und scale_color_manual können mit scale_fill_brewer() auch vorgegebene Farbpaletten des colorbrewer verwendet werden. Dazu muss lediglich scale_fill_brewer() anstelle von scale_fill_manual angeben werden und statt values eine der Paletten - eine Übersicht findet sich hier. Die Farbpaletten von ColorBreweR sind alle in ggplot2 integriert.\n\np1 +\n  scale_color_brewer(palette = \"RdYlBu\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n7.6.3.2 viridis\nAnalog dazu gibt es auch die {viridis}-Paletten, welche durchgängig “colorblind-safe” und ebenfalls in {ggplot2} integriert sind. Allerdings ist hier zu beachten, dass für Farbauswahlen basierend auf einer kategorialen Variable scale_color_viridis_d() zu verwenden ist. Soll die Farbe entlang einer numerischen/metrischen Variable bestimmt werden, dann ist scale_color_viridis_c() zu verwenden. Außerdem kann mit begin und end die Breite der Farbskala angepasst werden:\np1 +\n  scale_color_viridis_d(option=\"magma\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \np1 +\n  scale_color_viridis_d(option=\"magma\",begin = .65,end = .85,\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.6.3.3 Weitere Farbpaletten\nDarüber hinaus gibt es unzählige Pakete, die ebenfalls scale_color_ und scale_fill_-Funktionen bieten: Hier noch zwei Beispiele mit {scico} und {MetBrewer}, welches Farben aus Bildern im Metropolitan Museum of Art enthält:\n\ninstall.packages('scico')\ninstall.packages(\"MetBrewer\")\n\n{scico} Farbpaletten\n\n\n\n\n\n\n\n\n\n{MetBrewer} Farbpaletten\n\n\n\n\n\n\n\n\n\nlibrary(scico)\np1 +\n  scale_color_scico_d(palette = \"oslo\",begin = .5,end = .8,\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \nlibrary(MetBrewer)\np1 +\n  scale_color_met_d(name = \"Kandinsky\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparable packages also exist for:\n\n{DutchMasters} - Color palettes from paintings by Dutch masters.\n{wesanderson} - Color palettes based on various Wes Anderson films (e.g., The Grand Budapest Hotel).\n{ochRe} - Color palettes “inspired by Australian art, landscapes, and wildlife.”\n{paletteer} offers a vast selection of various color palettes.\n\nCheck out the interactive color picker here\n\n\n\n7.6.4 Shapes\n\n\n\n\n\n\n\n\n\nZusätzlicher Überblick\n\n\n7.6.5 Linetypes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\n\n\nShapes und Linetypes at a glance in the R Cookbook",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#useful-links",
    "href": "06_viz_translated.html#useful-links",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.7 Useful links",
    "text": "7.7 Useful links\n\nThe Graphs chapter of the R Cookbook is an excellent resource for various options and a basic overview—for example, on adjusting the legend, line and point types, or the axes.\nAdjusting font size and color: This guide provides a good overview of how to modify font size and color in {ggplot2}.\nFrom Data to Viz offers a decision tree for various relationships and descriptions with example syntax.\n\n\n\n\n\n\n\n\n\n\n\nThe R Graph Gallery is even more extensive and offers additional visualization ideas.\nFor those who want to learn more about effective (and beautiful) data visualizations with {ggplot2}, Cédric Scherer’s tutorial is an excellent introduction. This workshop is great for further exploration.\nThis workshop offers additional insights on how to make data visualizations more appealing with {ggplot2}.\nA list of extensions for ggplot2.\nThe book on {ggplot2}.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "06_viz_translated.html#footnotes",
    "href": "06_viz_translated.html#footnotes",
    "title": "7  Visualization with {ggplot2}",
    "section": "",
    "text": "If we had specified color in aes, the corresponding command would be scale_color_manual.↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "09_reg.html",
    "href": "09_reg.html",
    "title": "8  Regressionsmodelle",
    "section": "",
    "text": "8.1 Regressionsmodelle mit lm()\nRegressionsmodelle in R lassen sich mit lm() erstellen. Hier geben wir das Merkmal an, dass auf der y-Achse liegt (die abhängige Variable) und nach einer ~ das Merkmal für die x-Achse (unabhängige Variable). Die Interpretation des Ergebnisses wird uns die kommenden Wochen beschäftigen.\nlm(var2~ var1, data = dat1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839\nDer Wert unter var1 gibt an, um wieviel sich die Gerade pro “Schritt nach rechts” nach oben/unten verändert. Die Gerade steigt also pro Einheit von var1 um 1.8389662. Die Ergebnisse können wir unter m1 ablegen:\nm1 &lt;- lm(var2~ var1, data = dat1)\nMit summary() bekommen wir dann eine Regressionstabelle:\nsummary(m1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.372 -3.613  0.162  2.234 10.789 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -2.3400     4.3454  -0.538   0.6096  \nvar1          1.8390     0.7727   2.380   0.0548 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.127 on 6 degrees of freedom\nMultiple R-squared:  0.4856,    Adjusted R-squared:  0.3999 \nF-statistic: 5.664 on 1 and 6 DF,  p-value: 0.05477\nm1 enthält alle Informationen zum Modell, besonders hilfreich ist $coefficients:\nm1$coefficients\n\n(Intercept)        var1 \n  -2.339960    1.838966 \n\nsummary(m1)$coefficients\n\n             Estimate Std. Error    t value   Pr(&gt;|t|)\n(Intercept) -2.339960  4.3453801 -0.5384938 0.60961706\nvar1         1.838966  0.7727028  2.3799139 0.05477457\nWir können uns die einzelnen Werte mit View(m1) ansehen:\nBspw. finden sich unter fitted.values die vorhergesagten Werte für jeden Fall.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#regressionsgerade-und-daten-visualisieren",
    "href": "09_reg.html#regressionsgerade-und-daten-visualisieren",
    "title": "8  Regressionsmodelle",
    "section": "8.2 Regressionsgerade und Daten visualisieren",
    "text": "8.2 Regressionsgerade und Daten visualisieren\nMit geom_smooth(method = \"lm\") können wir Regressionsgeraden auch in {ggplot2} darstellen:\nUnser Modell mit var1 und var2 können wir so darstellen:\n\nlibrary(ggplot2)\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  \n\n\n\n\n\n\n\n\nHier scheinen wir einen Ausreißer zu haben. In unserem übersichtlichen Datensatz ist der schnell gefunden. In größeren Datensätzen hilft uns geom_text():\n\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  +\n  geom_text(data = . %&gt;% filter(var2 &gt; 20), aes(y = var2+3, label = id), color = \"sienna1\")\n\n\n\n\n\n\n\n\nWir können nämlich einzelne geom_ auch nur für ein Subset angeben - dazu vergeben wir data = neu (übernehmen also nicht die Auswahl aus dem Haupt-Befehl ggplot()) und setzen darin einen filter(). Außerdem verschieben wir mit var2+3 das Label etwas über den Punkt.\n\n8.2.1 Übung",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#modelle-nur-für-manche-fälle-berechnen",
    "href": "09_reg.html#modelle-nur-für-manche-fälle-berechnen",
    "title": "8  Regressionsmodelle",
    "section": "8.3 Modelle nur für manche Fälle berechnen",
    "text": "8.3 Modelle nur für manche Fälle berechnen\nWenn wir jetzt das Modell nochmal berechnen wollen, haben wir zwei Möglichkeiten:\n\n8.3.1 Neuen data.frame erstellen\nWir können in R mehrere data.frame-Objekte im Speicher halten. Also können wir leicht einen neuen data.frame erstellen, der nur die Beobachtungen mit var2 &lt; 20 enthält und diesen dann für unseren lm()-Befehl verwenden:\n\ndat1_u20 &lt;- dat1 %&gt;% filter(var2&lt;20)\nm2a &lt;- lm(var2~ var1, data = dat1_u20)\nsummary(m2a)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1_u20)\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456\n\n\n\n\n8.3.2 Direkt in lm() filtern\nWir können filter()-Befehl auch direkt in das data=-Argument von lm() bauen:\n\nm2b &lt;- lm(var2~ var1, data = dat1 %&gt;% filter(var2&lt;20))\nsummary(m2b)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1 %&gt;% filter(var2 &lt; 20))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#regressionstabellen",
    "href": "09_reg.html#regressionstabellen",
    "title": "8  Regressionsmodelle",
    "section": "8.4 Regressionstabellen",
    "text": "8.4 Regressionstabellen\nWenn wir diese verschiedenen Modelle jetzt vergleichen möchten, bietet sich eine Tabelle an.\nEs gibt zahlreiche Alternativen zur Erstellung von Regressionstabellen, mein persönlicher Favorit ist modelsummary() aus dem gleichnamigen Paket {modelsummary}. Es kommt mit (nahezu) allen Modellarten zurecht und bietet darüber hinaus eine breite Palette an (u.a. auch Word-Output - dazu später mehr) und auch Koeffizientenplots (auch dazu kommen wir noch). Außerdem ist die Dokumentation hervorragend.\n\nfdz_install(\"modelsummary\")\n\n\nlibrary(modelsummary)\nmodelsummary(list(m1,m2a,m2b))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n\n\n\n\n(Intercept)\n-2.340\n1.138\n1.138\n\n\n\n(4.345)\n(1.922)\n(1.922)\n\n\nvar1\n1.839\n0.668\n0.668\n\n\n\n(0.773)\n(0.388)\n(0.388)\n\n\nNum.Obs.\n8\n7\n7\n\n\nR2\n0.486\n0.372\n0.372\n\n\nR2 Adj.\n0.400\n0.247\n0.247\n\n\nAIC\n55.4\n36.6\n36.6\n\n\nBIC\n55.6\n36.5\n36.5\n\n\nLog.Lik.\n-24.702\n-15.321\n-15.321\n\n\nF\n5.664\n2.967\n2.967\n\n\nRMSE\n5.31\n2.16\n2.16\n\n\n\n\n\n\n\nWir werden uns noch ein bisschen ausführlicher mit den Anpassungsmöglichkeiten für {modelsummary} befassen, hier nur schon mal zwei zentrale Optionen:\n\nmit stars = T können wir uns die Signifikanz mit den gebräuchlichen Sternchen-Codes anzeigen lassen (*: p &lt; .05 usw.)\nmit gof_omit = \"IC|RM|Log\" können wir die Goodness of Fit Statistiken ausblenden die IC, RM oder Log im Namen haben (also AIC, BIC, RMSE und die LogLikelihood)\nmit \"Name\" = in list() können wir Namen angeben:\n\n\nmodelsummary(list(\"m1\"=m1,\"m2a\"=m2a,\"m2b\"=m2b),stars = T,gof_omit = \"IC|RM|Log\")\n\n\n\n\n\nm1\n m2a\n m2b\n\n\n\n\n(Intercept)\n-2.340\n1.138\n1.138\n\n\n\n(4.345)\n(1.922)\n(1.922)\n\n\nvar1\n1.839+\n0.668\n0.668\n\n\n\n(0.773)\n(0.388)\n(0.388)\n\n\nNum.Obs.\n8\n7\n7\n\n\nR2\n0.486\n0.372\n0.372\n\n\nR2 Adj.\n0.400\n0.247\n0.247\n\n\nF\n5.664\n2.967\n2.967\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\n8.4.1 Übung",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#kategoriale-unabhängige-variablen",
    "href": "09_reg.html#kategoriale-unabhängige-variablen",
    "title": "8  Regressionsmodelle",
    "section": "8.5 Kategoriale unabhängige Variablen",
    "text": "8.5 Kategoriale unabhängige Variablen\nNatürlich können wir auch kategoriale unabhängige Variablen in unser Modell mit aufnehmen. Dazu müssen wir aber entsprechende Variable als factor definieren - und R so mitteilen, dass die Zahlenwerte nicht numerisch zu interpretieren sind. Wenn wir educ aus unserem kleinen Beispiel betrachten - dann steht 1 für einen grundlegenden Bildungsabschluss, 2 für einen mittleren und 3 für einen hohen Bildungsabschluss.\n\ndat1\n\n  id var1 var2 educ gend  x\n1  1    2    2    3    2  2\n2  2    1    2    1    1  1\n3  3    2    1    2    1  2\n4  4    5    9    2    2  4\n5  5    7    7    1    1  1\n6  6    8    4    3    2 NA\n7  7    9   25    2    1 NA\n8  8    5    3   -1    2 NA\n\nm3 &lt;- lm(var2~factor(educ), dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ factor(educ), data = dat1)\n\nResiduals:\n         1          2          3          4          5          6          7 \n-1.000e+00 -2.500e+00 -1.067e+01 -2.667e+00  2.500e+00  1.000e+00  1.333e+01 \n         8 \n-1.277e-15 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    3.000e+00  8.848e+00   0.339    0.752\nfactor(educ)1  1.500e+00  1.084e+01   0.138    0.897\nfactor(educ)2  8.667e+00  1.022e+01   0.848    0.444\nfactor(educ)3 -1.088e-15  1.084e+01   0.000    1.000\n\nResidual standard error: 8.848 on 4 degrees of freedom\nMultiple R-squared:  0.2848,    Adjusted R-squared:  -0.2516 \nF-statistic: 0.531 on 3 and 4 DF,  p-value: 0.685\n\n\nNoch schöner ist das aber natürlich, wenn wir educ vorher labeln:\n\ndat1$ed_fct &lt;- factor(dat1$educ, levels = 1:3,\n                        labels = c(\"basic\",\"medium\",\"high\"))\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   &lt;NA&gt;\n\n\nDann verwenden den factor im Regressionsbefehl:\n\nm3 &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     4.500      6.257   0.719    0.512\ned_fctmedium    7.167      8.077   0.887    0.425\ned_fcthigh     -1.500      8.848  -0.170    0.874\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nIm Vergleich zu educ = basic ist der vorhergesagte Wert für var2 bei educ = medium um 7.17 höher.\nIm Vergleich zu educ = basic ist der vorhergesagte Wert für var2 bei educ = high um -1.5 höher.\n\nWir können die Referenzkategorie auch ändern:\n\ndat1$ed_fct &lt;- relevel(dat1$ed_fct,ref = \"medium\")\nm3b &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3b)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   11.667      5.109   2.284   0.0844 .\ned_fctbasic   -7.167      8.077  -0.887   0.4251  \ned_fcthigh    -8.667      8.077  -1.073   0.3437  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nIm Vergleich zu educ = medium ist der vorhergesagte Wert für var2 bei educ = basic um 7.17 niedriger.\nIm Vergleich zu educ = medium ist der vorhergesagte Wert für var2 bei educ = high um 8.67 niedriger.\n\n\n8.5.1 Übung",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#mehre-unabhängige-variablen",
    "href": "09_reg.html#mehre-unabhängige-variablen",
    "title": "8  Regressionsmodelle",
    "section": "8.6 Mehre unabhängige Variablen",
    "text": "8.6 Mehre unabhängige Variablen\nUm mehrere unabhängige Variablen in unser Regressionsmodellen aufzunehmen, geben wir sie mit + an:\n\nm4 &lt;- lm(var2 ~ ed_fct  + var1, dat1)\nsummary(m4)\n\n\nCall:\nlm(formula = var2 ~ ed_fct + var1, data = dat1)\n\nResiduals:\n     1      2      3      4      5      6      7 \n 4.258  2.758 -4.824 -2.082 -2.758 -4.258  6.907 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   2.3187     5.8227   0.398    0.717\ned_fctbasic  -4.8297     6.0381  -0.800    0.482\ned_fcthigh   -8.0824     5.9411  -1.360    0.267\nvar1          1.7527     0.8347   2.100    0.127\n\nResidual standard error: 6.501 on 3 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.7002,    Adjusted R-squared:  0.4003 \nF-statistic: 2.335 on 3 and 3 DF,  p-value: 0.2521",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#modelplot",
    "href": "09_reg.html#modelplot",
    "title": "8  Regressionsmodelle",
    "section": "8.7 Koeffizientenplots",
    "text": "8.7 Koeffizientenplots\nNeben Regressionstabellen stellt {modelsummary} auch die Funktion modelplot() zur Verfügung, mit denen einfach ein Koeffizientenplot aus einem oder mehreren Modellen erstellt werden kann:\n\nmodelplot(m4)\n\n\n\n\n\n\n\n\nFür einen Modellvergleich geben wir einfach die Modelle in einer named list an, außerdem können wir mit den üblichen {ggplot2}-Befehlen die Grafik weiter anpassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4))\n\n\n\n\n\n\n\n\nMit coef_map können wir Labels für die Koeffizienten vergeben ((Intercept) bekommt keinen Namen und wird daher weggelassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4),\n          coef_map = c(\"var1\" = \"Name für var1\",\n                       \"ed_fcthigh\"  = \"Höhere Bildung\",\n                       \"ed_fctbasic\" = \"Grundlegende Bildung\"\n                          ))\n\n\n\n\n\n\n\n\nAußerdem können wir mit den üblichen {ggplot2}-Befehlen die Grafik weiter anpassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4),\n          coef_map = c(\"var1\" = \"Name für var1\",\n                       \"ed_fcthigh\"  = \"Höhere Bildung\",\n                       \"ed_fctbasic\" = \"Grundlegende\\nBildung\")) + # \\n fügt einen Zeilenumbruch ein\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"grey40\") +  # 0-Linie einfügen\n  scale_color_manual(values = c(\"orange\",\"navy\")) +\n  theme_minimal(base_size = 15,base_family = \"mono\") \n\n\n\n\n\n\n\n\nMit {broom} können wir auch einen data.frame aus den Regressionsergebnissen erstellen und den ggplot ganz selbst erstellen - siehe Anhang.\n\n8.7.1 Übung",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#übungen",
    "href": "09_reg.html#übungen",
    "title": "8  Regressionsmodelle",
    "section": "8.8 Übungen",
    "text": "8.8 Übungen\nVerwenden Sie folgenden Subdatensatz des PASS CampusFiles:\n\npend_ue08 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\") %&gt;% \n  filter(welle == 13, netges &gt; 0, azges1 &gt; 0,schul2 &gt; 1, palter &gt; 0)\n\n\n8.8.1 Übung 1: Regression\n\nErstellen Sie ein Objekt mod1 mit einem linearen Regressionsmodell (lm) mit netges (Monatsnetto in EUR) als abhängiger und azges1 (Arbeitszeit in Stunden) als unabhängiger Variable! (siehe hier)\nBetrachten Sie Ergebnisse mod1 - was können Sie zum Zusammenhang zwischen netges und azges1 erkennen?\nVisualisieren Sie Ihr Regressionsmodell mit {ggplot2}.\nSehen Sie Ausreißer im Scatterplot? Markieren Sie diese mit Hilfe der Variable pnr und geom_text().\n\n\n\n8.8.2 Übung 2: Nur manche Beobachtungen\n\nErstellen Sie ein lm()-Modell mod2, welches nur auf den Beobachtungen mit einem Monatseinkommen unter 20.000 EUR beruht.\nErstellen Sie eine Regressionstabelle, welche diese neue Modell mod2 neben das Modell mod1 aus Übung 1 stellt.\n\n\n\n8.8.3 Übung 3: kat. UVs\n\nErstellen Sie ein Regressionsmodell mit de Einkommen der Befragen (netges) als abhängiger und dem Schulabschluss der Befragten schul als unabhängiger Variable:\n\n\n\n\n\n\n\n\n\n\n\n\n\nvalue\nlabel\n\n\n\n\n-10 bis -1 und 1\nt.n.z./k.A.\n\n\n2\nSchule beendet ohne Abschluss\n\n\n3\nSonder-/Foerderschulabschluss\n\n\n4\nVolks-/Hauptschulabschluss bzw: POS 8./9. Klasse\n\n\n5\nMittlere Reife/Realschulabschluss bzw. POS 10. Klasse\n\n\n6\nFachhochschulreife\n\n\n7\nAllgem. oder fachgeb. Hochschulreife (Abitur)/EOS 12. Klasse\n\n\n\n\n\n\n\n\nAchten Sie darauf, dass schul2 als factor definiert ist. Vergeben Sie für die Levels 2-7 die Labels “ohne”, “Förderschule”,“Hauptschule”,“Mittlere Reife”,“FOS/BOS”,“Abi” und legen sie den factor als Variable schul2_fct in Ihrem data.frame ab - siehe Code-Hilfe unten:\n\n\n\nCode\npend_ue08$schul2_fct &lt;-  \n  factor(pend_ue08$schul2,levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))\n\n\n\nErstellen Sie das Regressionsmodell mit dieser neuen factor-Variable für schul2_fct als unabhängiger Variablen.\nÄndern Sie die Referenzkategorie auf die Ausprägung Mittlere Reife (schul2 = 5) und schätzen Sie das Modell erneut.\n\n\n\n8.8.4 Übung 4: mehrere UVs & Koeffizientenplot\n\nPassen Sie das lm()-Modell mod1 (mit allen Fällen aus pend_u08) so an, dass neben der Arbeitszeit zusätzlich den Schulabschluss (schul2) als unabhängige Variable mit aufgenommen werden.\nErstellen Sie auch eine grafische Gegenüberstellung der beiden Modelle mit und ohne den Schulabschluss",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "09_reg.html#anhang",
    "href": "09_reg.html#anhang",
    "title": "8  Regressionsmodelle",
    "section": "8.9 Anhang",
    "text": "8.9 Anhang\n\ndat1 &lt;- dat1 %&gt;% select(-matches(\"compl\"))\n\n\n8.9.1 Vorhergesagte Werte\nDie vorhergesagten Werte von lm() finden sich unter $fitted.values:\n\nm1$fitted.values\n\n        1         2         3         4         5         6         7         8 \n 1.337972 -0.500994  1.337972  6.854871 10.532803 12.371769 14.210736  6.854871 \n\n\nDiese vorhergesagten Werte entsprechen einfach der Summe aus dem Wert unter Intercept und dem Wert unter var1 multipliziert mit dem jeweiligen Wert für var1.\n\nm1\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839  \n\n\nFür die erste Zeile aus dat1 ergibt sich also m1 folgender vorhergesagter Wert: 2.1351+0.5811*1=2.7162\nDie Werte unter fitted.values folgen der Reihenfolge im Datensatz, sodass wir sie einfach als neue Spalte in dat1 ablegen können:\n\ndat1$lm_vorhersagen &lt;- m1$fitted.values\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_vorhersagen\n1  1    2    2    3    2  2   high       1.337972\n2  2    1    2    1    1  1  basic      -0.500994\n3  3    2    1    2    1  2 medium       1.337972\n4  4    5    9    2    2  4 medium       6.854871\n5  5    7    7    1    1  1  basic      10.532803\n6  6    8    4    3    2 NA   high      12.371769\n7  7    9   25    2    1 NA medium      14.210736\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871\n\n\nDie Grafik zeigt wie Vorhersagen auf Basis von m1 aussehen: Sie entsprechen den Werten auf der blauen Geraden (der sog. Regressionsgeraden) an den jeweiligen Stellen für var1.\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) +\n  geom_point(size = 3) +      \n  geom_smooth(method = \"lm\", color = \"darkblue\" , se = FALSE,size =.65) +\n  geom_point(aes(x = var1, y = lm_vorhersagen), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8),y=c(0,8)) \n\n\n\n\n\n\n\n\n\n\n\n8.9.2 Residuen\nDie hellblauen Punkte (also die Vorhersagen von m1) liegen in der Nähe der tatsächlichen Punkte. Trotzdem sind auch die hellblauen Punkte nicht deckungsgleich mit den tatsächlichen Werten. Diese Abweichungen zwischen den vorhergesagten und tatsächlichen Werten werden als Residuen bezeichnet: \\[Residuum = beobachteter\\, Wert \\; - \\; vorhergesagter\\,Wert\\] \\[\\varepsilon_{\\text{i}} = \\text{y}_{i} - \\hat{y}_{i}\\] Wir können diese per Hand berechnen als Differenz zwischen dem tatsächlichen und dem vorhergesagten Wert oder einfach unter m1$residuals aufrufen:\n\nm1$residuals\n\n         1          2          3          4          5          6          7 \n 0.6620278  2.5009940 -0.3379722  2.1451292 -3.5328032 -8.3717694 10.7892644 \n         8 \n-3.8548708 \n\n\nAuch die Residuen für lm können wir in dat1 ablegen:\n\ndat1$lm_residuen &lt;- m1$residuals\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_vorhersagen lm_residuen\n1  1    2    2    3    2  2   high       1.337972   0.6620278\n2  2    1    2    1    1  1  basic      -0.500994   2.5009940\n3  3    2    1    2    1  2 medium       1.337972  -0.3379722\n4  4    5    9    2    2  4 medium       6.854871   2.1451292\n5  5    7    7    1    1  1  basic      10.532803  -3.5328032\n6  6    8    4    3    2 NA   high      12.371769  -8.3717694\n7  7    9   25    2    1 NA medium      14.210736  10.7892644\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871  -3.8548708\n\n\nHier sind die Residuen für lm hellblau eingezeichnet:\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_smooth(method = \"lm\", color = \"darkblue\" , se = FALSE,size =.65) +\n  geom_segment(aes(x = var1, xend = var1, y = var2, yend = lm_vorhersagen), color = \"dodgerblue3\", size = .65, linetype = 1) +\n  geom_point(size = 3) +\n  geom_point(aes(x = var1, y = lm_vorhersagen), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8),y=c(0,8)) \n\n\n\n\n\n\n\n\n\n\n\n8.9.3 Annahmen checken\nmodel dashboard\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\n\nmodel_test &lt;- check_model(m4)\nplot(model_test)\n\n\n\n\n\n\n\n\n\n\n8.9.4 Test auf Normalverteilung der Residuen\nGrafische Überprüfung: Q-Q-Plot\n\nlibrary(ggfortify)\nautoplot(m1,which = 2)\n\n\n\n\n\n\n\n\n\n\nÜberprüfen lässt sich die NV-Annahme mit dem Shapiro-Wilk-Test & shapiro.test(). Dieser testet die \\(H_0\\): “Die Residuen sind normalverteilt” gegen die \\(H_A\\): “Die Residuen weichen signifikant von der Normalverteilung ab”\n\nshapiro.test(m1$residuals) \n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.95346, p-value = 0.746\n\n\n\n\n8.9.5 Test auf Homoskedastizität\nHomoskedastizität ist gegeben, wenn die vorhergesagten Werte über den kompletten Wertebereich (ungefähr) gleich weit von den tatsächlichen Werten (m1\\$fitted.values) entfernt sind. Auch hier gibt es eine graphische Überprüfungsmethode sowie einen Test. Zur graphischen Überprüfung werden die vorhergesagten Werten und die Residuen als Scatterplot dargestellt. Auch hier hilft uns autoplot():\n\nautoplot(m1, which = 1)\n\n\n\n\n\n\n\n\n\n\nDer dazugehörige Test ist der Breusch-Pagan-Test. Dieser testet die \\(H_0\\) “Homoskedastizität” gegen die \\(H_A\\) “Heteroskedastizität”, der p-Wert gibt also an mit welcher Irrtumswahrscheinlichkeit wir die Homoskedastizitäts-Annahme verwerfen müssen. In R können wir dafür bptest aus dem Paket lmtest verwenden:\n\ninstall.packages(\"lmtest\")\n\n\nlibrary(lmtest)\nbptest(m3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m3\nBP = 3.6069, df = 2, p-value = 0.1647\n\n\n\n\n8.9.6 Test auf Multikollinearität\n\ninstall.packages(\"car\")\n\n\n# library(car)\npendx &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",n_max = 300)  %&gt;% filter(netges &gt;0, palter &gt;0 )\nmox &lt;- lm(netges ~ palter + azges1,data=pendx)\ncar::vif(mox)\n\n  palter   azges1 \n1.000133 1.000133 \n\n\nInterpretation:\n\n\nEin verbreiteter Schwellenwert des VIF beträgt 10,00. Werte des VIF über 10 deuten auf ein schwerwiegendes Multikollinearitätsproblem, oftmals werden Gegenmaßnahmen schon ab einem strikteren Grenzwert von ca. 5,00 empfohlen. Im konkreten Beispiel ist für alle UVs also nach beiden Grenzwerten alles in Ordnung.\nBeim Vorliegen von Mulitkollinearität gibt es mehrere Möglichkeiten, das zu beheben: Wir können eine oder mehrere unabh. Variablen aus dem Modell ausschließen. Das ist letztlich eine inhaltliche Frage und kann nicht mit einem Standardrezept gelöst werden. Alternativ können wir die kollinearen unabh. Variablen zu Indexvariablen zusammenfassen. Wir würden also einen gemeinsamen Index, bspw. der Mittelwert über die jeweiligen unabh. Variablen, erstellen.\n\n\n\n8.9.7 Regressionsmodelle vergleichen\nMit dem Paket {performance} können wir auch einen umfassenden Modellvergleich bekommen:\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\ncompare_performance(m1,m4,metrics = c(\"R2\",\"R2_adj\"))\n\nWhen comparing models, please note that probably not all models were fit\n  from same data.\n\n\n# Comparison of Model Performance Indices\n\nName | Model |    R2 | R2 (adj.)\n--------------------------------\nm1   |    lm | 0.486 |     0.400\nm4   |    lm | 0.700 |     0.400\n\n\n\n\n8.9.8 Individuelle Koeffizientenplots mit {broom}\nmodelplot() bietet eine schnelle Art, Koeffizientenplots zu erstellen, allerdings verwende ich häufig {broom}. Mit broom::tidy(..., conf.int = TRUE) bekommen wir einen data.frame mit den Ergebnissen des Regressionsmodells, die wir bspw. in einem {ggplot2} weiterverarbeiten können - wenn uns die Standardlösung von modelplot() nicht weiterhilft/gefällt:\n\nlibrary(broom) ## schon geladen als Teil des tidyverse\ntidy(m3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      4.5       6.26     0.719   0.512    -12.9      21.9\n2 ed_fctmedium     7.17      8.08     0.887   0.425    -15.3      29.6\n3 ed_fcthigh      -1.5       8.85    -0.170   0.874    -26.1      23.1\n\ntidy(m3, conf.int = TRUE) %&gt;% \n  mutate(term = str_replace(term, \"ed_fct\", \"Education: \")) %&gt;% \n  ggplot(aes(y = term, x = estimate)) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"navy\") +\n  geom_errorbarh(aes(xmin = conf.low, xmax  = conf.high), height = .1) + \n  geom_point(color = \"orange\", shape = 18,size = 7) +\n  theme_minimal(base_size = 16)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "14_tabellenexport.html",
    "href": "14_tabellenexport.html",
    "title": "9  Tabellenexport",
    "section": "",
    "text": "9.1 {flextable}\nMit dem Paket {flextable} können wir data.frames als Tabelle in eine Word-Datei exportieren, {officer} erweiteret diese Funktionen speziell für den Export in Word:\ninstall.packages(\"flextable\")\nlibrary(flextable)\ninstall.packages(\"officer\")\nlibrary(officer)\ndf1 &lt;- data.frame(x1= c(2,2), y1 = c(0,1))\ndf1\n\n  x1 y1\n1  2  0\n2  2  1\n{flextable} stellt uns eine Reihe an Funktionen zur Formatierung zur Verfügung, um die Darstellung des data.frame zu anzupassen:\nflextable(df1) %&gt;% \n  border_remove() %&gt;% \n  hline_top(border = fp_border(color = \"orange\")) %&gt;%\n  hline(i=1,border = fp_border(color = \"blue\",style = \"dotted\")) %&gt;% \n  set_header_labels(x1 = \"Anderes Label\") %&gt;% \n  add_header_row(values = c(\"Überschrift\",\"\"),colwidths = c(1,1)) %&gt;% \n  autofit()\n\nÜberschriftAnderes Labely12021\nHier finden sich weitere Infos zu flextable, u.a. können bspw. die Trennlinien dünner gemacht werden oder eine andere Farbe angegeben werden. Hier finden sich alle vefügbaren Funktionen.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellenexport</span>"
    ]
  },
  {
    "objectID": "14_tabellenexport.html#deskription",
    "href": "14_tabellenexport.html#deskription",
    "title": "9  Tabellenexport",
    "section": "9.2 Deskription",
    "text": "9.2 Deskription\n\n9.2.1 Verteilungstabellen für metrische Variablen\nFür die metrischen Merkmale kennen wir ja das summary():\n\nsummary(pend14$netges)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0    1080    1600    1883    2160   88453 \n\nsummary(pend14$azges1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00   27.00   36.00   33.93   40.00   90.00 \n\n\nEine einfach Möglichkeit, diese summary() untereinander anzuordnen, ist summarise in Kombination mit pivot_longer() zu verwenden:\n\npend14 %&gt;% \n  select(azges1,netges) %&gt;% \n  pivot_longer(cols = everything(), names_to = \"variable\") %&gt;% \n  group_by(variable) %&gt;% \n  summarise(min = min(value,na.rm = T),\n            mean = mean(value,na.rm = T),\n            max = max(value,na.rm = T))\n\n# A tibble: 2 × 4\n  variable   min   mean   max\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 azges1       2   33.9    90\n2 netges       0 1883.  88453\n\n\n\n\n\n\n\n\n\n\n\n\npend14 %&gt;% \n  select(azges1,netges) %&gt;% \n  pivot_longer(cols = everything(), names_to = \"variable\") %&gt;% \n  group_by(variable) %&gt;% \n  summarise(Min  = min(value,na.rm = T),\n            Mean = mean(value,na.rm = T),\n            Max  = mean(value,na.rm = T)) %&gt;% \n  flextable()\n\nvariableMinMeanMaxazges1233.931233.9312netges01,883.30401,883.3040\n\n\n\nmet_ft &lt;- \n  pend14 %&gt;% \n  select(azges1,netges) %&gt;% \n  pivot_longer(cols = everything(), names_to = \"variable\") %&gt;% \n  group_by(variable) %&gt;% \n  summarise(Min  = min(value,na.rm = T),\n            Mean = mean(value,na.rm = T),\n            Max  = mean(value,na.rm = T)) %&gt;% \n  flextable() %&gt;% \n  autofit()\n\nDer eigentliche Export ist dann mit save_as_docx, wo wir eine Überschrift und mit path die Zieldatei angeben können:\n\nsave_as_docx(\"Metrische unab. Variablen\" = met_ft, path = \"./results/Met_UVs_Tabelle.docx\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAussagekräftigere Variablenbeschriftung mit rename() & Nachkommastellen\n\n\n\n\n\nUm den Variablen in der Tabelle aussagekräftigere Namen zu geben, benennen wir sie einfach mit rename() um. Falls wir mehr als ein Wort als Variablenname/späteres Label vergeben wollen, setzen wir die Wörter in '``'.\nMit digits = in colformat_double() können wir die Anzahl der Nachkommastellen setzen:\n\n  pend14 %&gt;% \n  select(`Arbeitszeit umfangreichste Tätigkeit` =azges1,Nettoverdienst=netges) %&gt;% \n  pivot_longer(cols = everything(), names_to = \"variable\") %&gt;% \n  group_by(variable) %&gt;% \n  summarise(Min  = min(value,na.rm = T),\n            Mean = mean(value,na.rm = T),\n            Max  = mean(value,na.rm = T)) %&gt;% \n  flextable() %&gt;% \n  colformat_double(digits = 2) %&gt;% \n  autofit()\n\nvariableMinMeanMaxArbeitszeit umfangreichste Tätigkeit2.0033.9333.93Nettoverdienst0.001,883.301,883.30\n\n\n\n\n\n\n\n9.2.2 Häufigkeitsauszählungen\n\npend14 %&gt;%  \n  mutate(schul2_fct = factor(schul2,levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\")),\n         zpsex_fct = factor(zpsex,levels = 1:2,labels =c(\"Männer\",\"Frauen\"))) %&gt;% \n  select(zpsex_fct,schul2_fct) %&gt;% \n  pivot_longer(everything(),names_to = \"variable\") %&gt;% \n  count(variable,value)\n\n# A tibble: 8 × 3\n  variable   value              n\n  &lt;chr&gt;      &lt;fct&gt;          &lt;int&gt;\n1 schul2_fct ohne              25\n2 schul2_fct Förderschule       2\n3 schul2_fct Hauptschule      101\n4 schul2_fct Mittlere Reife   230\n5 schul2_fct FOS/BOS           51\n6 schul2_fct Abi              216\n7 zpsex_fct  Männer           317\n8 zpsex_fct  Frauen           308\n\n\n\npend14 %&gt;%  \n  mutate(schul2_fct = factor(schul2,levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\")),\n         zpsex_fct = factor(zpsex,levels = 1:2,labels =c(\"Männer\",\"Frauen\"))) %&gt;% \n  select(zpsex_fct,schul2_fct) %&gt;% \n  pivot_longer(everything(),names_to = \"variable\") %&gt;% \n  count(variable,value) %&gt;% \n  flextable()\n\nvariablevaluenschul2_fctohne25schul2_fctFörderschule2schul2_fctHauptschule101schul2_fctMittlere Reife230schul2_fctFOS/BOS51schul2_fctAbi216zpsex_fctMänner317zpsex_fctFrauen308\n\n\n\nkat_ft &lt;- \n  pend14 %&gt;%  \n  mutate(schul2_fct = factor(schul2,levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\")),\n         zpsex_fct = factor(zpsex,levels = 1:2,labels =c(\"Männer\",\"Frauen\"))) %&gt;% \n  select(zpsex_fct,schul2_fct) %&gt;% \n  pivot_longer(everything(),names_to = \"variable\") %&gt;% \n  count(variable,value)  %&gt;% \n  flextable() %&gt;% autofit()\n\nFür den Export können wir dann wieder save_as_docx() verwenden:\n\nsave_as_docx(\"Kategoriale unab. Variablen\" = kat_ft, path = \"./results/Kat_UVs_Tabelle.docx\")\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.3 Übung",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellenexport</span>"
    ]
  },
  {
    "objectID": "14_tabellenexport.html#regressionstabellen",
    "href": "14_tabellenexport.html#regressionstabellen",
    "title": "9  Tabellenexport",
    "section": "9.3 Regressionstabellen",
    "text": "9.3 Regressionstabellen\nFür Regressionstabellen können wir mit {modelsummary} eine {flextable}-Tabelle erstellen:\n\npend14_reg_df &lt;- \n  pend14 %&gt;%\n  mutate(zpsex_fct = factor(zpsex,levels = 1:2, labels = c(\"Männer\",\"Frauen\")),\n         schul2_fct = factor(schul2,levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))) %&gt;% \n  na.omit()\n\nm1 &lt;- lm(netges ~ azges1 + zpsex_fct, data = pend14_reg_df)\nm2 &lt;- lm(netges ~ azges1 + zpsex_fct + schul2_fct, data = pend14_reg_df)\nmodelsummary(list(\"Modell 1\"=m1,\"Modell 2\"=m2),\n                                output = \"flextable\",gof_omit = \"IC|Log|RMS\",\n                           coef_rename = c(\"(Intercept)\"=\"Intercept\",\n                                           \"azges1\" = \"Arbeitszeit (h)\",\n                                           \"zpsex_fctFrauen\" = \"Frauen\",\n                                           \"schul2_fctFörderschule\" = \"Förderschulabschluss\",\n                                           \"schul2_fctHauptschule\" = \"Hauptschulabschluss\",\n                                           \"schul2_fctMittlere Reife\" = \"Mittlere Reife\",\n                                           \"schul2_fctFOS/BOS\" = \"Fachhochschulreife\",\n                                           \"schul2_fctAbi\" = \"Abitur\"),\n                           stars = T,fmt =2)\n\n Modell 1Modell 2Intercept2787.36***1768.49+(620.11)(928.63)Arbeitszeit (h)-12.12-12.03(15.37)(15.46)Frauen-1000.25**-1055.03**(315.07)(321.29)Förderschulabschluss30.12(2634.95)Hauptschulabschluss627.13(800.21)Mittlere Reife870.98(761.35)Fachhochschulreife1368.66(876.52)Abitur1473.44+(759.53)Num.Obs.625625R20.0170.029R2 Adj.0.0130.018+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n9.3.1 Referenzkategorien einfügen\nUm die Referenzkategorie für kategoriale Variablen kenntlich zu machen, können wir den Hinweis ref. mitaufanzeigen.\nDazu können wir mit Hilfe des Arguments add_rows eine zusätzliche Zeile für die Referenzkategorie der Variable zpsex einfügen. Zunächst erstellen wir einen data.frame, welcher neben den Modellnamen die Koeffizientennamen sowie die einzufügenden Werte enthält. Mit tribble aus dem Paket tibble lässt sich das einfach bewerkstelligen: wir können die Zeilen und Spalten gleich so aufschreiben, wie wir sie haben möchten:\n\nlibrary(tibble)\nref_rows &lt;- tribble( ~ term,    ~ \"Modell 1\",  ~ \"Modell 2\",\n                     \"Männer\",    'ref.',   'ref.')\nattr(ref_rows, 'position') &lt;- 5 # Zeile angeben \n\nmodelsummary(\n  list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n  output = \"flextable\",\n  gof_omit = \"IC|Log|RMS\",\n  coef_rename = c(\"(Intercept)\"=\"Intercept\",\n                                           \"azges1\" = \"Arbeitszeit (h)\",\n                                           \"zpsex_fctFrauen\" = \"Frauen\",\n                                           \"schul2_fctFörderschule\" = \"Förderschulabschluss\",\n                                           \"schul2_fctHauptschule\" = \"Hauptschulabschluss\",\n                                           \"schul2_fctMittlere Reife\" = \"Mittlere Reife\",\n                                           \"schul2_fctFOS/BOS\" = \"Fachhochschulreife\",\n                                           \"schul2_fctAbi\" = \"Abitur\"),\n  add_rows = ref_rows,\n  stars = T,\n  fmt = 2\n) %&gt;% autofit()\n\n Modell 1Modell 2Intercept2787.36***1768.49+(620.11)(928.63)Arbeitszeit (h)-12.12-12.03(15.37)(15.46)Männerref.ref.Frauen-1000.25**-1055.03**(315.07)(321.29)Förderschulabschluss30.12(2634.95)Hauptschulabschluss627.13(800.21)Mittlere Reife870.98(761.35)Fachhochschulreife1368.66(876.52)Abitur1473.44+(759.53)Num.Obs.625625R20.0170.029R2 Adj.0.0130.018+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nDas funktioniert auch für mehrere Referenzkategorien:\n\nref_rows2 &lt;- tribble(~term,    ~\"Modell 1\",  ~\"Modell 2\",\n                \"Männer\",    'ref.',   'ref.',\n                \"keine Schulabschluss\",    '',   'ref.',\n                )\nattr(ref_rows2, 'position') &lt;- c(5,8) # Zeile angeben \n\nmodelsummary(\n  list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n  output = \"flextable\",\n  gof_omit = \"IC|Log|RMS\",\n  coef_rename = c(\"(Intercept)\"=\"Intercept\",\n                                           \"azges1\" = \"Arbeitszeit (h)\",\n                                           \"zpsex_fctFrauen\" = \"Frauen\",\n                                           \"schul2_fctFörderschule\" = \"Förderschulabschluss\",\n                                           \"schul2_fctHauptschule\" = \"Hauptschulabschluss\",\n                                           \"schul2_fctMittlere Reife\" = \"Mittlere Reife\",\n                                           \"schul2_fctFOS/BOS\" = \"Fachhochschulreife\",\n                                           \"schul2_fctAbi\" = \"Abitur\"),\n  add_rows = ref_rows2,\n  stars = T,\n  fmt = 2\n)\n\n Modell 1Modell 2Intercept2787.36***1768.49+(620.11)(928.63)Arbeitszeit (h)-12.12-12.03(15.37)(15.46)Männerref.ref.Frauen-1000.25**-1055.03**(315.07)(321.29)keine Schulabschlussref.Förderschulabschluss30.12(2634.95)Hauptschulabschluss627.13(800.21)Mittlere Reife870.98(761.35)Fachhochschulreife1368.66(876.52)Abitur1473.44+(759.53)Num.Obs.625625R20.0170.029R2 Adj.0.0130.018+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\nTipparbeit beim Umbenennen sparen mit coef_rename =\n\n\n\n\n\nMit Hilfe der Option coef_rename = und einer function() können wir die Variablenumbenennung auch automatisieren. Mehr dazu hier Dazu erstellen wir eine Funktion erstellen, welche bspw. mit gsub() Variablennamen durch die gewünschte Beschriftung ersetzt:\n\nrename_function &lt;- function(old_names) {\n  new_names &lt;- \n    gsub(\"schul2_fct\", \"\", old_names) %&gt;% \n    gsub(\"zpsex_fct\", \"\",.) %&gt;% \n    gsub(\"azges1\", \"Arbeitszeit (h) \",.)\n  \n  return(setNames(new_names, old_names))\n}\n\n## diese Funktion dann in modelsummary verwenden:\nmodelsummary(list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n             output = \"flextable\",gof_omit = \"IC|Log|RMS\", \n             coef_rename = rename_function) # function anwenden\n\n Modell 1Modell 2(Intercept)2787.3561768.486(620.109)(928.625)Arbeitszeit (h) -12.117-12.028(15.373)(15.458)Frauen-1000.250-1055.027(315.071)(321.292)Förderschule30.121(2634.951)Hauptschule627.133(800.213)Mittlere Reife870.982(761.353)FOS/BOS1368.659(876.515)Abi1473.443(759.534)Num.Obs.625625R20.0170.029R2 Adj.0.0130.018\n\n\n\n\n\nAuf den mit {modelsummary} erstellten flextable können wir natürlich auch alle Funktionen für flextable anwenden und dann mit save_as_docx() die Tabelle exportieren:\n\nregtab2 &lt;- \n  modelsummary(\n    list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n    output = \"flextable\",\n    gof_omit = \"IC|Log|RMS\",\n    coef_rename = c(\"(Intercept)\"=\"Intercept\",\n                    \"azges1\" = \"Arbeitszeit (h)\",\n                    \"zpsex_fctFrauen\" = \"Frauen\",\n                    \"schul2_fctFörderschule\" = \"Förderschulabschluss\",\n                    \"schul2_fctHauptschule\" = \"Hauptschulabschluss\",\n                    \"schul2_fctMittlere Reife\" = \"Mittlere Reife\",\n                    \"schul2_fctFOS/BOS\" = \"Fachhochschulreife\",\n                    \"schul2_fctAbi\" = \"Abitur\"),\n    add_rows = ref_rows2,\n    stars = T,\n    fmt = 2) %&gt;% \n  autofit() %&gt;% \n  italic(i = ~ `Modell 2` == \"ref.\",j =2:3)\n\n\nsave_as_docx(regtab2,path = \"./results/regressionstabelle.docx\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellenexport</span>"
    ]
  },
  {
    "objectID": "14_tabellenexport.html#alle-tabellen-in-eine-datei-mit-officer",
    "href": "14_tabellenexport.html#alle-tabellen-in-eine-datei-mit-officer",
    "title": "9  Tabellenexport",
    "section": "9.4 Alle Tabellen in eine Datei mit {officer}",
    "text": "9.4 Alle Tabellen in eine Datei mit {officer}\nUm die Tabellen in Dokument gemeinsames Dokument zu exportieren, ist das Paket officer eine große Hilfe. Mehr Infos hier.\n\nlibrary(officer)\n\nZunnächst lesen wir mit read_docx() eine Vorlage ein, welche Einstellungen für das Word-Dokument enthält (Seitenformat,..) und fügen dann mit body_add_flextable() die Tabellen ein. Mit body_add_par(.,\"\") können wir leere Absätze einfügen.\n\nread_docx(\"Word_Vorlage.docx\") %&gt;%\n   body_add_par(value = \"Metrische Variablen\",style = \"heading 1\") %&gt;%\n   body_add_flextable(., value = met_ft ) %&gt;% # flextable met_ft einfügen\n   body_add_par(.,\"\") %&gt;% # leeren Absatz  einfügen\n   body_add_par(value = \"Kategoriale Variablen\",style = \"heading 1\") %&gt;%\n   body_add_flextable(., value = kat_ft ) %&gt;% # flextable cat_ft einfügen\n   body_add_par(.,\"\") %&gt;% # leeren Absatz einfügen\n   body_add_flextable(., value = regtab2 ) %&gt;% # flextable regtab2 einfügen\n   print(target = \"./results/Tables.docx\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellenexport</span>"
    ]
  },
  {
    "objectID": "14_tabellenexport.html#übung-1",
    "href": "14_tabellenexport.html#übung-1",
    "title": "9  Tabellenexport",
    "section": "9.5 Übung",
    "text": "9.5 Übung\n\n9.5.1 Übung\n\npend_ue14 &lt;- \n  haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",col_select = c(\"famstand\",\"azges1\",\"palter\",\"schul2\"))%&gt;% \n  filter(palter &gt; 0, famstand &gt; 0 , azges1&gt;0, schul2 &gt; 1) %&gt;% \n  mutate(famstand_fct = factor(famstand,levels = 1:5,labels = c(\"Ledig\",\"Verheiratet\", \"Verheiratet getr. lebd.\", \"Geschieden\", \"Verwitwet\")),\n         schul2_fct = factor(schul2, levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))) \n\n\nErstellen Sie eine Übersicht für die Variablen zpalter (Alter) und azges1 (Arbeitszeit) und exportieren Sie diese in eine Word-Datei. Verwenden Sie den obigen Einlesebefehl - dann sind die Missings bereits ausgeschlossen,\n\nErstellen Sie zunächst einen data.frame mit min, mean und max der beiden Variablen.\nFormatieren Sie diesen data.frame dann als flextable\nSpeichern Sie diesen mit save_as_docx()\n\nErstellen Sie eine Übersichtstabelle zu famstand_fct (Familienstand) und schul2_fct (Ausbildung).\n\nDie Labels sind bereits im obigen Einlesebefehl gesetzt.\n\n\n\n\n9.5.2 Übung\n\nErstellen sie folgende Regressionsmodelle und erstellen Sie mit {modelsummary} eine Regressiontabelle:\n\n\nm1 &lt;- lm(azges1 ~ schul2_fct, data = pend_ue14)\nm2 &lt;- lm(azges1 ~ schul2_fct + zpalter, data = pend_ue14)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellenexport</span>"
    ]
  },
  {
    "objectID": "14_tabellenexport.html#latex",
    "href": "14_tabellenexport.html#latex",
    "title": "9  Tabellenexport",
    "section": "9.6 Latex",
    "text": "9.6 Latex\n{kableExtra} ist mein Favorit für Tabellen in pdf Outputs.\n\n9.6.1 Verteilungstabellen für metrische Variablen\n\nlibrary(kableExtra)\n\nmet_kbl &lt;- \n  pend14 %&gt;% \n  select(azges1,netges) %&gt;% \n  pivot_longer(cols = everything(), names_to = \"variable\") %&gt;% \n  group_by(variable) %&gt;% \n  summarise(Min  = min(value,na.rm = T),\n            Mean = mean(value,na.rm = T),\n            Max  = mean(value,na.rm = T)) %&gt;% \n  kbl(., booktabs = T, format = 'latex') %&gt;% #  ab hier spezifisch für latex\n  kable_styling(latex_options = \"striped\")\n\nwrite(met_kbl,file = \"./results/desc1.tex\")\n\n\n\n9.6.2 Häufigkeitsauszählungen\n\nkat_kbl &lt;- \n  pend14 %&gt;%  \n    select(zpsex,schul2) %&gt;% \n    mutate(zpsex = factor(zpsex,levels = 1:2, labels = c(\"Männer\",\"Frauen\")),\n           schul2 = factor(schul2, levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))) %&gt;% \n    pivot_longer(everything(),names_to = \"variable\") %&gt;% \n    count(variable,value)  %&gt;% \n  kbl(., booktabs = T, format = 'latex') %&gt;%  # ab hier latex-syntax\n  kable_styling(latex_options = \"striped\", stripe_index = c(1,2))\n\nwrite(kat_kbl,file = \"./results/crosstab1.tex\")\n\n\n\n9.6.3 Regressionstabelle mit {modelsummary}\n\n  m1 &lt;- lm(netges ~ azges1 + zpsex_fct, data = pend14_reg_df)\n  m2 &lt;- lm(netges ~ azges1 + zpsex_fct + schul2_fct, data = pend14_reg_df)\n  \n  ref_rows2 &lt;- tribble(~term,    ~\"Modell 1\",  ~\"Modell 2\",\n                  \"Männer\",    'ref.',   'ref.',\n                  \"keine Ausbildung\",    '',   'ref.',\n                  )\n  attr(ref_rows2, 'position') &lt;- c(5,8) # Zeile angeben \n  \n  modelsummary(\n    list(\"Modell 1\" = m1, \"Modell 2\" = m2),\n    gof_omit = \"IC|Log|RMS\",\n    coef_rename = c(\n      \"(Intercept)\" = \"Intercept\",\n      \"zpsexFrauen\" = \"Frauen\",\n      \"schul2dual/schul.\" = \"Duale/Schulische Ausbildung\",\n      \"schul2Aufst.\" = \"Aufstiegsfortbildung\",\n      \"schul2FH/Uni\" = \"FH/Uni-Abschluss\"\n    ),\n    add_rows = ref_rows2,\n    stars = T,\n    fmt = 2,\n    output = \"./results/modelsummary.tex\" ## Latex-Output\n  )",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellenexport</span>"
    ]
  },
  {
    "objectID": "14_tabellenexport.html#anhang",
    "href": "14_tabellenexport.html#anhang",
    "title": "9  Tabellenexport",
    "section": "9.7 Anhang",
    "text": "9.7 Anhang\n\n9.7.1 Kreuztabellen\n\n\nGeschlechtAusbildungMännerFrauenTotalohne21425Förderschule202Hauptschule6041101Mittlere Reife96134230FOS/BOS262551Abi112104216Total317308625\n\n\nHier ist die Herausforderung, einen data.frame() für {flextable} vorzubereiten: table() gibt keinen data.frame aus und meistens ist der long shape Output von count() auch nicht das was wir wollen:\n\ntab1 &lt;- table(pend14$zpsex,pend14$schul2)\nclass(tab1)\n\n[1] \"table\"\n\n\n\npend14 %&gt;% \n  mutate(zpsex_fct = factor(zpsex,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %&gt;% # zahlenwerte in zpsex mit labels überschreiben \n  mutate(schul2_fct = factor(schul2, levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))) %&gt;% # auch für schul2\n  count(zpsex_fct,schul2_fct) \n\n# A tibble: 11 × 3\n   zpsex_fct schul2_fct         n\n   &lt;fct&gt;     &lt;fct&gt;          &lt;int&gt;\n 1 Männer    ohne              21\n 2 Männer    Förderschule       2\n 3 Männer    Hauptschule       60\n 4 Männer    Mittlere Reife    96\n 5 Männer    FOS/BOS           26\n 6 Männer    Abi              112\n 7 Frauen    ohne               4\n 8 Frauen    Hauptschule       41\n 9 Frauen    Mittlere Reife   134\n10 Frauen    FOS/BOS           25\n11 Frauen    Abi              104\n\n\ntabyl() aus {janitor} hilft hier weiter:\n\nlibrary(janitor)\npend14 %&gt;% \n  mutate(zpsex_fct = factor(zpsex,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %&gt;% # zahlenwerte in zpsex mit labels überschreiben \n  mutate(schul2_fct = factor(schul2, levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))) %&gt;% # auch für schul2\n  tabyl(schul2_fct,zpsex_fct) %&gt;%\n    adorn_totals(where = c(\"row\",\"col\")) \n\n     schul2_fct Männer Frauen Total\n           ohne     21      4    25\n   Förderschule      2      0     2\n    Hauptschule     60     41   101\n Mittlere Reife     96    134   230\n        FOS/BOS     26     25    51\n            Abi    112    104   216\n          Total    317    308   625\n\n\n\n\n\n\n\n\nÜbrigens: Mit adorn_percentages() können wir bspw. statt absoluten Häufigkeiten die prozentualen Anteile ausgeben lassen. Weitere adorn_...() Funktionen in der Vignette.\n\n\n\n\npend14 %&gt;% \n  mutate(zpsex_fct = factor(zpsex,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %&gt;% # zahlenwerte in zpsex mit labels überschreiben \n  mutate(schul2_fct = factor(schul2, levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))) %&gt;% # auch für schul2\n  tabyl(schul2_fct,zpsex_fct) %&gt;%\n    adorn_totals(where = c(\"row\",\"col\"))  %&gt;%\n  flextable() %&gt;%\n  border_remove() %&gt;% # linien raus\n  hline(i=6) %&gt;% # in zeile 4 eine Linie einfügen\n  hline_top() %&gt;% # linie oben\n  set_header_labels(schul2_fct = \"Ausbildung\") %&gt;%  # kopf-label links\n  add_header_row(values = c(\"\",\"Geschlecht\",\"\"),colwidths = c(1,2,1)) # label oben\n\nGeschlechtAusbildungMännerFrauenTotalohne21425Förderschule202Hauptschule6041101Mittlere Reife96134230FOS/BOS262551Abi112104216Total317308625\n\n\n\ncross_tab &lt;- \n  pend14 %&gt;% \n    mutate(zpsex_fct = factor(zpsex,levels = 1:2, labels = c(\"Männer\",\"Frauen\"))) %&gt;% # zahlenwerte in zpsex mit labels überschreiben \n    mutate(schul2_fct = factor(schul2, levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))) %&gt;% # auch für schul2\n    tabyl(schul2_fct,zpsex_fct) %&gt;%\n      adorn_totals(where = c(\"row\",\"col\"))  %&gt;%\n    flextable() %&gt;%\n    border_remove() %&gt;% # linien raus\n    hline(i=6) %&gt;% # in zeile 4 eine Linie einfügen\n    hline_top() %&gt;% # linie oben\n    set_header_labels(schul2_fct = \"Ausbildung\") %&gt;%  # kopf-label links\n    add_header_row(values = c(\"\",\"Geschlecht\",\"\"),colwidths = c(1,2,1)) # label oben\n\n\nsave_as_docx(\"Kreuztabelle\" = cross_tab, path = \"./results/Kreuztabelle.docx\")\n\n\n\n9.7.2 Layout-Tipps für Tabellen\nHier finden sich einige Hinweise von Claus Wilke für ein gelungenes Tabellen-Layout:\n\nDo not use vertical lines.\nDo not use horizontal lines between data rows. Horizontal lines as separator between the title row and the first data row or as frame for the entire table are fine.\nText columns should be left aligned.\nNumber columns should be right aligned and should use the same number of decimal digits throughout.\nColumns containing single characters are centered.\nThe header fields are aligned with their data, i.e., the heading for a text column will be left aligned and the heading for a number column will be right aligned.\n\n\n\n9.7.3 weitere Pakete\nNeben {flextable} gibt es noch eine ganze Reihe an weiteren Paketen - allerdings sind zielen diese vor allem auf pdf und HTML-Formate. Hier findet sich eine gelungene Übersicht. Hier eine Übersicht mit meiner persönlichen Einschätzung.\n\n{kableExtra} - mein Favorit für Tabellen in html und pdf Outputs.\n{gt} Großes Projekt mit sehr vielen Möglichkeiten, Tabellen auch interaktiv zu gestalten - daher vor allem für HTML-Outputs geeignet.\n{gtsummary} - {gt} speziell für Deskriptionen eines Treatment/Control Vergleich, hier eine aktuelle Einführung",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellenexport</span>"
    ]
  },
  {
    "objectID": "references_translated.html",
    "href": "references_translated.html",
    "title": "Links & Further Reading",
    "section": "",
    "text": "%&gt;% vs. |&gt;\nIn this course, we have used the pipe %&gt;% from {tidyverse} (technically from the {magrittr} package). With the update to R 4.1, a pipe |&gt; was also introduced in base R, and help pages and other resources are slowly but surely replacing %&gt;% with |&gt;. For (almost) all applications we’ve learned, both pipes behave identically. Since older R versions are still installed at the IAB, we have stuck to the ‘old version’. However, there’s nothing wrong with switching to |&gt; after an update—or simply sticking with %&gt;%.\nYou can find more about the differences here between the two pipes. Additionally, this blog post offers a good overview of the pitfalls when switching from %&gt;% to |&gt;.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#anonymfun",
    "href": "references_translated.html#anonymfun",
    "title": "Links & Further Reading",
    "section": "Anonymous Functions: .x vs. \\(x)",
    "text": "Anonymous Functions: .x vs. \\(x)\nWith R 4.1.0, a new ‘anonymous function shorthand’ was introduced in base R, replacing the ‘formula syntax’ notation ~mean(.x) that we learned in Chapter 6. In the new base R, it would be written as \\(x) mean(x).\nFrom the {purrr} release notes for version 1.0.0 (December 2022): We believe that it’s better to use these new base tools because they work everywhere: the base pipe doesn’t require that you load magrittr and the new function shorthand works everywhere, not just in purrr functions. Additionally, being able to specify the argument name for the anonymous function can often lead to clearer code.\nAccordingly, the application in across() would look like this:\n\nsat_small &lt;- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",n_max = 16) %&gt;% \n    select(F1450_04,F1450_05,F1450_06) %&gt;% \n    slice(12:16)\n\n# formula syntax\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"), ~mean(.x)))\n# anonymous function shorthand\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"), \\(x) mean(x) ))\n\nIn this script, I have relied on the previous ‘formula syntax’ notation, as most help pages currently still use this syntax.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#introductions-to-r",
    "href": "references_translated.html#introductions-to-r",
    "title": "Links & Further Reading",
    "section": "Introductions to R",
    "text": "Introductions to R\nA collection of teaching scripts and materials from various contexts for self-learning:\nR for Data Science the standard work for data analysis with {tidyverse} - very intuitive introduction, focus on Data Science.\nProblem-oriented introductions to specific applications “do more with R”.\nTen simple rules for teaching yourself R.\nModern Data Analysis with R: A German-language introduction to {tidyverse}.\nR for the Rest of Us offers many tutorials and free courses, including many YouTube videos.\nStata 2 R is aimed at Stata users who want to switch to R. However, it shows the {data.table} package for data processing instead of {tidyverse}. {data.table} is very fast but has a somewhat more cumbersome syntax compared to {tidyverse}. For those working with very large datasets, it’s worth trying out {data.table}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#rmarkdown",
    "href": "references_translated.html#rmarkdown",
    "title": "Links & Further Reading",
    "section": "RMarkdown",
    "text": "RMarkdown\n{rmarkdown} allows you to combine formatted text elements with Markdown and R code or output. Unlike an R script, an RMarkdown document contains not only commands but also text that can be formatted using Markdown commands. This way, graphics, tables, etc., can be created directly alongside the accompanying text. With R Markdown, we can create HTML, PDF, Word documents, PowerPoint and HTML presentations, websites, and books. This entire website was created with {R Markdown} or the related package {Quarto}.\nThe help pages and documentation for R Markdown are extensive, and the tutorials and cheatsheets are excellent. Therefore, here’s just a brief overview.\n\nMarkdown Syntax\nAn RMarkdown document in its basic form looks something like this:\n---\ntitle: \"My First RMarkdown Document\"\nauthor: \"My Name\"\ndate: \"2022-09-11\"\noutput: pdf_document\n---\n  \n# Heading 1\n\n## Subheading 2\n\nThis is an R Markdown document. \nMarkdown is a simple syntax for creating HTML, PDF, and MS Word documents. \nText can be **bold** and *italic*. \n\nWhen we click the **Knit** button, a document is created.\nThat contains both the content and the output of any embedded R code chunks within the document. \nAn R code chunk looks like this:\n\n```{r cars}\n# this is where the R code goes\nsummary(mtcars$qsec)\n```\n\n\n\n\n\n\n\n\n\n\n\nExample\nPaper on a sample dataset, written entirely in R Markdown\nYou can find the source code here.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#cheatsheets",
    "href": "references_translated.html#cheatsheets",
    "title": "Links & Further Reading",
    "section": "Cheatsheets",
    "text": "Cheatsheets\nA collection of cheatsheets for a wide range of applications is available here.\n\nData visualization with {ggplot2}.\nData manipulation with {dplyr}.\nReshaping/creating datasets with {tidyr}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#ggplot2",
    "href": "references_translated.html#ggplot2",
    "title": "Links & Further Reading",
    "section": "{ggplot2}",
    "text": "{ggplot2}\nA significant strength of ggplot2 is the numerous extensions that allow you to\n\nCombine multiple plots with {patchwork}.\nCreate maps with sf, another link.\nUse advanced text formatting with {ggtext}.\nCreate animated graphics with {gganimate} - an introduction or here.\nInsert logos into {ggplot2} with {ggpath}.\n\nAn overview of extension packages for {ggplot2} can be found here.\nAlso, The R Graph Gallery provides an excellent overview of visualization possibilities with syntax examples for {ggplot2}.\n\nTutorial by Cédric Scherer.\nSession on more intuitive graphics by Cara Thompson.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#purrr",
    "href": "references_translated.html#purrr",
    "title": "Links & Further Reading",
    "section": "Advanced use of lapply()/map() with custom functions",
    "text": "Advanced use of lapply()/map() with custom functions\n\nComprehensive introduction to loops with map() and other functions from {purrr} Hendrik van Broekhuizen.\nModel series: Blog by Tim Tiefenbach on elegant possibilities.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#regex",
    "href": "references_translated.html#regex",
    "title": "Links & Further Reading",
    "section": "regex",
    "text": "regex\nFor working with text variables, regular expressions (regex) are a great help. They allow you to search for specific character sequences in text sections, replace them, etc. Joshua C. Fjelstul’s blog is a good starting point. There’s also a helpful cheatsheet for regex in R and the regex package {stringr}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#further-resources",
    "href": "references_translated.html#further-resources",
    "title": "Links & Further Reading",
    "section": "Further Resources",
    "text": "Further Resources\n{easystats} offers a collection of packages that make statistical analysis easier and more unified. However, this unification comes with somewhat limited flexibility—it’s a matter of taste and depends on the application. We have used {performance} and {effectsize} from the easystats universe.\nEvent History Models / Event History Modeling / Survival Analysis.",
    "crumbs": [
      "Links & Further Reading"
    ]
  }
]