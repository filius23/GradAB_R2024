[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GradAB R Intro 2024",
    "section": "",
    "text": "Welcome!\nIntroduction to R for GradAB and IAB people.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#course-dates",
    "href": "index.html#course-dates",
    "title": "GradAB R Intro 2024",
    "section": "Course dates",
    "text": "Course dates\n\n   E09\n   11.09.2024      10:30 – 16:00\n   13.09.2024      8:30 – 15:30",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Getting started with R",
    "section": "",
    "text": "1.1 Installing and Setting Up R & RStudio\nR is a completely free program that you can download from CRAN. The RStudio extension is also free and can be downloaded here. RStudio enhances R by providing a significantly more informative and appealing interface, help, and auto-completion when writing syntax, as well as an overall improved user interface. However, RStudio is an extension of R, so you need both programs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#installing-and-setting-up-r-rstudio",
    "href": "01_intro.html#installing-and-setting-up-r-rstudio",
    "title": "1  Getting started with R",
    "section": "",
    "text": "Install R first and then RStudio, so that RStudio recognizes the installed R version, and the two programs usually connect automatically. R is essentially the engine, and RStudio is our cockpit. We could work directly with R, but RStudio offers a more comfortable option and a better overview.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.1: R and RStudio",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#setting-up-rstudio",
    "href": "01_intro.html#setting-up-rstudio",
    "title": "1  Getting started with R",
    "section": "1.2 Setting Up RStudio",
    "text": "1.2 Setting Up RStudio\nAfter successful installation, open the RStudio application  and you should see the following view:\n\nTo avoid problems when working with R in the future, please disable the automatic saving and loading of the workspace. To do this, go to the appropriate menu under the “Tools -&gt; Global options” tab, disable “Restore .RData into workspace at startup,” and set “Save workspace to .RData on exit:” to Never. Otherwise, RStudio will save all loaded objects when you end the session and automatically load them the next time you open the program, which can lead to problems.\n\nConfirm the settings with “Apply” and close the window with “OK.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#first-steps-in-r",
    "href": "01_intro.html#first-steps-in-r",
    "title": "1  Getting started with R",
    "section": "1.3 First Steps in R",
    "text": "1.3 First Steps in R\nAfter these basic settings, we can start with the first steps in R. To do this, first open a script by clicking on the white icon in the top left corner or pressing CTRL/Command + Shift + N simultaneously.\n\nA fourth window opens, so you should now see the following view:\n\nThis script editor is where we will create and execute commands. The script editor serves as a collection of all commands to be executed. We can save these collections to revisit them later, and, more importantly, we can share command collections with others or use scripts from others for ourselves. So, we first draft a calculation in the script editor:\n\nTo execute it, click on the line to be executed so that the cursor is in that line, and then press CTRL and Enter simultaneously (Mac users: Command and Enter):\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Shortcuts for Calculations\n\n\n\nR outputs the results in the console below:\n\nThis also works for multiple calculations at once by selecting multiple lines and then pressing CTRL and Enter again (Mac users: Command and Enter):\n\nInputs from the script editor and results from the console will be presented like this in the future:\n\n2+5\n\n[1] 7\n\n3-4\n\n[1] -1\n\n5*6\n\n[1] 30\n\n7/8\n\n[1] 0.875\n\n\nOf course, R also handles longer calculations, such as following the order of operations:\n\n2+3*2\n\n[1] 8\n\n(2+3)*2\n\n[1] 10\n\n\nOther operations are also possible:\n\n4^2 ## 4²\nsqrt(4) ## Square root \nexp(1) ## Exponential function (Euler's number)\nlog(5) ## Natural logarithm\nlog(exp(5)) ## log and exp cancel each other out\n\nWe can create sequences of numbers using seq() or ::\n\n2:6\n\n[1] 2 3 4 5 6\n\nseq(2,11,3)\n\n[1]  2  5  8 11\n\n\n\n1.3.1 Creating Objects\nSo far, we have always displayed our calculations directly. For more extensive calculations—since we want to work with datasets starting in the next chapter—we want to save the intermediate steps.\nResults can be saved as objects under any name using &lt;-. R will then not display the result but will repeat the command in the console:\n\nx &lt;- 4/2\n\nIn the “Environment” window at the top right, you can now see the stored object x:\n\nWe can retrieve it later:\n\nx\n\n[1] 2\n\n\nAdditionally, we can use objects in calculations—we simply use x and create, for example, y:\n\ny &lt;- x * 5\ny\n\n[1] 10\n\n\n\n\n\n1.3.2 Storing Multiple Values\nWith c(), we can store multiple values under one object, and these can also be used in calculations:\n\nx1 &lt;- c(1,2,3)\nx1\n\n[1] 1 2 3\n\nx1* 2\n\n[1] 2 4 6\n\n\nWith length(), we can check the number of stored values:\n\nlength(x1)\n\n[1] 3\n\n\n\ny1 &lt;- c(10,11,9)\ny1\n\n[1] 10 11  9\n\ny1/x1\n\n[1] 10.0  5.5  3.0\n\n\nls() lists all existing objects, we can use the pattern = option to display only objects with a name that contains “1”:\n\nls()\n\n[1] \"path\" \"x\"    \"x1\"   \"y\"    \"y1\"  \n\nls(pattern = \"1\")\n\n[1] \"x1\" \"y1\"\n\n\n\n\n1.3.3 Deleting Values\nOf course, we can also delete objects using rm(). If we try to call a non-existent object, we will get an error message:\n\nrm(x1)\nx1\n\nError in eval(expr, envir, enclos): Objekt 'x1' nicht gefunden\n\n\nWith rm(list = ls()), all objects can be removed from the environment.\n\n\n1.3.4 Saving Scripts\nWe can save the script to call it again later.\n\nIt is important to give the saved file the extension “.R”, for example, “01_Script.R”.\n\n\n1.3.5 Comments\nBesides the actual commands, comments are a central part of a data analysis syntax. This allows future users (especially ourselves in 3 weeks or 2 years) to understand what is happening. Comments in R can be added with #:\n\n2+ 5 # this is a comment\n\n[1] 7\n\n2+ # a comment can also be placed here\n  5\n\n[1] 7\n\n\n\n( 2 + # a \n    3) * # comment\n  2 # across multiple lines\n\n[1] 10\n\n\nTip: It’s best to create a folder right away where you can store all R scripts and datasets from this course.\n\n\n1.3.6 Structuring Scripts\n\n# Heading 1 ----\n\n## Section 1.1 ----\n3+2*4\n3+2*3\n## Section 1.2 ----\n3+2*sqrt(3)\n\n# Heading 2 ----\nx &lt;- c(2,6,8,2,35)\ny &lt;- seq(2,10,2)\n\ny/x",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#exercises",
    "href": "01_intro.html#exercises",
    "title": "1  Getting started with R",
    "section": "1.4 Exercises",
    "text": "1.4 Exercises\n\nStore the number of students at the University of Oldenburg (15643) in stud.\nStore the number of professorships at the University of Oldenburg (210) in prof.\nCalculate the number of students per professorship at the University of Oldenburg using the objects stud and prof.\nStore the result in studprof and recall the object again!\nDo you see the created variables in the Environment window?\nStore the student numbers of the University of Bremen (19173), University of Vechta (5333), and University of Oldenburg (15643) together in studs.\nStore the number of professors at the University of Bremen (322), University of Vechta (67), and University of Oldenburg (210) together in profs.\nCalculate the number of students per professorship for all three universities.\nYou also want to include the student numbers (14000) and professorships (217) of the University of Osnabrück in studs and profs. How would you do that?\nCalculate the ratio of students to professorships for all four universities!\nDelete the object stud. How can you tell that it worked?\nDelete all objects from the Environment. How can you tell that it worked?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "02_intro.html",
    "href": "02_intro.html",
    "title": "2  Working with Datasets",
    "section": "",
    "text": "2.1 Data Structures in R: data.frame\nIn the previous chapter, we combined the student numbers of the University of Bremen (19173), University of Vechta (5333), and University of Oldenburg (15643) under studs and related them to the professor numbers stored in profs. While this works fine, it is more organized to store related values together. For this, R provides the data.frame. We can store the two objects in a dataset by entering them into data.frame and storing the new object under dat1. When we call dat1, we see that the values have been combined row by row:\nstuds &lt;- c(19173, 5333, 15643)  # Store student numbers under \"studs\"\nprofs &lt;- c(322, 67, 210)        # Store professor numbers under \"profs\"\ndat1_orig &lt;- data.frame(studs, profs)\ndat1_orig\n\n  studs profs\n1 19173   322\n2  5333    67\n3 15643   210\ndat1 &lt;- data.frame(studs = c(19173, 5333, 15643), \n                   profs = c(322, 67, 210),\n                   gegr  = c(1971, 1830, 1973)) # Without intermediate objects\ndat1    # Display the entire dataset\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\nIn the first row, we see the values for the University of Bremen, in the second row for the University of Vechta, and so on. We can access the columns using dataset_name$variable_name. For example, we can display the profs column:\ndat1$profs \n\n[1] 322  67 210\nWe can display the variable/column names of the dataset with colnames()/names(). Additionally, we can call the number of rows and columns using nrow and ncol:\ncolnames(dat1) ## Display variable/column names\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nnames(dat1) ## Display variable/column names\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nncol(dat1) ## Number of columns/variables\n\n[1] 3\n\nnrow(dat1) ## Number of rows/cases\n\n[1] 3\nWe can add new variables to the dataset by using dataset_name$new_variable:\ndat1$stu_prof &lt;- dat1$studs/dat1$profs\n## dat1 now has one more column:\nncol(dat1) \n\n[1] 4\n\ndat1\n\n  studs profs gegr stu_prof\n1 19173   322 1971 59.54348\n2  5333    67 1830 79.59701\n3 15643   210 1973 74.49048\nWe can also store one or more words in a variable, but letters/words must always be enclosed in \"\".\ndat1$uni &lt;- c(\"Uni Bremen\", \"Uni Vechta\", \"Uni Oldenburg\")\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\nWith View(dat1), a new window opens where we can view the entire dataset:\nView(dat1)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#data-types-in-r",
    "href": "02_intro.html#data-types-in-r",
    "title": "2  Working with Datasets",
    "section": "2.2 Data Types in R",
    "text": "2.2 Data Types in R\nSo far, we have encountered two variable types: numeric (contains numbers) and character (contains text or numbers that are understood as text). We also learned an organization method: data.frame.\nThe following variable types in R are important for us:2\n\n\n\n\n\n\n\n\n\n\n\n\nVectors (Variables)\n\n\n\n\ninteger  double\nNumeric values (numeric)\n\n\ncharacter\nText (or numbers understood as text)\n\n\nfactor\nText or numbers understood as text with predefined sorting and fixed value universe\n\n\nlogical\nTRUE or FALSE—mostly the result of a comparison (greater/less/equal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombined Vectors\n\n\n\n\ndata.frame  tibble\nTwo-dimensional data structure organized in tabular form—tibble is an enhancement of data.frame in the tidyverse (more on this later)\n\n\nlist\nOrdered collection of vectors of different types—can contain other value types, data.frame, or even other lists\n\n\n\n\n\n\n\nFor now, we focus on character and numeric variables. We will discuss the other types when they are needed. With class(), we can examine the type of a variable, or with is.numeric() or is.character(), we can check whether a variable belongs to a certain type:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\nclass(dat1$uni)\n\n[1] \"character\"\n\n\nWe can enforce a type change with as.character() or as.numeric():\n\nas.character(dat1$profs) ## The \"\" indicate that the variable is defined as character\n\n[1] \"322\" \"67\"  \"210\"\n\n\nThis does not change the original variable dat1$profs:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\n\nIf we want to keep this conversion for dat1$profs, we need to overwrite the variable:\n\ndat1$profs &lt;- as.character(dat1$profs)\nclass(dat1$profs)\n\n[1] \"character\"\n\n\nWe cannot perform calculations with character variables, even if they contain numbers:\n\ndat1$profs / 2 \n\nError in dat1$profs/2: nicht-numerisches Argument für binären Operator\n\n\nHowever, we can convert dat1$profs to numeric on the fly to perform calculations:\n\nas.numeric(dat1$profs) / 2\n\n[1] 161.0  33.5 105.0\n\n\nIf we convert text variables to numeric, calculations result in NA. NA in R stands for missing values:\n\nas.numeric(dat1$uni)\n\nWarning: NAs durch Umwandlung erzeugt\n\n\n[1] NA NA NA\n\n\nR, understandably, does not know how to convert university names into numbers.\n\n\n\n\n\n\nA common issue in calculations is due to incorrect variable types.\n\n\n\n\n2.2.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#selecting-rows-columns",
    "href": "02_intro.html#selecting-rows-columns",
    "title": "2  Working with Datasets",
    "section": "2.3 Selecting Rows & Columns",
    "text": "2.3 Selecting Rows & Columns\nA typical task when working with datasets is selecting rows (“cases”) and columns (“variables”).\nFor this, R in its base version3 provides a selection method using []. The basic structure is [row_selection, column_selection]. Leaving out the part before or after the comma selects all rows/columns. Be careful: forgetting the comma is a common source of errors in R.\n\ndat1 # complete dataset\ndat1[1,1] # first row, first column\ndat1[1,]  # first row, all columns\ndat1[,1]  # all rows, first column (equivalent to dat1$studs)\ndat1[,\"studs\"] # all rows, column named studs -&gt; note: \"\"\n\nIn these square brackets, you can also write conditions to make selections from dat1.\n\ndat1[dat1$studs &gt; 10000, ] # rows where studs is greater than 10000, all columns\ndat1[dat1$studs &gt; 10000 & dat1$profs &lt; 300, ] # & means AND\ndat1$profs[dat1$studs &gt; 10000] # Only see the number of professors: no comma\n\nRepetitive use of the dataset name in the [] makes the syntax quite long and somewhat tedious. Therefore, there is a better/more convenient solution. We use the {dplyr} package4.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#packages",
    "href": "02_intro.html#packages",
    "title": "2  Working with Datasets",
    "section": "2.4 Packages in R",
    "text": "2.4 Packages in R\nPackages are extensions for R that include additional functions.  Packages need to be installed once and then loaded before use in a new session (i.e., after every restart of R/RStudio). install.packages() performs the installation, and library() loads the packages:\n\ninstall.packages(\"Package\") # only needed once on your PC\nlibrary(Package) # needed after every restart\n\nOften, when using install.packages(), not only the specified package is downloaded but also a number of other packages, the so-called “dependencies”. These are packages used in the background to enable the functions of the desired package. So don’t be surprised if the installation takes a bit longer.\nWith install.packages() we essentially screw in the light bulb in R, with library() we flip the switch so we can use the functions from the package. Each restart turns the light bulb off again, and we need to turn it back on with library(). The advantage is that we don’t have to turn on all the light bulbs at once when starting R.\n\n\n\n\n\nSource: Dianne Cook\n\n\n\n\n\n\n\n\n\n\ninstall.packages() in the IAB Network\n\n\n\nPackages in R are typically installed from CRAN. This is not possible on the servers at IAB due to isolation from the internet. This restricts package installation in R to the collection maintained by DIM under N:/Ablagen/D01700-Allgemein/R/bin/windows/contrib/.\nA central challenge in installing from local zip files is handling dependencies: packages that the desired package relies on. When installing from the internet, dependencies are automatically installed, but with a local installation, this is not the case.\nAt IAB, some workarounds exist, and currently, I have a solution in progress at FDZ based on a .Rprofile file that provides the fdz_install() command, which behaves like the standard install.packages() command (or should, at least).\nThe most recent version of the .Rprofile file can be found under N:\\Ablagen\\D01700-Quickablage\\Filser\\R_2024\\prog.\nPlace the .Rprofile file in C:\\Users\\*YOUR_USERNAME*\\Documents and restart R (CTRL + F10), you should then see a similar message in the console:\n\n----------------------------------------\nIAB-FDZ .Rprofile\nVersion 0.5\n----------------------------------------\n- Local repository: N:/Ablagen/D01700-Allgemein/R/bin/windows/contrib/4.2\n- Working directory: N:/Ablagen/D01700-FDZ/Quickablage/AndreasF/R-Kurs\n \n- Default package library: C:/Users/FilserA001.IAB/AppData/Local/R/win-library/4.2\n- HOME directory: C:/Users/FilserA001.IAB/Documents\n- R_home directory: C:/PROGRA~1/R/R-4.2.1\n----------------------------------------\n\nMore about RProfile\n\n\n\n\n\n\n\n\nLoading packages once\n\n\n\n\n\nIn addition to library(), you can also call functions from packages using :::\n\npackage::function()\n\nThis option is often used when only one function from a package is used or to clarify which package the function comes from. It can also help with issues if a command from another package has the same name—this will override the previous command (usually with a warning), which might look like:\n\nThe following objects are masked from ‘package:dplyr’:\n\n    between, first, last\n\nThe following object is masked from ‘package:purrr’:\n\n    transpose\n\nThis can be avoided by not fully loading certain packages but only calling the necessary functions with ::.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#tidyverse",
    "href": "02_intro.html#tidyverse",
    "title": "2  Working with Datasets",
    "section": "2.5 {tidyverse}",
    "text": "2.5 {tidyverse}\nIn this course, we will mainly work with packages from the {tidyverse}. The tidyverse is a collection of packages that share common syntax logic and thus harmonize particularly well and cover a broad range of use cases. With\n\ninstall.packages(\"tidyverse\")\nfdz_install(\"tidyverse\") # on IAB servers with .Rprofile\n\nthe following packages are installed:\nbroom, conflicted, cli, dbplyr, dplyr, dtplyr, forcats, ggplot2, googledrive, googlesheets4, haven, hms, httr, jsonlite, lubridate, magrittr, modelr, pillar, purrr, ragg, readr, readxl, reprex, rlang, rstudioapi, rvest, stringr, tibble, tidyr, xml2, tidyverse\nWe will get to know some of them during the course. The initially most important one is {dplyr}, which makes selecting cases and variables easier:\n\n\n\n\n\nIllustration based on the {dplyr} Cheatsheet\n\n\n\n\nBut installation is only the first step; we need to load the package with library():\n\nlibrary(tidyverse) # after once using install.packages(\"tidyverse\")\n\n\n2.5.1 Chaining Commands with %&gt;%\nIn R, dplyr and other {tidyverse} packages use %&gt;% (the pipe operator) to chain commands. This is a way to streamline commands and improve readability:\n\ndat1 %&gt;%\n  filter(studs &gt; 10000) %&gt;%\n  select(uni,studs)\n\n            uni studs\n1    Uni Bremen 19173\n2 Uni Oldenburg 15643\n\n\nHere, %&gt;% takes the output of one function and passes it as an input to the next function. This operator allows you to read and write code that closely resembles natural language. %&gt;%[^pipe] simply stands for “and then”.\n\nCall dat1 and then (%&gt;%)\nSelect only rows where studs &gt; 10000 and then (%&gt;%)\nKeep only the uni column\n\n\ndat1 %&gt;% filter(.,studs &gt; 10000) %&gt;% select(.,uni) # the dot represents the result of the previous step\n\nUsually it’s written just like this\n\ndat1 %&gt;% filter(studs &gt; 10000) %&gt;% select(uni)\n\n            uni\n1    Uni Bremen\n2 Uni Oldenburg\n\n\n\n\n\n\n\n\nThe shortcut for %&gt;% is STRG+SHIFT+m (cmd+shift+m on Mac)\n\n\n\nLet’s a have a closer look at filter() and select():\n\n\n2.5.2 Selecting Observations with filter()\nWith filter(), we can select rows from dat1 based on conditions:\n\ndat1 %&gt;% filter(uni == \"Uni Oldenburg\", studs &gt; 1000)\n\n  studs profs gegr stu_prof           uni\n1 15643   210 1973 74.49048 Uni Oldenburg\n\n\nThe selection does not change the original object dat1:\n\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\nIf we want to keep the result of our selection with filter() for further steps, we can store it in a new data.frame object:\n\nover_10k &lt;- filter(dat1, studs &gt; 10000)\nover_10k\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n\n\n\n\n\n\n\n\nfilter() helpers\n\n\n\n\n\n{dplyr} provides a number of helpers for filter():\n\ngreater/smaller than or equal to: &lt;= &gt;=\nor: |\none of: %in%\nwithin a given range: between()\n\n\nfilter(dat1, studs &gt;= 10000)\nfilter(dat1, studs &lt;= 10000)\nfilter(dat1,studs &gt; 10000 | profs &lt; 200) # more than 10.000 Students *or* less than 200 professors\nfilter(dat1, gegr %in% c(1971,1830)) # founded 1971 or 1830\nfilter(dat1, between(gegr,1971,1830)) # founded between 1971 and 1830 (including)\n\n\n\n\n\n\n2.5.3 Selecting variables with select()\nselect() allows us to select specific columns:\n\ndat1 %&gt;% select(uni,studs) # columns uni and studs\n\n            uni studs\n1    Uni Bremen 19173\n2    Uni Vechta  5333\n3 Uni Oldenburg 15643\n\n\n\ndat1 %&gt;% select(1:3) # column 1-3\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\n\ndat1 %&gt;% select(-profs) # all but profs\n\n  studs gegr stu_prof           uni\n1 19173 1971 59.54348    Uni Bremen\n2  5333 1830 79.59701    Uni Vechta\n3 15643 1973 74.49048 Uni Oldenburg\n\n\n\n\n\n\n\n\nselect() helpers\n\n\n\n\n\n\ncontains(\"b\"): Variable name contains ..., see select(dat1,contains(\"b\"))\nmatches(): Variable selection using regular expressions, see select(dat1,matches(\"b$\")): all variables ending on a b\n\n\n\n\n\n\n2.5.4 Selecting Rows with slice()\nA first function from {tidyverse} is slice(), which allows us to select rows:\n\nslice(dat1,1) # first row\nslice(dat1,2:3) # rows 2-3\nslice(dat1,c(1,3)) # rows 1 and 3\n\n\n\n2.5.5 Sorting data with arrange()\nAnother common task in data analysis is sorting datasets. For this, we use arrange():\n\ndat1 %&gt;% arrange(studs)\n\n  studs profs gegr stu_prof           uni\n1  5333    67 1830 79.59701    Uni Vechta\n2 15643   210 1973 74.49048 Uni Oldenburg\n3 19173   322 1971 59.54348    Uni Bremen\n\n\nThis also works for string variables:\n\ndat1 %&gt;% arrange(uni)\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n3  5333    67 1830 79.59701    Uni Vechta\n\n\nOf course, we can also sort by multiple variables; we just add more to arrange() and we can sort in descending order using desc():\n\ndat1 %&gt;% arrange(desc(gegr), studs)\n\n  studs profs gegr stu_prof           uni\n1 15643   210 1973 74.49048 Uni Oldenburg\n2 19173   322 1971 59.54348    Uni Bremen\n3  5333    67 1830 79.59701    Uni Vechta\n\n\n(This doesn’t make much sense in this example.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#variable-type-factor",
    "href": "02_intro.html#variable-type-factor",
    "title": "2  Working with Datasets",
    "section": "2.6 Variable type factor",
    "text": "2.6 Variable type factor\nBut what if we want to assign a specific order that doesn’t follow numeric or alphabetical order? For example, if we want to order the universities as follows: 1) Uni Oldenburg, 2) Uni Bremen, and 3) Uni Vechta.\nThis is where a third variable type comes in: factor.\nWith the levels = argument, we can define an order:\n\nfactor(dat1$uni, levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\n[1] Uni Bremen    Uni Vechta    Uni Oldenburg\nLevels: Uni Oldenburg Uni Bremen Uni Vechta\n\ndat1$uni_fct &lt;- factor(dat1$uni, \n                       levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\nIf we now sort by uni_fct, the order of the levels is respected:\n\nclass(dat1$uni_fct)\n\n[1] \"factor\"\n\ndat1 %&gt;% arrange(uni_fct)\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n\n\nThis may seem trivial at the moment but is very useful later for ordering variables in plots or setting the reference category in regression models.\n\n2.6.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#rproj",
    "href": "02_intro.html#rproj",
    "title": "2  Working with Datasets",
    "section": "2.7 Setting up a project",
    "text": "2.7 Setting up a project\nIn general, it’s worth setting up projects in RStudio. Projects are .Rproj files  that automatically set the working directory to where they are saved. This simplifies collaborative work: no matter who is working on a project or on which device, the project file ensures all paths are always relative to the project directory. Furthermore, version control via git, e.g., github, and other functions can be set in the project file for all users. Also, the last open scripts remain open, making it easier to work on multiple projects.\n\n\n\n\n\n\n\n\n\nWith getwd(), we can check if it worked:\n\ngetwd()\n\n\n\n[1] \"D:/Courses/R-Course\"\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, we could create an .Rproj project with the following command (here’s an example of calling a package with ::):\n\nrstudioapi::initializeProject(path = \"D:/Courses/R-Course\")\n\nWe can open the project with:\n\nrstudioapi::openProject(path = \"D:/Courses/R-Course\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#import",
    "href": "02_intro.html#import",
    "title": "2  Working with Datasets",
    "section": "2.8 Importing datasets",
    "text": "2.8 Importing datasets\nIn most cases, we’ll use datasets that are already saved in a file and just need to be imported. There are countless ways to do this.\nIn this seminar, we’ll work with the Campus-File of PASS, whose parts are available as Stata files.\nTo import the dataset into R, we need to tell R the file path where the dataset is located. The file path depends on your device’s folder structure; in this case, it would be “D:/Courses/R-Course/”.\nOf course, the file path depends on where you saved the dataset:\n\n\n\n\n\n\n\n\n\nWe need to inform R of this file path.\n\n2.8.1 The import command\nNow we can use the actual import command read.table. For the path, we can just enter the quotation marks after file = and press the Tab key. Then we’ll see all subdirectories and tables in the project folder.5\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\") \n\nThe import process consists of two parts: first, we specify the object name as pend, under which R will store the dataset. After the &lt;- is the actual read_dta() command, which contains several options. First, we specify the exact dataset name, including the file extension.\n\n\n\n\n\n\nR has problems with Windows-style \\ in file paths\n\n\n\n\n\nUnfortunately, Windows systems use \\ in file paths, which causes problems in R. Therefore, file paths must always be specified with / or alternatively with \\\\. RStudio can help a bit with the CTRL + F/Search & Replace function.\n\n\n\nThe object created is a data.frame:\n\nclass(pend)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTechnically, it’s a tibble—an enhanced version of data.frame in the tidyverse that includes labels and provides additional information in its display, such as variable classes in the first row.\nIf we were to simply type pend here, the entire dataset would be displayed. For an overview, we can use head:\n\nhead(pend)\n\n# A tibble: 6 × 123\n         pnr      hnr welle   pintjahr pintmon pintmod  zpsex   palter PD0400   \n       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt;\n1 1000001901 10000019 1 [Wav… 2007     5 [May]  1 [CAP… 2 [Fem… 36       2 [Rat…\n2 1000001902 10000019 1 [Wav… 2007     5 [May] NA       1 [Mal… 39       2 [Rat…\n3 1000001901 10000019 3 [Wav… 2009     3 [Mar…  1 [CAP… 2 [Fem… 38      -9 [Ite…\n4 1000002001 10000020 1 [Wav… 2007     4 [Apr…  1 [CAP… 1 [Mal… 66     -10 [Ite…\n5 1000002002 10000020 1 [Wav… 2007     4 [Apr…  1 [CAP… 2 [Fem… 61       3 [Rat…\n6 1000002002 10000020 2 [Wav… 2008     5 [May]  1 [CAP… 2 [Fem… 62       3 [Rat…\n# ℹ 114 more variables: PA0100 &lt;dbl+lbl&gt;, PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nWith nrow and ncol, we can check if it worked. The dataset should have 28424 rows and 123 columns:\n\nnrow(pend)\n\n[1] 28424\n\nncol(pend)\n\n[1] 123\n\n\nOf course, we can also select rows and columns from this much larger dataset as we did before. For example, we can select the data from 2006 and store it under pend06:\n\npend06 &lt;- pend %&gt;% filter(pintjahr == 2006)\n\nNaturally, pend06 has significantly fewer rows than pend:\n\nnrow(pend06)\n\n[1] 168\n\n\nIf we want to see the exact ages of the respondents from pend06, we can call up the corresponding column with pend06$palter:\n\npend06$palter\n\n&lt;labelled&lt;double&gt;[168]&gt;: Age (W1: gen. from P1; W2 ff.: best info.), gen.\n  [1] 71 66 64 64 63 51 64 65 26 38 41 63 58 58 69 45 59 37 28 63 56 29 29 49 47\n [26] 66 34 22 21 37 36 58 56 80 44 65 61 66 40 53 34 70 69 54 65 62 58 54 51 57\n [51] 72 52 25 34 55 44 68 73 46 87 74 83 46 40 62 58 66 41 53 71 66 79 54 42 68\n [76] 68 81 92 70 66 68 77 44 66 66 67 62 43 35 35 52 54 20 48 48 20 41 24 22 33\n[101] 55 41 50 36 19 52 25 36 37 29 37 36 43 49 16 59 28 19 43 44 30 43 50 50 53\n[126] 52 71 43 58 58 58 38 49 30 27 50 58 26 36 44 28 19 42 44 23 20 33 24 31 32\n[151] 31 44 50 58 45 57 37 62 46 52 50 47 40 62 40 19 28 35\n\nLabels:\n value                                      label\n   -10 Item not surveyed in questionnaire version\n    -9                  Item not surveyed in wave\n    -8                          Implausible value\n    -4              Question mistakenly not asked\n    -3                    Not applicable (filter)\n    -2                            Details refused\n    -1                                 Don't know\n\n\nAs we’ve seen, there are many more variables in PASS than just palter, and not all have such meaningful names—like PD0400. To understand these variable names and the meaning of the values, we need the codebook.\nWe can also access a variable’s attributes()—more on labels later.\n\n\n2.8.2 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#exporting-objects",
    "href": "02_intro.html#exporting-objects",
    "title": "2  Working with Datasets",
    "section": "2.9 Exporting objects",
    "text": "2.9 Exporting objects\n\n\n\n\n\n\nThe term save can sometimes lead to misunderstandings in R: does it mean\n\nsaving a dataset or other object to disk as .csv, .dta, .sav for access by other programs, or\nsimply storing the results internally in R under an object name?\n\nI avoid the word save and instead speak of exporting (Case 1: writing to a file) or storing (Case 2: storing results/values within R in an object).\n\n\n\nThe proprietary format in R for exporting data.frames and reloading afterwards is .RData (comparable to dta in Stata):\n\nsaveRDS(pend06, file = \"./data/pend06.RData\")\nrm(pend06) # delete pend06 from memory\n\npend06_neu &lt;- readRDS(file = \"./data/pend06.RData\")\nhead(pend06) # does not exist anymore -&gt; rm()\n\nError in eval(expr, envir, enclos): Objekt 'pend06' nicht gefunden\n\nhead(pend06_neu,n=1)\n\n# A tibble: 1 × 123\n         pnr      hnr welle   pintjahr pintmon  pintmod zpsex   palter PD0400   \n       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt;\n1 1000402601 10004026 1 [Wav… 2006     12 [Dec… 0 [CAT… 1 [Mal… 71     -10 [Ite…\n# ℹ 114 more variables: PA0100 &lt;dbl+lbl&gt;, PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nWe can also export and restore other objects. However, we need to load() them, which will result in restoring the previous object name:\n\nsave(studs, file = \"./data/stud_vektor.RData\")\nrm(studs)\nstuds\nload(file = \"./data/stud_vektor.RData\") # studs is back with the same object name\nstuds\n\nThis also works for multiple Objects:\n\nsave(studs,profs, file = \"./data/meine_vektoren.RData\")\nrm(studs,profs)\nstuds\nprofs\nload(file = \"./data/meine_vektoren.RData\") # studs & profs restored with the same name\nstuds\nprofs\n\n\n2.9.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#overview-importing-and-exporting-data-sets",
    "href": "02_intro.html#overview-importing-and-exporting-data-sets",
    "title": "2  Working with Datasets",
    "section": "2.10 Overview: Importing and exporting data sets",
    "text": "2.10 Overview: Importing and exporting data sets\n\nImport optionsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nfile type\nR function\nR package\nComment\n\n\n\n\n.csv\nread.table()\n-\nset delimiter with `sep = \";\"`\n\n\n.Rdata (R format)\nreadRDS\n-\n\n\n\ngroße .csv\nvroom()\n{vroom}\nset delimiter using `delim = \";\"`\n\n\n.dta (Stata)\nread_dta()\n{haven}\n\n\n\n.dta (Stata - große Dateien)\nread.dta13()\n{readstata13}\nuse convert.factors = F to import only numeric values\nalso imports files from newer Stata versions\n\n\n.dat (SPSS)\nread_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nread_xlsx()\n{readxl}\nuse `sheet = 1`to specifiy which sheet you want\n\n\n\n\n\n\n\n\n\n\n# csv file\ndat1 &lt;- read.table(file = \"Dateiname.csv\",sep = \";\")\n\n# Rdata\ndat1 &lt;- readRDS(file = \"Dateiname.Rdata\")\n\n# large csv\nlibrary(vroom)\ndat1 &lt;- vroom(file = \"Dateiname.csv\",delim = \";\")\n\n# Stata dta\nlibrary(haven)\ndat1 &lt;- read_dta(file = \"Dateiname.dta\")\n\n# Stata large files\n# faster than read_dta(), but without labels\nlibrary(readstata13)\ndat1 &lt;- read.dta13(file = \"Dateiname.dta\",convert.factors = F) \n\n# SPSS sav\ndat1 &lt;- read_sav(file = \"Dateiname.sav\")\n\n# Excel\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"1\")\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"Tabellenblatt1\")\n\n\n\n\n\nExport optionsCode\n\n\n\n\n\n\n\nfile type\nR function\nR package\nComment\n\n\n\n\n.Rdata (R format)\nsaveRDS()\n-\nall variable properties remain\n\n\n.csv\nwrite.table()\n-\nuse `sep = \";\"` to set delimiter br&gt;use row.names= F to suppress row numbering\n\n\n.dta (Stata)\nwrite_dta()\n{haven}\n\n\n\n.dat (SPSS)\nwrite_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nwrite.xlsx()\n{xlsx}\nuse `sheetName` to select excel sheet\n\n\n\n\n\n\n\n\n\n\n# Rdata\nsaveRDS(dat1,file = \"Dateiname.Rdata\")\n# csv\nwrite.table(dat1,file = \"Dateiname.csv\",sep = \";\",row.names = F)\n# dta\nlibrary(haven)\nwrite_dta(dat1,path = \"Dateiname.dta\")\n# sav\nlibrary(haven)\nwrite_sav(dat1,path = \"Dateiname.sav\")\n# xlsx\nlibrary(xlsx)\nwrite.xlsx(dat1,file = \"Dateiname.xlsx\", sheetName = \"Tabellenblatt 1\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#getting-help",
    "href": "02_intro.html#getting-help",
    "title": "2  Working with Datasets",
    "section": "2.11 Getting help",
    "text": "2.11 Getting help\nR packages (often) come with very detailed help pages, which can either be called up directly from RStudio:\n\n# help for packages\nvignette(\"dplyr\")\nvignette(package = \"dplyr\")\nvignette(\"rowwise\")\nhelp(\"dplyr\")\nhelp(package = \"dplyr\")\n\n\n# help for a specific function\n?select()\n\nAlternatively, googling the package and function mostly gives you what you need R dplyr select()\nOr refer to the CRAN site:\n\n\n\n\n\nCRAN-Seite für {dplyr}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#exercises",
    "href": "02_intro.html#exercises",
    "title": "2  Working with Datasets",
    "section": "2.12 Exercises",
    "text": "2.12 Exercises\n\n2.12.1 Exercise 1\n\nCreate a data.frame object called dat2:\n\n\ndat2 &lt;- data.frame(studs = c(14954,47269 ,23659,9415 ,38079), \n                   profs = c(250,553,438 ,150,636),\n                   prom_recht = c(FALSE,TRUE,TRUE,TRUE,FALSE),\n                   gegr  = c(1971,1870,1457,1818,1995))\n\n\nDo you see dat2 in your environment?\nPrint dat2 in the console.\nAdd the names of the universities as a new column to the dataset. The names are in this order:\n\n\nc(\"FH Aachen\",\"RWTH Aachen\",\"Uni Freiburg\",\"Uni Bonn\",\"FH Bonn-Rhein-Sieg\")\n\n[1] \"FH Aachen\"          \"RWTH Aachen\"        \"Uni Freiburg\"      \n[4] \"Uni Bonn\"           \"FH Bonn-Rhein-Sieg\"\n\n\n\nDisplay dat2 - either in the console or using View().\nCalculate the ratio of students per professor and store the results in a new variable. Check the result.\nDisplay only the third row of dat2.\nDisplay only the third column of dat2.\n\nWhat would you do to copy dat2 into an object called df_unis?\nBack to top\n\n\n\n2.12.2 Exercise 2\n\nCreate a .Rprofile for the package installation in C:\\Users\\*USERNAME*\\Documents.\nInstall the tidyverse packages using fdz_install(\"tidyverse\") after placing the .Rprofile file under C:\\Users\\*USERNAME*\\Documents.\nUse the data.frame dat2 from Exercise 1.\nUse filter to display only the universities with fewer than 10,000 students. (Remember to install and load {tidyverse} with library()).\nDisplay the founding years (gegr) column of universities with the right to award doctorates (prom_recht).\n\nBack to top\n\n\n\n2.12.3 Exercise 3\n\nContinue using the dataset from Exercises 1 & 2.\nDisplay only the universities that were founded in 1971, 1457, or 1995, and for these cases, show only the name and founding year.\nSort the dataset according to the following order. (Create a factor variable that defines this order.)\n\n\nc(\"RWTH Aachen\", \"Uni Freiburg\", \"Uni Bonn\", \"FH Aachen\", \"FH Bonn-Rhein-Sieg\")\n\n[1] \"RWTH Aachen\"        \"Uni Freiburg\"       \"Uni Bonn\"          \n[4] \"FH Aachen\"          \"FH Bonn-Rhein-Sieg\"\n\n\nBack to top\n\n\n\n2.12.4 Exercise 4\n\nCreate an R project in your directory for this course.\nSave the personal data from the PASS-CampusFile (PENDDAT_cf_W13.dta) in your directory in the subfolder orig.\nRead the dataset PENDDAT_cf_W13.dta as shown above into R and assign it to the object name pend.\nUse head() and View() to get an overview of the dataset.\nHow many respondents (rows) does the dataset contain?\nDisplay the variable names of pend using names()!\nHow can you display the rows that contain the respondent with the pnr 1000908201?\nSelect all respondents older than 60 (Age: palter) and save this selection as ue_1960.\nHow do you need to adjust the command so that ue_1960 contains only the variables pnr, hnr, welle, pintjahr, and palter?\nHow many columns does ue_1960 have? How many rows?\n\nBonus Exercises:\n\n\nHow old is the respondent with the pnr 1000908201 in welle 10 (in pintjahr 2016)?\nCreate a new variable with the birth year of the respondents (based on the age palter and the interview year pintjahr).\n\n\nBack to top\n\n\n\n2.12.5 Exercise 5\n\nExport the data.frame with the smaller dataset version (ue_1960) created in the previous exercise as an .Rdata file.\nLoad the exported .Rdata file under a different name, e.g., ue_1960_neu.\nDid everything work? Compare the newly loaded object with the original one: identical(ue_1960, ue_1960_neu) - are both objects identical?\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#appendix",
    "href": "02_intro.html#appendix",
    "title": "2  Working with Datasets",
    "section": "2.13 Appendix",
    "text": "2.13 Appendix\n\n2.13.1 Alternatives to R Projects\nBesides setting up a project, you can also set the path using setwd() or directly specify it within read_dta() or other read...() commands. However, this approach is less portable to other machines. When someone else opens the .Rproj file, R automatically sets paths relative to the file’s location. This is also true if the directory is moved on your device—R will automatically adjust the working directory.\nTo set the working directory with setwd(), insert the folder path within the parentheses. Make sure to replace any \\ with /:\n\nsetwd(\"D:/Kurse/R_IAB\")\n\nYou can check if it worked with getwd():\n\ngetwd()\n\nThe path you set with setwd() should appear.\nAlternatively, you can provide the full path directly in read_dta():\n\npend &lt;- haven::read_dta(\"C:/Kurse/R_IAB/orig/PENDDAT_cf_W13.dta\")\n\n\n\n2.13.2 Selecting Rows & Columns Without {dplyr}\nBase R (without extensions like {dplyr}) can also filter datasets using square brackets []:\n\ndat1[1, 1] # first row, first column\n\n[1] 19173\n\ndat1[1, ]  # first row, all columns\n\n  studs profs gegr stu_prof        uni    uni_fct\n1 19173   322 1971 59.54348 Uni Bremen Uni Bremen\n\ndat1[, 1]  # all rows, first column (equivalent to dat1$studs)\n\n[1] 19173  5333 15643\n\ndat1[, \"studs\"] # all rows, column named studs -&gt; note the \"\"\n\n[1] 19173  5333 15643\n\n\nYou can also select multiple rows or columns by using c():\n\ndat1[c(1, 2), ]  ## 1st & 2nd row, all columns\ndat1[, c(1, 3)]  ## all rows, 1st & 3rd column (equivalent to dat1$studs & dat1$stu_prof)\ndat1[, c(\"studs\", \"uni\")] ## all rows, columns named studs and uni\n\nYou can also write conditions in these square brackets to make selections from dat1.\n\ndat1 # full dataset\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\ndat1[dat1$uni == \"Uni Oldenburg\", ] # Rows where uni equals \"Uni Oldenburg\", all columns\n\n  studs profs gegr stu_prof           uni       uni_fct\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\ndat1$studs[dat1$uni == \"Uni Oldenburg\"] # Just check the student count: no comma needed\n\n[1] 15643\n\n\nThis works as expected, and we can expand it:\n\ndat1[dat1$uni == \"Uni Oldenburg\" & dat1$studs &gt; 10000, ] # & means AND\n\n  studs profs gegr stu_prof           uni       uni_fct\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\nYou can also use the OR operator:\n\ndat1[dat1$uni == \"Uni Oldenburg\" | dat1$studs &gt; 10000, ]\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\n\n\n2.13.3 select() vs $\nWhen you use select() to pick a specific variable, it preserves the data structure as a data.frame(), whereas dat1$variablename extracts the column as a vector (a series of values):\n\ndat1$studs\n\n[1] 19173  5333 15643\n\nclass(dat1$studs)\n\n[1] \"numeric\"\n\ndat1$studs / 20\n\n[1] 958.65 266.65 782.15\n\n\nselect() keeps the values as a column in a data.frame:\n\ndat1 %&gt;% select(studs)\n\n  studs\n1 19173\n2  5333\n3 15643\n\ndat1 %&gt;% select(studs) %&gt;% class()\n\n[1] \"data.frame\"\n\ndat1 %&gt;% select(studs) / 20\n\n   studs\n1 958.65\n2 266.65\n3 782.15",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#footnotes",
    "href": "02_intro.html#footnotes",
    "title": "2  Working with Datasets",
    "section": "",
    "text": "In many other programming languages, these are called libraries.↩︎\nThere are more, and this enumeration ignores technical details—for an advanced introduction to vectors in R, click here.↩︎\nWe will see soon how packages can make working in R easier.↩︎\nIt has become common in the R community to write packages with {} to distinguish them more clearly from functions. I follow this convention in this script.↩︎\nSometimes the dataset is not in the project’s subfolder, in which case the entire path can be specified in read_dta(): pend &lt;- read_dta(file = \"D:/Courses/R-Course/data/PENDDAT_cf_W13.dta\")↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "03_desc.html",
    "href": "03_desc.html",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "3.1 Frequency Counts\nWe have various commands available to create a frequency count:\nThe simplest command for counting frequencies is the table() command. For example, with the variable statakt representing the education status of respondents:\ntable(pend$statakt)\n\n\n -10   -9   -5    1    2    3 \n3765 3289  280 9470 6139 5481\nHere, we see the absolute frequencies displayed. The first row lists the different values, and the second row shows the frequencies.\nHowever, the labels are ignored in the output of table(). A look into the PASS data report or using attributes() reveals the value labels:\nattributes(pend$statakt)$labels\n\n    Item not surveyed in questionnaire version \n                                           -10 \n                     Item not surveyed in wave \n                                            -9 \n          Cannot be generated (missing values) \n                                            -5 \nIn occupation with earnings &gt;400 EUR per month \n                                             1 \n                        Unemployed, registered \n                                             2 \n                        Pupil/student (school) \n                                             3 \n                       Apprenticeship/Studying \n                                             4 \n                  Military or civilian service \n                                             5 \n                  Carrying out domestic duties \n                                             6 \n           Maternity protection/parental leave \n                                             7 \n                    Pensioner/early retirement \n                                             8 \n                                         Other \n                                             9 \n         Unemployed, not registered (since W4) \n                                            10 \n                Ill/unfit to work/unemployable \n                                            11 \n                   Self-employed/family worker \n                                            12\n9470 respondents are employed, 5481 respondents are inactive, etc. (More on labels and working with value labels in R later.)\nWith count() from {dplyr}, we get the labels displayed directly. Again, we use the pipe %&gt;%:\npend %&gt;% count(statakt)\n\n# A tibble: 6 × 2\n  statakt                                                  n\n  &lt;dbl+lbl&gt;                                            &lt;int&gt;\n1 -10 [Item not surveyed in questionnaire version]      3765\n2  -9 [Item not surveyed in wave]                       3289\n3  -5 [Cannot be generated (missing values)]             280\n4   1 [In occupation with earnings &gt;400 EUR per month]  9470\n5   2 [Unemployed, registered]                          6139\n6   3 [Pupil/student (school)]                          5481\nWe can also store tables under a freely chosen name and call them up later:\nt1 &lt;- table(pend$statakt)\nt2 &lt;- pend %&gt;% count(statakt)\nWe see here that the table with table() creates a new object form, a table. With count(), however, a data.frame is created.\nclass(t1)\n\n[1] \"table\"\n\nclass(t2)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#frequency-counts",
    "href": "03_desc.html#frequency-counts",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "table()\ncount() from {dplyr}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#NA03",
    "href": "03_desc.html#NA03",
    "title": "3  Getting an Overview",
    "section": "3.2 Missing Values in R: NA",
    "text": "3.2 Missing Values in R: NA\nNegative values are a bit annoying.\nTo mark the values like -5 as missing data in R, we need to set them to NA in pend. To do this, we call pend$statakt and filter with [] only the values for statakt equal to -1. In the previous chapter, we learned how to call specific values this way:\n\npend$statakt[pend$statakt == -5] # only call statakt = -5\n\n&lt;labelled&lt;double&gt;[280]&gt;: Current main occupation, gen. (since W2)\n  [1] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [26] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [51] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [76] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[101] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[126] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[151] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[176] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[201] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[226] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[251] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[276] -5 -5 -5 -5 -5\n\nLabels:\n value                                          label\n   -10     Item not surveyed in questionnaire version\n    -9                      Item not surveyed in wave\n    -5           Cannot be generated (missing values)\n     1 In occupation with earnings &gt;400 EUR per month\n     2                         Unemployed, registered\n     3                         Pupil/student (school)\n     4                        Apprenticeship/Studying\n     5                   Military or civilian service\n     6                   Carrying out domestic duties\n     7            Maternity protection/parental leave\n     8                     Pensioner/early retirement\n     9                                          Other\n    10          Unemployed, not registered (since W4)\n    11                 Ill/unfit to work/unemployable\n    12                    Self-employed/family worker\n\n\n(Here, we get the labels again, which is somewhat suboptimal for clarity.)\nIf we then assign a new value with &lt;-, the called values will be overwritten - here, we overwrite all values for statakt == -1 with NA:\n\npend$statakt[pend$statakt == -5]  &lt;- NA\n\nHowever, we have not yet overwritten all the negative values; -10 and -9 are still missing. Of course, it would be possible this way, but it’s a bit cumbersome:\n\npend$statakt[pend$statakt == -9 ]  &lt;- NA\npend$statakt[pend$statakt == -10]  &lt;- NA\n\nFor the PASS data, it’s shorter to use &lt; 0, because all missing codes are less than 0:1\n\npend$statakt[pend$statakt &lt; 0 ]  &lt;- NA\n\nIn count(), NA is also counted:\n\npend %&gt;% count(statakt)\n\n# A tibble: 4 × 2\n  statakt                                                 n\n  &lt;dbl+lbl&gt;                                           &lt;int&gt;\n1  1 [In occupation with earnings &gt;400 EUR per month]  9470\n2  2 [Unemployed, registered]                          6139\n3  3 [Pupil/student (school)]                          5481\n4 NA                                                   7334\n\n\nIf we want to avoid this, we use filter() again - with is.na(), we can identify NA. By prefixing with !, we can request that all non-NA values be retained with TRUE:\n\npend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt)\n\n# A tibble: 3 × 2\n  statakt                                                n\n  &lt;dbl+lbl&gt;                                          &lt;int&gt;\n1 1 [In occupation with earnings &gt;400 EUR per month]  9470\n2 2 [Unemployed, registered]                          6139\n3 3 [Pupil/student (school)]                          5481",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#other-table-values",
    "href": "03_desc.html#other-table-values",
    "title": "3  Getting an Overview",
    "section": "3.3 Other Table Values",
    "text": "3.3 Other Table Values\nWith the help of additional functions, we can customize the frequency table to match the Stata with tab statakt:\n\n\n   Current main occupation, gen. (since |\n                                    W2) |      Freq.     Percent        Cum.\n----------------------------------------+-----------------------------------\nIn occupation with earnings &gt;400 EUR pe |      9,470       44.90       44.90\n                 Unemployed, registered |      6,139       29.11       74.01\n                 Pupil/student (school) |      5,481       25.99      100.00\n----------------------------------------+-----------------------------------\n                                  Total |     21,090      100.00\n\n\n\ntab1 &lt;- pend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt)\n\n\nprop.table(): relative values/percentages\n\n\ntab1$pct &lt;- prop.table(tab1$n) \ntab1\n\n# A tibble: 3 × 3\n  statakt                                                n   pct\n  &lt;dbl+lbl&gt;                                          &lt;int&gt; &lt;dbl&gt;\n1 1 [In occupation with earnings &gt;400 EUR per month]  9470 0.449\n2 2 [Unemployed, registered]                          6139 0.291\n3 3 [Pupil/student (school)]                          5481 0.260\n\n\n29.109% of respondents are unemployed.\n\nprop.table() with cumsum(): cumulative relative frequencies\n\n\ntab1$cum &lt;- prop.table(tab1$n) %&gt;% cumsum()\ntab1\n\n# A tibble: 3 × 4\n  statakt                                                n   pct   cum\n  &lt;dbl+lbl&gt;                                          &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1 [In occupation with earnings &gt;400 EUR per month]  9470 0.449 0.449\n2 2 [Unemployed, registered]                          6139 0.291 0.740\n3 3 [Pupil/student (school)]                          5481 0.260 1    \n\n\n74.011% of respondents are employed or unemployed (and not inactive).\n\n3.3.0.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#creating-a-contingency-table",
    "href": "03_desc.html#creating-a-contingency-table",
    "title": "3  Getting an Overview",
    "section": "3.4 Creating a Contingency Table",
    "text": "3.4 Creating a Contingency Table\nContingency tables allow us to explore how frequently combinations of different variables occur together. Let’s look at two ways to create contingency tables in R.\nUsing count() from the {dplyr} package, we create a contingency table by inserting two variables. For instance, if we want to see the frequencies of employment status (statakt) by gender (zpsex), we can use the following command:\n\npend %&gt;% count(zpsex, statakt)\n\n# A tibble: 8 × 3\n  zpsex      statakt                                                 n\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                                           &lt;int&gt;\n1 1 [Male]    1 [In occupation with earnings &gt;400 EUR per month]  4685\n2 1 [Male]    2 [Unemployed, registered]                          3240\n3 1 [Male]    3 [Pupil/student (school)]                          2047\n4 1 [Male]   NA                                                   3555\n5 2 [Female]  1 [In occupation with earnings &gt;400 EUR per month]  4785\n6 2 [Female]  2 [Unemployed, registered]                          2899\n7 2 [Female]  3 [Pupil/student (school)]                          3434\n8 2 [Female] NA                                                   3779\n\ntab2 &lt;- pend %&gt;% count(zpsex, statakt)\ntab2$pct &lt;- prop.table(tab2$n)\ntab2\n\n# A tibble: 8 × 4\n  zpsex      statakt                                                 n    pct\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                                           &lt;int&gt;  &lt;dbl&gt;\n1 1 [Male]    1 [In occupation with earnings &gt;400 EUR per month]  4685 0.165 \n2 1 [Male]    2 [Unemployed, registered]                          3240 0.114 \n3 1 [Male]    3 [Pupil/student (school)]                          2047 0.0720\n4 1 [Male]   NA                                                   3555 0.125 \n5 2 [Female]  1 [In occupation with earnings &gt;400 EUR per month]  4785 0.168 \n6 2 [Female]  2 [Unemployed, registered]                          2899 0.102 \n7 2 [Female]  3 [Pupil/student (school)]                          3434 0.121 \n8 2 [Female] NA                                                   3779 0.133 \n\n\n\ntab2 %&gt;% mutate(pct_zpsex= prop.table(n), .by = zpsex)\n\n# A tibble: 8 × 5\n  zpsex      statakt                                          n    pct pct_zpsex\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                                    &lt;int&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 1 [Male]    1 [In occupation with earnings &gt;400 EUR pe…  4685 0.165      0.346\n2 1 [Male]    2 [Unemployed, registered]                   3240 0.114      0.240\n3 1 [Male]    3 [Pupil/student (school)]                   2047 0.0720     0.151\n4 1 [Male]   NA                                            3555 0.125      0.263\n5 2 [Female]  1 [In occupation with earnings &gt;400 EUR pe…  4785 0.168      0.321\n6 2 [Female]  2 [Unemployed, registered]                   2899 0.102      0.195\n7 2 [Female]  3 [Pupil/student (school)]                   3434 0.121      0.231\n8 2 [Female] NA                                            3779 0.133      0.254",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#summary-statistics",
    "href": "03_desc.html#summary-statistics",
    "title": "3  Getting an Overview",
    "section": "3.5 Summary Statistics",
    "text": "3.5 Summary Statistics\nFor numerical variables, such as income (netges), we often compute summary statistics like the mean, median, or quantiles. To get a quick overview, use summary():\n\nsummary(pend$netges)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n    -5.0     -3.0     -3.0    567.9    990.0 111419.0 \n\npend$netges[pend$netges &lt; 0] &lt;- NA # Handling Missing Data\nsummary(pend$netges)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0     880    1320    1562    1890  111419   18056 \n\n\n\n3.5.1 Calculating Specific Statistics\nTo calculate specific statistics, we can use:\n\nMinimum: min()\nMaximum: max()\nMean: mean()\nMedian: median()\nQuantiles: quantile()\nVariance: var()\nStandard Deviation: sd()\n\nFor instance, the mean of income. Setting na.rm = TRUE forces R to ignore missing values:\n\nmean(pend$netges)\n\n[1] NA\n\nmean(pend$netges, na.rm = TRUE)\n\n[1] 1562.3\n\n\n\n\n3.5.2 Custom Summary with summarise()\nYou can use summarise() from {dplyr} to create custom summary tables:\n\npend %&gt;%\n  summarise(\n    Minimum = min(netges, na.rm = TRUE),\n    Median = median(netges, na.rm = TRUE),\n    Mean = mean(netges, na.rm = TRUE),\n    Maximum = max(netges, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 4\n  Minimum   Median  Mean Maximum  \n  &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n1 0           1320 1562. 111419   \n\n\n\n\n3.5.3 Comparing Across Groups\nTo compare statistics across groups, use .by in summarise():\n\npend %&gt;%\n  summarise(\n    Minimum = min(netges, na.rm = TRUE),\n    Median = median(netges, na.rm = TRUE),\n    Mean = mean(netges, na.rm = TRUE),\n    Maximum = max(netges, na.rm = TRUE),\n    .by = welle\n  ) %&gt;% arrange(welle)\n\n# A tibble: 13 × 5\n   welle                   Minimum   Median  Mean Maximum  \n   &lt;dbl+lbl&gt;               &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n 1  1 [Wave 1 (2006/2007)] 1          1200  1525. 111419   \n 2  2 [Wave 2 (2007/2008)] 0          1320  1529.   7200   \n 3  3 [Wave 3 (2008/2009)] 0          1298. 1498.  12000   \n 4  4 [Wave 4 (2010)]      0          1210  1447.  10800   \n 5  5 [Wave 5 (2011)]      0          1250  1494.  33363   \n 6  6 [Wave 6 (2012)]      0          1215  1459.  15950   \n 7  7 [Wave 7 (2013)]      0          1250  1539.  87835   \n 8  8 [Wave 8 (2014)]      0          1255  1456.   9000   \n 9  9 [Wave 9 (2015)]      0          1280  1613. 110451   \n10 10 [Wave 10 (2016)]     0          1375  1541.   6300   \n11 11 [Wave 11 (2017)]     0          1500  1748.  44440   \n12 12 [Wave 12 (2018)]     0          1500  1667.   7150   \n13 13 [Wave 13 (2019)]     0          1550  1816.  88453   \n\n\nYou can also filter for specific waves if needed:\n\npend %&gt;% \n  filter(welle %in% c(1, 10)) %&gt;% \n  summarise(\n    Minimum = min(netges, na.rm = TRUE),\n    Median = median(netges, na.rm = TRUE),\n    Mean = mean(netges, na.rm = TRUE),\n    Maximum = max(netges, na.rm = TRUE),\n    .by = welle\n  )\n\n# A tibble: 2 × 5\n  welle                   Minimum   Median  Mean Maximum  \n  &lt;dbl+lbl&gt;               &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n1  1 [Wave 1 (2006/2007)] 1           1200 1525. 111419   \n2 10 [Wave 10 (2016)]     0           1375 1541.   6300   \n\n\nThese methods allow for thorough analysis of both categorical and numerical data in R.\n\n\n3.5.4 Exercise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#exercises",
    "href": "03_desc.html#exercises",
    "title": "3  Getting an Overview",
    "section": "3.6 Exercises",
    "text": "3.6 Exercises\nUse the PASS CampusFile PENDDAT_cf_W13.dta for all exercises:\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nAs a reminder: you can find an overview of the data import commands here\n\n3.6.1 Exercise 1\nWe are interested in the variable famstand, which contains the marital status of the respondents:\n\n\n\n\n\n\n\n\nMarital status, gen.\nMarital status, gen.\n\n\n\n\n-8\nImplausible value\n\n\n-4\nQuestion mistakenly not asked\n\n\n-3\nNot applicable (filter)\n\n\n-2\nNo answer\n\n\n1\nSingle\n\n\n2\nMarried/civil partnership, living together\n\n\n3\nMarried/civil partnership, not living together\n\n\n4\nDivorced\n\n\n5\nWidowed\n\n\n\n\n\n\n\n\nDisplay a table with absolute frequencies of famstand using both table() and count() (Remember to load {tidyverse} for count()).\nOverwrite missing codes with NA.\nDid the replacement of missing values with NA work? Create the table again.\nDisplay the relative frequencies (proportions). Use prop.table()\n\nBack to top\n\n\n3.6.2 Exercise 2\n\nCreate a contingency table for famstand and zpsex using count().\nWhat percentage of the respondents are divorced women? Use prop.table()\n\nBack to top\n\n\n3.6.3 Exercise 3\nDescribe the age of respondents (palter) using summary and create your own overview using summarise() to compare respondent age by marital status.\n\nFirst, overwrite missing values with NA:\n\n\npend$palter[pend$palter&lt;0] &lt;- NA\npend$famstand[pend$famstand&lt;0] &lt;- NA\n\n\nCreate an overview using summary().\nCreate an overview with the minimum, median, mean, variance, and maximum age values using summarise().\nExtend this overview to display the summary statistics for the different famstand categories.\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#notes",
    "href": "03_desc.html#notes",
    "title": "3  Getting an Overview",
    "section": "3.7 Notes",
    "text": "3.7 Notes\n\n3.7.1 Rounding with round()\nExplanation: You can round values to a certain number of digits using round(x , 3). The second number in the parentheses (after the comma) specifies how many decimal places you want:\n\nround(21.12121123,digits = 3)\n\n[1] 21.121\n\nround(21.12121123,digits = 5)\n\n[1] 21.12121\n\nround(21.12121123,digits = 0)\n\n[1] 21\n\n\nWe can round the relative frequencies to make the table above more readable:\n\nxtabs(~zpsex+statakt, data = pend) %&gt;% \n  prop.table(.,margin = 1) %&gt;% \n  round(.,3)\n\n     statakt\nzpsex     1     2     3\n    1 0.470 0.325 0.205\n    2 0.430 0.261 0.309",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#footnotes",
    "href": "03_desc.html#footnotes",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "For non-systematic values, we can use the %in% operator that we already learned about in connection with filter(): pend$var1[pend$var1 %in% c(-9,2,124) ]  &lt;- NA (this is just an example).↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html",
    "href": "04_data_wrangle.html",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "4.1 Creating Variables\nLet’s take a closer look at creating variables in R. There are two basic ways to add variables to a data.frame:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#var",
    "href": "04_data_wrangle.html#var",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "Base R: ...$newvar &lt;-\n{dplyr}: mutate(new_var= )\n\n\n4.1.1 Base R: ...$newvar &lt;-\n\ndat3$studs_to_mean &lt;- dat3$studs - mean(dat3$studs)\ndat3\n\n  studs profs prom_recht gegr                uni studs_to_mean\n1 14954   250      FALSE 1971          FH Aachen      -11721.2\n2 47269   553       TRUE 1870        RWTH Aachen       20593.8\n3 23659   438       TRUE 1457       Uni Freiburg       -3016.2\n4  9415   150       TRUE 1818           Uni Bonn      -17260.2\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       11403.8\n\n\nYou can also delete variables using &lt;- NULL:\n\ndat3$studs_to_mean &lt;- NULL\ndat3\n\n  studs profs prom_recht gegr                uni\n1 14954   250      FALSE 1971          FH Aachen\n2 47269   553       TRUE 1870        RWTH Aachen\n3 23659   438       TRUE 1457       Uni Freiburg\n4  9415   150       TRUE 1818           Uni Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg\n\n\n\n\n4.1.2 {dplyr}: mutate(new_var= )\nAn alternative way to create variables is using mutate(new_variable = ) from {dplyr} ({tidyverse}):\n\ndat3 %&gt;% mutate(studs_to_mean = studs - mean(studs))\n\n  studs profs prom_recht gegr                uni studs_to_mean\n1 14954   250      FALSE 1971          FH Aachen      -11721.2\n2 47269   553       TRUE 1870        RWTH Aachen       20593.8\n3 23659   438       TRUE 1457       Uni Freiburg       -3016.2\n4  9415   150       TRUE 1818           Uni Bonn      -17260.2\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       11403.8\n\n\nYou can also create multiple variables within a single mutate() command:\n\ndat3 %&gt;% mutate(\n  studs_to_mean = studs - mean(studs),\n  profs_to_mean = profs - mean(profs)\n)\n\n  studs profs prom_recht gegr                uni studs_to_mean profs_to_mean\n1 14954   250      FALSE 1971          FH Aachen      -11721.2        -155.4\n2 47269   553       TRUE 1870        RWTH Aachen       20593.8         147.6\n3 23659   438       TRUE 1457       Uni Freiburg       -3016.2          32.6\n4  9415   150       TRUE 1818           Uni Bonn      -17260.2        -255.4\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       11403.8         230.6\n\n\nOr variables can be reused within mutate():\n\ndat3 %&gt;% mutate(\n  rel_to_mean = studs - mean(studs),\n  above_mean = rel_to_mean &gt; 0\n)\n\n  studs profs prom_recht gegr                uni rel_to_mean above_mean\n1 14954   250      FALSE 1971          FH Aachen    -11721.2      FALSE\n2 47269   553       TRUE 1870        RWTH Aachen     20593.8       TRUE\n3 23659   438       TRUE 1457       Uni Freiburg     -3016.2      FALSE\n4  9415   150       TRUE 1818           Uni Bonn    -17260.2      FALSE\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     11403.8       TRUE\n\n\nThe original dataset remains unchanged:\n\ndat3\n\n  studs profs prom_recht gegr                uni\n1 14954   250      FALSE 1971          FH Aachen\n2 47269   553       TRUE 1870        RWTH Aachen\n3 23659   438       TRUE 1457       Uni Freiburg\n4  9415   150       TRUE 1818           Uni Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg\n\n\nTo keep the results, store them in an object:\n\ndat4 &lt;- dat3 %&gt;% mutate(\n  rel_to_mean = studs - mean(studs),\n  above_mean = rel_to_mean &gt; 0\n)\n\ndat4\n\n  studs profs prom_recht gegr                uni rel_to_mean above_mean\n1 14954   250      FALSE 1971          FH Aachen    -11721.2      FALSE\n2 47269   553       TRUE 1870        RWTH Aachen     20593.8       TRUE\n3 23659   438       TRUE 1457       Uni Freiburg     -3016.2      FALSE\n4  9415   150       TRUE 1818           Uni Bonn    -17260.2      FALSE\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     11403.8       TRUE\n\n\n\n\n\n\n\n\nCreating Dummy Variables with as.numeric()\n\n\n\n\n\nYou can convert logical variables into numeric dummy variables (0/1) using as.numeric():\n\ndat3 %&gt;% mutate(\n  prom_dummy = as.numeric(prom_recht),\n  over10k = as.numeric(studs &gt; 10000)\n)\n\n  studs profs prom_recht gegr                uni prom_dummy over10k\n1 14954   250      FALSE 1971          FH Aachen          0       1\n2 47269   553       TRUE 1870        RWTH Aachen          1       1\n3 23659   438       TRUE 1457       Uni Freiburg          1       1\n4  9415   150       TRUE 1818           Uni Bonn          1       0\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg          0       1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#group_by",
    "href": "04_data_wrangle.html#group_by",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.2 Grouping with .by=",
    "text": "4.2 Grouping with .by=\nThe true power of mutate() becomes apparent when combined with other {dplyr} functions. A common task in data preparation involves grouped values.\nWe’ll make our example dataset a bit smaller:\n\ndat5 &lt;- dat3 %&gt;% \n  select(-uni,-gegr) # to ensure everything is visible\n\nSince {dplyr} version 1.1.1, we can specify a grouping directly in mutate() using the .by= argument. This .by= grouping is applied only to the immediate calculations within mutate():\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  mutate(m_studs2 = mean(studs),\n         .by = prom_recht) %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n1 14954   250      FALSE 26675.2   405.4  26516.5    405.4\n2 47269   553       TRUE 26675.2   405.4  26781.0    405.4\n3 23659   438       TRUE 26675.2   405.4  26781.0    405.4\n4  9415   150       TRUE 26675.2   405.4  26781.0    405.4\n5 38079   636      FALSE 26675.2   405.4  26516.5    405.4\n\n\nUsing summarise() instead of mutate() provides an overview:\n\ndat5 %&gt;%\n  summarise(m_studs = mean(studs),.by = prom_recht)\n\n  prom_recht m_studs\n1      FALSE 26516.5\n2       TRUE 26781.0\n\n\n\n\n\n\n\n\ngroup_by()\n\n\n\n\n\nBefore {dplyr} 1.1.1, grouping a dataset relied on group_by(). After setting group_by() along the values of a variable, all subsequent mutate() calculations are performed only within those groups:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs),\n         m_profs2 = mean(profs))\n\n# A tibble: 5 × 7\n# Groups:   prom_recht [2]\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 14954   250 FALSE       26675.    405.   26516.     443 \n2 47269   553 TRUE        26675.    405.   26781      380.\n3 23659   438 TRUE        26675.    405.   26781      380.\n4  9415   150 TRUE        26675.    405.   26781      380.\n5 38079   636 FALSE       26675.    405.   26516.     443 \n\n\nAfter using group_by(), it’s good practice to remove the grouping with ungroup() once it’s no longer needed:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs)) %&gt;% \n  ungroup() %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n# A tibble: 5 × 7\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 14954   250 FALSE       26675.    405.   26516.     405.\n2 47269   553 TRUE        26675.    405.   26781      405.\n3 23659   438 TRUE        26675.    405.   26781      405.\n4  9415   150 TRUE        26675.    405.   26781      405.\n5 38079   636 FALSE       26675.    405.   26516.     405.\n\n\n\n\n\n\n\n4.2.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#across",
    "href": "04_data_wrangle.html#across",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.3 across(): Processing Multiple Variables",
    "text": "4.3 across(): Processing Multiple Variables\nA highly versatile addition to mutate() and summarise() is across(). This allows us to apply a function to multiple columns simultaneously, without repeating code:\n\ndat3 %&gt;%\n  summarise(studs = mean(studs),\n            profs = mean(profs))\n\n    studs profs\n1 26675.2 405.4\n\n\nHere, across() offers a much shorter syntax for variable selection, and we can use ?select_helpers like matches():\n\ndat3 %&gt;%\n  summarise(across(.cols = matches(\"studs|profs\"),.fns = ~mean(.x)))\n\n    studs profs\n1 26675.2 405.4\n\n\nThis is also compatible with .by=:\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), ~mean(.x)), .by= prom_recht)\n\n  prom_recht   studs    profs\n1      FALSE 26516.5 443.0000\n2       TRUE 26781.0 380.3333\n\n\nWe can apply multiple functions by placing them in a list():\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), list(mean = ~mean(.x), sd = ~sd(.x))), .by= prom_recht)\n\n  prom_recht studs_mean studs_sd profs_mean profs_sd\n1      FALSE    26516.5 16351.84   443.0000 272.9432\n2       TRUE    26781.0 19119.14   380.3333 207.5966\n\n\nYou can define this list() in advance and use it later:\n\nwert_liste &lt;- list(MEAN = ~mean(.x), SD = ~sd(.x))\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), wert_liste), .by= prom_recht)\n\n  prom_recht studs_MEAN studs_SD profs_MEAN profs_SD\n1      FALSE    26516.5 16351.84   443.0000 272.9432\n2       TRUE    26781.0 19119.14   380.3333 207.5966\n\n\nThe .names() argument allows us to control the naming of columns. {.fn} stands for the function being applied, and {.col} represents the name of the variable being processed.\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), \n                   wert_liste,\n                   .names = \"{.fn}_{.col}\"),\n            .by= prom_recht)\n\n  prom_recht MEAN_studs SD_studs MEAN_profs SD_profs\n1      FALSE    26516.5 16351.84   443.0000 272.9432\n2       TRUE    26781.0 19119.14   380.3333 207.5966\n\n\nAll these functions also work with mutate():\n\ndat3 %&gt;%\n  mutate(across(matches(\"studs|profs\"),\n                wert_liste, \n                .names = \"{.col}XX{.fn}\"))\n\n  studs profs prom_recht gegr                uni studsXXMEAN studsXXSD\n1 14954   250      FALSE 1971          FH Aachen     26675.2  15799.92\n2 47269   553       TRUE 1870        RWTH Aachen     26675.2  15799.92\n3 23659   438       TRUE 1457       Uni Freiburg     26675.2  15799.92\n4  9415   150       TRUE 1818           Uni Bonn     26675.2  15799.92\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     26675.2  15799.92\n  profsXXMEAN profsXXSD\n1       405.4   203.349\n2       405.4   203.349\n3       405.4   203.349\n4       405.4   203.349\n5       405.4   203.349\n\n\nMore examples in the across() documentation\n\n4.3.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#custom-functions",
    "href": "04_data_wrangle.html#custom-functions",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.4 Custom Functions",
    "text": "4.4 Custom Functions\nWhat’s with the ~1 in across()? Let’s take a look at the basics of functions in R to understand.\nTo do so, let’s examine three satisfaction variables for respondents in rows 12-16:\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nImportant regarding job\n\n\n\n\nPEO0300a\nTo earn a lot of money\n\n\nPEO0300b\nA job, that is fun\n\n\nPEO0300c\nGood career opportunities\n\n\nPEO0300d\nJob security\n\n\nPEO0300e\nJob where you can show off your abilities\n\n\n\n\n\n\n\n\n\n\n\n\n\n-10 bis -1\n1\n2\n3\n4\n\n\n\n\nt.n.z./k.A.\nVery important\nRather important\nRather not important\nNot important at all\n\n\n\n\n\n\n\n\npend &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nsat_small &lt;- \n  pend %&gt;% \n    filter(welle == 1) %&gt;% \n    select(matches(\"PEO0300(a|b|c)\")) %&gt;% \n    slice(12:16) %&gt;% \n    haven::zap_labels() %&gt;% haven::zap_label() # remove labels\nsat_small\n\n# A tibble: 5 × 3\n  PEO0300a PEO0300b PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\n\n\nsat_small &lt;- sat_small %&gt;% mutate(across(everything(),~as.numeric(.x)))\n\nSometimes we want to process multiple variables in the same way. Above, we saw how to handle this with across() for existing functions. But what if we want to perform a calculation that isn’t as simple as applying mean(), sd(), etc.?\n\nsat_small %&gt;% \n  mutate(dmean_PEO0300a = PEO0300a - mean(PEO0300a,na.rm = T),\n         dmean_PEO0300c = PEO0300c - mean(PEO0300c,na.rm = T))\n\n# A tibble: 5 × 5\n  PEO0300a PEO0300b PEO0300c dmean_PEO0300a dmean_PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1        2        3        2            0.6         -0.200\n2        1        1        3           -0.4          0.8  \n3        1        1        3           -0.4          0.8  \n4        2        1        1            0.6         -1.2  \n5        1        1        2           -0.4         -0.200\n\n\n…and now what about F1450_06? Typing this out three times would violate the “DRY” principle2, especially considering the PASS CampusFile contains 5 columns of similar satisfaction variables. Copying and pasting is not a practical option.\nCustom functions allow us to adhere to the DRY principle in R. We’ll make our calculation steps part of a function() and apply it to the desired variables. A function takes an input, defined as a placeholder within the (). This placeholder is used within the function, and we return the result with return(). Only one output can be returned:\n\ndtomean &lt;- function(x){\n  d_x &lt;- x - mean(x,na.rm = T)\n  return(d_x)\n}\n\nHow can we now apply our function dtomean() to the variables from our sat_small?\nIn principle, we saw at the beginning that a data.frame is simply a combined collection of vectors (the variables).\nAccordingly, we can now apply our dtomean() to a variable (a vector) by calling it with data.frame$variablename:\n\ndtomean(sat_small$PEO0300a)\n\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n\nTo apply our function to each variable of a data.frame, we can use lapply() - the output will then be a list, with elements named after the variable names:\n\nlapply(sat_small,FUN = dtomean)\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\nres &lt;- lapply(sat_small,FUN = dtomean)\nclass(res)\n\n[1] \"list\"\n\n\nmap() from {purrr} is an alternative to lapply:\n\nsat_small %&gt;% map(~dtomean(.x))\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\n\nThis formula syntax can also be found in across() - additionally, with .names = we have the option to modify the variable names for the results:\n\nsat_small %&gt;% \n  mutate(across(matches(\"PEO0300\"),~dtomean(.x),.names = \"dmean_{.col}\"))\n\n# A tibble: 5 × 6\n  PEO0300a PEO0300b PEO0300c dmean_PEO0300a dmean_PEO0300b dmean_PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1        2        3        2            0.6            1.6         -0.200\n2        1        1        3           -0.4           -0.4          0.8  \n3        1        1        3           -0.4           -0.4          0.8  \n4        2        1        1            0.6           -0.4         -1.2  \n5        1        1        2           -0.4           -0.4         -0.200\n\n\n\n4.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#exercises",
    "href": "04_data_wrangle.html#exercises",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\n4.5.1 Exercise\n\nContinue using the university dataset dat3 as shown above from dat1 and dat2.\nCalculate the student-to-professor ratio (students per professor studs/profs) at the universities relative to the mean of the ratio (rel_studprofs).\nCalculate the student-to-professor ratio (studprofs) relative to the mean, separated by universities with and without the right to award doctorates, and add this as a new column.\n\nBack to top\n\n\n4.5.2 Exercise\n\nUse the pend_small dataset:\n\n\npend_small &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"welle\",\"zpsex\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"PEO0400d\")\n                               ) %&gt;% \n  filter(welle == 2) %&gt;% \n  slice(1:15)\n\n\nCalculate the mean for the variables PEO0400a, PEO0400b, PEO0400c, and PEO0400d:\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlab\n\n\n\n\nPEO0400a\nFamily/job: Woman should be willing to reduce her working hours for family\n\n\nPEO0400b\nFamily/job: What women really want is a home and children\n\n\nPEO0400c\nFamily/job: Working mother can have an equally warm relationship with her childr\n\n\nPEO0400d\nFamily/job: Responsibility of husband: To earn money; responsibility of wife: Ho\n\n\n\n\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n11     2     1        4        3        2        3\n12     2     2        2        3        2        3\n13     2     1        2        3        2        3\n14     2     1        1        2        1        1\n15     2     1        1        1        1        2\n\n\n\nUse across() to calculate the means for all four variables.\nCalculate the means separately by gender (zpsex) using .by =.\nAlso add the variance (var()), and use .names= to name the columns following the pattern metric.variable.\n\nBack to top\n\n\n4.5.3 Exercise\nContinue using pend_small:\n\npend_small\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n11     2     1        4        3        2        3\n12     2     2        2        3        2        3\n13     2     1        2        3        2        3\n14     2     1        1        2        1        1\n15     2     1        1        1        1        2\n\n\n\nStandardize the variables PEO0400a - PEO0400d from pend_small using the following pattern:\n\n\npend_small %&gt;% \n  mutate(std_PEO0400b = (PEO0400b - mean(PEO0400b,na.rm = T))/sd(PEO0400b,na.rm = T))\n\n\nUse a function so that you don’t have to repeatedly enter the same steps.\nAdditionally, use across() to apply the function to the desired variables.\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#appendix",
    "href": "04_data_wrangle.html#appendix",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.6 Appendix",
    "text": "4.6 Appendix\n\n4.6.1 Helper functions\n\n4.6.1.1 ifelse()\nifelse() is a great help for all recoding tasks: we formulate a condition and if it is met, the first value is used; if not, the second value is used. Here we check whether studs-mean(studs) is greater than 0 - if so, above is used, otherwise below:\n\ndat3 %&gt;% mutate(rel_to_mean = studs-mean(studs),\n                ab_mean_lab = ifelse(rel_to_mean &gt; 0,\"above\",\"below\"))\n\n  studs profs prom_recht gegr                uni rel_to_mean ab_mean_lab\n1 14954   250      FALSE 1971          FH Aachen    -11721.2       below\n2 47269   553       TRUE 1870        RWTH Aachen     20593.8       above\n3 23659   438       TRUE 1457       Uni Freiburg     -3016.2       below\n4  9415   150       TRUE 1818           Uni Bonn    -17260.2       below\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     11403.8       above\n\n\nThis can be helpful to replace negative values with NA, for example in the PASS data:\n\npend_small2 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"palter\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"statakt\"))  %&gt;% \n  slice(5624:5640)\n\nThe basic idea is to use ifelse() to replace negative values in a variable with NA:\n\npend_small2 %&gt;% mutate(PEO0400a = ifelse(PEO0400a&lt;0,NA,PEO0400a))\n\nacross() allows us to apply this ifelse()-function to replace NA in PEO0400a,PEO0400b, PEO0400c and statakt:\n\npend_small2 %&gt;% mutate(across(c(\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"statakt\"), ~ifelse(.x&lt;0,NA,.x)))  \n\n# A tibble: 17 × 5\n   palter    PEO0400a PEO0400b PEO0400c statakt\n   &lt;dbl+lbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 77               1        3        3      NA\n 2 78              NA       NA       NA      NA\n 3 51               2        4        1      NA\n 4 23               3        3        2      NA\n 5 17               3        2        1      NA\n 6 47               3        2        2      NA\n 7 24               3        4        1       1\n 8 52               2        3        1       1\n 9 19               2        3        2       3\n10 48               2        3        1       1\n11 49              NA       NA       NA      NA\n12 47               2        3        1      NA\n13 48               2        3        1       1\n14 49              NA       NA       NA       1\n15 39               4        3        1      NA\n16 37               3        4        1      NA\n17 38               3        3        1       1\n\npend_small2 %&gt;% mutate(across(matches(\"PEO0400|statakt\"), ~ifelse(.x&lt;0,NA,.x)))  # even shorter: matches()\n\n# A tibble: 17 × 5\n   palter    PEO0400a PEO0400b PEO0400c statakt\n   &lt;dbl+lbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 77               1        3        3      NA\n 2 78              NA       NA       NA      NA\n 3 51               2        4        1      NA\n 4 23               3        3        2      NA\n 5 17               3        2        1      NA\n 6 47               3        2        2      NA\n 7 24               3        4        1       1\n 8 52               2        3        1       1\n 9 19               2        3        2       3\n10 48               2        3        1       1\n11 49              NA       NA       NA      NA\n12 47               2        3        1      NA\n13 48               2        3        1       1\n14 49              NA       NA       NA       1\n15 39               4        3        1      NA\n16 37               3        4        1      NA\n17 38               3        3        1       1\n\n\n\n\n4.6.1.2 case_when()\ncase_when() ({dplyr}) extends the principle ifelse(), allowing us to specify more than two options.\nThe syntax is slightly different: first, we specify the condition, then after a ~ the values to be used:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 ~ \"very old\",\n                                gegr &lt; 1900 ~ \"old\"))\n\n  studs profs prom_recht gegr                uni      age\n1 14954   250      FALSE 1971          FH Aachen     &lt;NA&gt;\n2 47269   553       TRUE 1870        RWTH Aachen      old\n3 23659   438       TRUE 1457       Uni Freiburg very old\n4  9415   150       TRUE 1818           Uni Bonn      old\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     &lt;NA&gt;\n\n\nWith TRUE, we can address all cases that have not met any conditions so far:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 ~ \"very old\",\n                                gegr &lt; 1900 ~ \"old\",\n                                TRUE ~ \"relatively new\"))\n\n  studs profs prom_recht gegr                uni            age\n1 14954   250      FALSE 1971          FH Aachen relatively new\n2 47269   553       TRUE 1870        RWTH Aachen            old\n3 23659   438       TRUE 1457       Uni Freiburg       very old\n4  9415   150       TRUE 1818           Uni Bonn            old\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg relatively new\n\n\nThis doesn’t have to be limited to one variable:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 & prom_recht  == T ~ \"very old university\",\n                                gegr &lt; 1900 & prom_recht  == T ~ \"old university\",\n                                gegr &gt; 1900 & prom_recht  == T ~ \"young university\",\n                                gegr &lt; 1900 & prom_recht  == F ~ \"old college\",\n                                gegr &gt; 1900 & prom_recht  == F ~ \"young college\"))\n\n  studs profs prom_recht gegr                uni                 age\n1 14954   250      FALSE 1971          FH Aachen       young college\n2 47269   553       TRUE 1870        RWTH Aachen      old university\n3 23659   438       TRUE 1457       Uni Freiburg very old university\n4  9415   150       TRUE 1818           Uni Bonn      old university\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       young college\n\n\n\n\n4.6.1.3 cut(): creating classes\n\ndat3\n\n  studs profs prom_recht gegr                uni\n1 14954   250      FALSE 1971          FH Aachen\n2 47269   553       TRUE 1870        RWTH Aachen\n3 23659   438       TRUE 1457       Uni Freiburg\n4  9415   150       TRUE 1818           Uni Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg\n\n\nA common task in data preparation is classifying a continuous variable, such as the number of professors. We want to group profs in steps of 150. To create these classes, we use cut() and specify the class boundaries with breaks. We can use seq() to generate the breakpoints. In seq(), we specify the lower and upper limits along with the step size.\n\ncut(dat3$profs,breaks = c(50, 200, 350, 500, 650))\n\n[1] (200,350] (500,650] (350,500] (50,200]  (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\ncut(dat3$profs,breaks = seq(50,650,150))\n\n[1] (200,350] (500,650] (350,500] (50,200]  (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\n\nWe store these values in a new variable in the dat3 dataset:\n\ndat3$prof_class &lt;- cut(dat3$profs,breaks = seq(50,650,150))\ndat3\n\n  studs profs prom_recht gegr                uni prof_class\n1 14954   250      FALSE 1971          FH Aachen  (200,350]\n2 47269   553       TRUE 1870        RWTH Aachen  (500,650]\n3 23659   438       TRUE 1457       Uni Freiburg  (350,500]\n4  9415   150       TRUE 1818           Uni Bonn   (50,200]\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg  (500,650]\n\n\nFor this new variable, we can request a frequency table using count():\n\ndat3 %&gt;% count(prof_class)\n\n  prof_class n\n1   (50,200] 1\n2  (200,350] 1\n3  (350,500] 1\n4  (500,650] 2\n\n\nThe parentheses ( indicate exclusion, while the brackets ] indicate inclusion. There are 1 universities in the dataset that have more than 200 and up to 350 professors.\nFor the following examples, we delete the prof_class variable again:\n\ndat3$prof_class &lt;- NULL\n\nSome useful options for cut() in the appendix\n\nbsp &lt;- c(1990,1998,2001,2009)\nbsp\n\n[1] 1990 1998 2001 2009\n\ncut(bsp,breaks = c(1990,2000,2010)) \n\n[1] &lt;NA&gt;             (1.99e+03,2e+03] (2e+03,2.01e+03] (2e+03,2.01e+03]\nLevels: (1.99e+03,2e+03] (2e+03,2.01e+03]\n\n# Specify the number of digits in the labels\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4) \n\n[1] &lt;NA&gt;        (1990,2000] (2000,2010] (2000,2010]\nLevels: (1990,2000] (2000,2010]\n\n# Include the lower boundary\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4,include.lowest = T) \n\n[1] [1990,2000] [1990,2000] (2000,2010] (2000,2010]\nLevels: [1990,2000] (2000,2010]\n\n# Number the categories instead of labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = FALSE)\n\n[1] NA  1  2  2\n\n# Specify your own labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = c(\"90s\",\"00s\"))\n\n[1] &lt;NA&gt; 90s  00s  00s \nLevels: 90s 00s\n\n\n\n\n\n4.6.2 Renaming variables\nTo rename variables, use rename(new_name = old_name)\n\nsat_small %&gt;% rename(newname = PEO0300a)\n\n# A tibble: 5 × 3\n  newname PEO0300b PEO0300c\n    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       2        3        2\n2       1        1        3\n3       1        1        3\n4       2        1        1\n5       1        1        2\n\n\nFor advanced transformations, it’s worth looking into rename_with(). This allows us to use Regular Expressions, for example from {stringr}. Here’s just an example:\n\nsat_small %&gt;% rename_with(~tolower(.))\n\n# A tibble: 5 × 3\n  peo0300a peo0300b peo0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\nsat_small %&gt;% rename_with(~str_remove(.x,\"PEO0300\"))\n\n# A tibble: 5 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2     3     2\n2     1     1     3\n3     1     1     3\n4     2     1     1\n5     1     1     2\n\nsat_small %&gt;% rename_with(~str_replace(.x,\"PEO0300\",\"Occupation_\"))\n\n# A tibble: 5 × 3\n  Occupation_a Occupation_b Occupation_c\n         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1            2            3            2\n2            1            1            3\n3            1            1            3\n4            2            1            1\n5            1            1            2\n\n\n\n\n4.6.3 String Functions for regex\n{stringr} provides a series of very useful string functions with regular expressions. You can get an overview from this cheatsheet.\n\ndat3 %&gt;% mutate(uni_fh = str_detect(uni,\"Uni\"))\n\n  studs profs prom_recht gegr                uni uni_fh\n1 14954   250      FALSE 1971          FH Aachen  FALSE\n2 47269   553       TRUE 1870        RWTH Aachen  FALSE\n3 23659   438       TRUE 1457       Uni Freiburg   TRUE\n4  9415   150       TRUE 1818           Uni Bonn   TRUE\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg  FALSE\n\ndat3 %&gt;% mutate(bula = case_when(str_detect(uni,\"Bremen\")~ \"HB\",\n                                 str_detect(uni,\"Oldenb|Vechta\")~ \"NDS\",\n                                 str_detect(uni,\"Bonn|Aachen\")~ \"NRW\",\n                                 str_detect(uni,\"Freiburg\")~ \"BW\"\n                                 ))\n\n  studs profs prom_recht gegr                uni bula\n1 14954   250      FALSE 1971          FH Aachen  NRW\n2 47269   553       TRUE 1870        RWTH Aachen  NRW\n3 23659   438       TRUE 1457       Uni Freiburg   BW\n4  9415   150       TRUE 1818           Uni Bonn  NRW\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg  NRW\n\ndat3 %&gt;% mutate(ort = str_remove(uni,\"Uni |FH |RWTH \"))\n\n  studs profs prom_recht gegr                uni             ort\n1 14954   250      FALSE 1971          FH Aachen          Aachen\n2 47269   553       TRUE 1870        RWTH Aachen          Aachen\n3 23659   438       TRUE 1457       Uni Freiburg        Freiburg\n4  9415   150       TRUE 1818           Uni Bonn            Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg Bonn-Rhein-Sieg",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#footnotes",
    "href": "04_data_wrangle.html#footnotes",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "“tilde”:  Windows: Press Alt Gr + * (The asterisk is on the same key as the plus sign).  macOS: Press Alt (Option) + N, then press the space bar to insert the tilde.↩︎\nDo not repeat yourself, see Wickham et al: “You should consider writing a function whenever you’ve copied and pasted a block of code more than twice (i.e. you now have three copies of the same code).”↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html",
    "href": "05_merge_pivot.html",
    "title": "5  Merging & reshaping",
    "section": "",
    "text": "5.1 Joining/merging data sets\nA mutating join allows you to combine variables from two data.frames. It first matches observations by their keys, then copies across variables from one table to the other.\nR for Data Science: Mutating joins\nA quick illustration:1\nThere are also right_join() and anti_join(). For a more in-depth introduction, the chapter on Relational Data in R for Data Science is highly recommended.\nA very helpful option in the ..._join() functions is the ability to join different variables. For example, here we have some cases from ids_df, for which the (fictional) unemployment figures from alo_bula should be used. However, in ids_df, the variable Bula contains the state information, while in alo_bula, it is the variable bundesland:\nCode\nids_df &lt;-  data.frame(pnr = sample(1:9,4),\n                       Bula = c(2,1,14,15))\n\nset.seed(90459)\nalo_bula &lt;- data.frame(bundesland = seq(1:8),\n                       Werte = sample(letters,size = 8) # mit sample() kann eine zufällige Auswahl getroffen werden \n                       )\nids_df\n\n#&gt;   pnr Bula\n#&gt; 1   5    2\n#&gt; 2   6    1\n#&gt; 3   8   14\n#&gt; 4   4   15\n\nalo_bula\n\n#&gt;   bundesland Werte\n#&gt; 1          1     g\n#&gt; 2          2     m\n#&gt; 3          3     n\n#&gt; 4          4     z\n#&gt; 5          5     w\n#&gt; 6          6     r\n#&gt; 7          7     t\n#&gt; 8          8     h\n\nids_df %&gt;% left_join(alo_bula,by = c(\"Bula\"=\"bundesland\"))\n\n#&gt;   pnr Bula Werte\n#&gt; 1   5    2     m\n#&gt; 2   6    1     g\n#&gt; 3   8   14  &lt;NA&gt;\n#&gt; 4   4   15  &lt;NA&gt;\nA quick check for the matching cases can be done using:\ntable(ids_df$Bula %in% alo_bula$bundesland)\n\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;     2     2\nanti_join() allows for checking which key variables are not present in the other data.frame:\nids_df %&gt;% anti_join(alo_bula,by = c(\"Bula\"=\"bundesland\"))\n\n#&gt;   pnr Bula\n#&gt; 1   8   14\n#&gt; 2   4   15\n\nalo_bula %&gt;% anti_join(ids_df,by = c(\"bundesland\"=\"Bula\"))\n\n#&gt;   bundesland Werte\n#&gt; 1          3     n\n#&gt; 2          4     z\n#&gt; 3          5     w\n#&gt; 4          6     r\n#&gt; 5          7     t\n#&gt; 6          8     h",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#join",
    "href": "05_merge_pivot.html#join",
    "title": "5  Merging & reshaping",
    "section": "",
    "text": "5.1.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#reshaping-data-pivot_longer-pivot_wider",
    "href": "05_merge_pivot.html#reshaping-data-pivot_longer-pivot_wider",
    "title": "5  Merging & reshaping",
    "section": "5.2 Reshaping Data: pivot_longer() & pivot_wider()",
    "text": "5.2 Reshaping Data: pivot_longer() & pivot_wider()\n\n5.2.1 Wide to Long\nReshaping data from wide to long format is useful when you want to store multiple observations per row. For example:\n\nbsp_df &lt;- data.frame(bula = c(\"NRW\", \"NDS\"), alo2018 = c(2, 2), alo2017 = c(1, 1))\nbsp_df\n\n#&gt;   bula alo2018 alo2017\n#&gt; 1  NRW       2       1\n#&gt; 2  NDS       2       1\n\n\nWe can use pivot_longer() to convert this wide format to long:\n\nbsp_df %&gt;% pivot_longer(cols = c(alo2018, alo2017), names_to = \"year\", values_to = \"alo\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   bula  year      alo\n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 NRW   alo2018     2\n#&gt; 2 NRW   alo2017     1\n#&gt; 3 NDS   alo2018     2\n#&gt; 4 NDS   alo2017     1\n\n\nTo remove a prefix from the column names:\n\nbsp_df %&gt;% pivot_longer(cols = c(alo2018, alo2017), names_to = \"year\", values_to = \"alo\", names_prefix = \"alo\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   bula  year    alo\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 NRW   2018      2\n#&gt; 2 NRW   2017      1\n#&gt; 3 NDS   2018      2\n#&gt; 4 NDS   2017      1\n\n\n\n\n5.2.2 Long to Wide\nTo convert from long format back to wide:\n\nbsp_df2 &lt;- data.frame(land = c(\"NRW\", \"NDS\", \"NRW\", \"NDS\"), alo = c(2.1, 1.8, 2.4, 2.2), alter = c(\"age_1825\", \"age_1825\", \"age_2630\", \"age_2630\"))\nbsp_df2\n\n#&gt;   land alo    alter\n#&gt; 1  NRW 2.1 age_1825\n#&gt; 2  NDS 1.8 age_1825\n#&gt; 3  NRW 2.4 age_2630\n#&gt; 4  NDS 2.2 age_2630\n\n\n\nbsp_df2 %&gt;% pivot_wider(names_from = alter, values_from = alo)\n\n#&gt; # A tibble: 2 × 3\n#&gt;   land  age_1825 age_2630\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 NRW        2.1      2.4\n#&gt; 2 NDS        1.8      2.2\n\n\n\n\n5.2.3 Exercise",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#exercises",
    "href": "05_merge_pivot.html#exercises",
    "title": "5  Merging & reshaping",
    "section": "5.3 Exercises",
    "text": "5.3 Exercises\n\n5.3.1 Exercise 1: Joining\nJoin the selected observations from PENDDAT_cf_W13.dta with the household data to include the region where the respondents live, using hnr and welle as keys.\n\npend_ue11 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\", col_select = c(\"pnr\", \"welle\")) %&gt;% slice(1:10)\n\nhh_dat &lt;- haven::read_dta(\"./orig/HHENDDAT_cf_W13.dta\", col_select = c(\"hnr\", \"welle\", \"region\"))\n\npend_ue11 %&gt;% left_join(hh_dat, by = c(\"welle\"))\n\n#&gt; # A tibble: 18,466 × 4\n#&gt;           pnr welle                       hnr region   \n#&gt;         &lt;dbl&gt; &lt;dbl+lbl&gt;                 &lt;dbl&gt; &lt;dbl+lbl&gt;\n#&gt;  1 1000001901 1 [Wave 1 (2006/2007)] 10000019 4 [West] \n#&gt;  2 1000001901 1 [Wave 1 (2006/2007)] 10000020 4 [West] \n#&gt;  3 1000001901 1 [Wave 1 (2006/2007)] 10000023 4 [West] \n#&gt;  4 1000001901 1 [Wave 1 (2006/2007)] 10000026 4 [West] \n#&gt;  5 1000001901 1 [Wave 1 (2006/2007)] 10000031 4 [West] \n#&gt;  6 1000001901 1 [Wave 1 (2006/2007)] 10000032 4 [West] \n#&gt;  7 1000001901 1 [Wave 1 (2006/2007)] 10000035 4 [West] \n#&gt;  8 1000001901 1 [Wave 1 (2006/2007)] 10000040 4 [West] \n#&gt;  9 1000001901 1 [Wave 1 (2006/2007)] 10000043 4 [West] \n#&gt; 10 1000001901 1 [Wave 1 (2006/2007)] 10000055 3 [Süd]  \n#&gt; # ℹ 18,456 more rows\n\n\nBack to top\n\n\n5.3.2 Exercise 2: Reshaping\nBring the following data into long format:\n\npend_ue11b &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\", col_select = c(\"pnr\", \"welle\", \"famstand\")) %&gt;%\n  slice(200:210) %&gt;%\n  filter(welle %in% 2:3)\n\npend_ue11b %&gt;% pivot_wider(names_from = welle, values_from = famstand)\n\n#&gt; # A tibble: 3 × 3\n#&gt;          pnr `2`                                             `3`                \n#&gt;        &lt;dbl&gt; &lt;dbl+lbl&gt;                                       &lt;dbl+lbl&gt;          \n#&gt; 1 1000014501 -4 [Question mistakenly not asked]              3 [Married/civil p…\n#&gt; 2 1000014701  2 [Married/civil partnership, living together] 2 [Married/civil p…\n#&gt; 3 1000014702  2 [Married/civil partnership, living together] 2 [Married/civil p…\n\n\nUsing names_prefix = \"wave\":\n\npend_ue11b %&gt;% pivot_wider(names_from = welle, values_from = famstand, names_prefix = \"wave\")\n\n#&gt; # A tibble: 3 × 3\n#&gt;          pnr wave2                                           wave3              \n#&gt;        &lt;dbl&gt; &lt;dbl+lbl&gt;                                       &lt;dbl+lbl&gt;          \n#&gt; 1 1000014501 -4 [Question mistakenly not asked]              3 [Married/civil p…\n#&gt; 2 1000014701  2 [Married/civil partnership, living together] 2 [Married/civil p…\n#&gt; 3 1000014702  2 [Married/civil partnership, living together] 2 [Married/civil p…\n\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#footnotes",
    "href": "05_merge_pivot.html#footnotes",
    "title": "5  Merging & reshaping",
    "section": "",
    "text": "Using tidyexplain↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html",
    "href": "06_labels_factor.html",
    "title": "6  Labels & factors",
    "section": "",
    "text": "6.1 Labels from Other Programs in R\nIn many software packages like Stata or SPSS, labels are often retained through various operations and then displayed automatically. This is not the case in R. Instead, in R, we can assign labels using the factor variable type. This approach might seem unusual for those who have worked extensively with Stata or SPSS, but it is quite useful in practice if you get accustomed to the workflow.\nGenerally, you can use value labels from other software packages in are. For example, when we create a count summary with count(), the labels from the .dta-file are displayed:\n# Counting occurrences and showing labels\npend_kap5 %&gt;% \n  count(PSM0100)\n\n# A tibble: 3 × 2\n  PSM0100                            n\n  &lt;dbl+lbl&gt;                      &lt;int&gt;\n1 -5 [Does not use the internet]    28\n2  1 [Yes]                         318\n3  2 [No]                          337\nThese are assigned as attributes() variables:\nattributes(pend_kap5$PSM0100)\n\n$label\n[1] \"Usage of social networks\"\n\n$format.stata\n[1] \"%39.0f\"\n\n$labels\nItem not surveyed in wave Does not use the internet           Details refused \n                       -9                        -5                        -2 \n               Don't know                       Yes                        No \n                       -1                         1                         2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"\nenframe() from the {tibble} (part of the {tidyverse}) package helps to get data.frame with an overview of all value labels stored in an attribute:\nattributes(pend_kap5$PSM0100)$labels %&gt;% enframe(value = \"variable_value\",name = \"label\")\n\n# A tibble: 6 × 2\n  label                     variable_value\n  &lt;chr&gt;                              &lt;dbl&gt;\n1 Item not surveyed in wave             -9\n2 Does not use the internet             -5\n3 Details refused                       -2\n4 Don't know                            -1\n5 Yes                                    1\n6 No                                     2\nHowever, managing attributes() is tedious and sometimes causes problems when working with the labelled variables.\nR’s native way to work with labels are factor variables. As mentioned in chapter 2, factor variables are strings with a predefined universe and ordering.\nHow can we use the attributes()-labels as factor to save typing?\n{haven} includes the function as_factor1, which allows us to directly create a factor variable from labels:\npend_kap5$PSM0100_fct &lt;- as_factor(pend_kap5$PSM0100) # create factor variable from attributes and values\n\n# view:\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 2\n  PSM0100                        PSM0100_fct              \n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                    \n1  2 [No]                        No                       \n2  1 [Yes]                       Yes                      \n3  2 [No]                        No                       \n4 -5 [Does not use the internet] Does not use the internet\n5 -5 [Does not use the internet] Does not use the internet\n6 -5 [Does not use the internet] Does not use the internet",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#creating-or-editing-factor-manually",
    "href": "06_labels_factor.html#creating-or-editing-factor-manually",
    "title": "6  Labels & factors",
    "section": "6.2 Creating or editing factor manually",
    "text": "6.2 Creating or editing factor manually\nAlternatively, we can also label with factor() using the levels and labels options ourselves. The labels are assigned in order to the numbers from levels. Additionally, all unspecified levels automatically become NA:\n\npend_kap5$PSM0100_fct2 &lt;- factor(pend_kap5$PSM0100,\n                               levels = c(1,2),\n                               labels = c(\"Yes!\",\"No :-(\"))\n\n# view:\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 3\n  PSM0100                        PSM0100_fct               PSM0100_fct2\n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                     &lt;fct&gt;       \n1  2 [No]                        No                        No :-(      \n2  1 [Yes]                       Yes                       Yes!        \n3  2 [No]                        No                        No :-(      \n4 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n5 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n6 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n\n\nOr we can use the functions from {forcats} to recode a factor. {forcats} is part of the {tidyverse}. With fct_recode(), we can change the levels:\n\nlevels(pend_kap5$PSM0100_fct)\n\n[1] \"Item not surveyed in wave\" \"Does not use the internet\"\n[3] \"Details refused\"           \"Don't know\"               \n[5] \"Yes\"                       \"No\"                       \n\npend_kap5$PSM0100_fct3 &lt;- fct_recode(pend_kap5$PSM0100_fct,\n  `Uses social networks` =  \"Yes\", # use `` around words with spaces\n  )\nlevels(pend_kap5$PSM0100_fct3)\n\n[1] \"Item not surveyed in wave\" \"Does not use the internet\"\n[3] \"Details refused\"           \"Don't know\"               \n[5] \"Uses social networks\"      \"No\"                       \n\n\n\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 4\n  PSM0100                        PSM0100_fct           PSM0100_fct2 PSM0100_fct3\n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                 &lt;fct&gt;        &lt;fct&gt;       \n1  2 [No]                        No                    No :-(       No          \n2  1 [Yes]                       Yes                   Yes!         Uses social…\n3  2 [No]                        No                    No :-(       No          \n4 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n5 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n6 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n\n\nMore fct_....() functions from {forcats} can be found in this Cheatsheet.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#creating-label-data.frame-and-merging-with-data",
    "href": "06_labels_factor.html#creating-label-data.frame-and-merging-with-data",
    "title": "6  Labels & factors",
    "section": "6.3 Creating label data.frame and merging with data",
    "text": "6.3 Creating label data.frame and merging with data\nAn alternative approach involves creating a small label data.frame and left_join() (more on left_join() later.)\n\ntab2 &lt;- pend_kap5 %&gt;% count(PSM0100)\ntab2\n\n# A tibble: 3 × 2\n  PSM0100                            n\n  &lt;dbl+lbl&gt;                      &lt;int&gt;\n1 -5 [Does not use the internet]    28\n2  1 [Yes]                         318\n3  2 [No]                          337\n\n\n\nlab_df &lt;- data.frame(PSM0100=1:2)\nlab_df\n\n  PSM0100\n1       1\n2       2\n\nlab_df$PD0400_lab &lt;- factor(lab_df$PSM0100,\n                            levels = 1:2,\n                            labels = c(\"Uses social networks\",\n                                       \"Does not use social networks\"))\nlab_df\n\n  PSM0100                   PD0400_lab\n1       1         Uses social networks\n2       2 Does not use social networks\n\n\n\ntab2 %&gt;% \n  left_join(lab_df,by = \"PSM0100\")\n\n# A tibble: 3 × 3\n  PSM0100                            n PD0400_lab                  \n  &lt;dbl+lbl&gt;                      &lt;int&gt; &lt;fct&gt;                       \n1 -5 [Does not use the internet]    28 &lt;NA&gt;                        \n2  1 [Yes]                         318 Uses social networks        \n3  2 [No]                          337 Does not use social networks\n\n\n…or if you have multiple variables, create an Excel sheet and merge it:\n\n  pend_kap5 %&gt;% \n    select(zpsex,PSM0100) %&gt;% \n    distinct() %&gt;%  \n    pivot_longer(cols = everything()) %&gt;% \n    distinct() %&gt;% \n    arrange(name,value) %&gt;% \n  data.frame() %&gt;% \n  xlsx::write.xlsx(file = \"./data/label.xlsx\",row.names = F)\n\nWarning: `zpsex` and `PSM0100` have conflicting value labels.\nℹ Labels for these values will be taken from `zpsex`.\n✖ Values: 1 and 2\n\nlab_df2 &lt;- \n  xlsx::read.xlsx(file = \"./data/label_read.xlsx\",sheetIndex = 1)\n\n\npend_kap5 %&gt;% \n    count(zpsex,PSM0100) \n\n# A tibble: 6 × 3\n  zpsex      PSM0100                            n\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                      &lt;int&gt;\n1 1 [Male]   -5 [Does not use the internet]    13\n2 1 [Male]    1 [Yes]                         150\n3 1 [Male]    2 [No]                          161\n4 2 [Female] -5 [Does not use the internet]    15\n5 2 [Female]  1 [Yes]                         168\n6 2 [Female]  2 [No]                          176\n\nlab_df2 %&gt;% pivot_wider(names_from = name)\n\n# A tibble: 5 × 3\n  label                     PSM0100 zpsex\n  &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt;\n1 &lt;NA&gt;                      -5      &lt;NA&gt; \n2 Uses Social Media         1       &lt;NA&gt; \n3 Does not use social media 2       &lt;NA&gt; \n4 Men                       &lt;NA&gt;    1    \n5 Women                     &lt;NA&gt;    2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#exercise",
    "href": "06_labels_factor.html#exercise",
    "title": "6  Labels & factors",
    "section": "6.4 Exercise",
    "text": "6.4 Exercise\n\npend_ue5 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"pnr\",\"welle\",\"PD0400\")) %&gt;% \n  filter(PD0400&gt;0)\n\nEdit the value labels of PD0400: Religiousness, self-rating\n\n\nvaluelabel1Not at all religious2Rather not religious3Rather religious4Very religious\n\n\n\nFirst, use head() and a count with count() to get an overview.\nHow can you use the labels from the attributes() with as_factor() to create a variable PD0400_fct?\nCreate a factor() variable F411_01_fct2 with value labels: 1 = Not at all, 2 = Rather not, 3 = Rather yes, 4 = Very much\n\nBonus exercise: Use the labeled variable for a bar chart.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#appendix",
    "href": "06_labels_factor.html#appendix",
    "title": "6  Labels & factors",
    "section": "6.5 Appendix",
    "text": "6.5 Appendix\n\n6.5.1 Remove labels with zap_... from {haven}\nThe label attributes() often cause problems in further processing. With haven::zap_labels(), we can remove value labels from a dataset, and with haven::zap_label(), we can remove variable labels.\n\npend_kap5\n\n# A tibble: 683 × 6\n          pnr welle             zpsex      PSM0100                 azges1 palter\n        &lt;dbl&gt; &lt;dbl+lbl&gt;         &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;               &lt;dbl+&gt; &lt;dbl+&gt;\n 1 1000002601 8 [Wave 8 (2014)] 2 [Female]  2 [No]                 22     34    \n 2 1000010402 8 [Wave 8 (2014)] 2 [Female]  1 [Yes]                40     30    \n 3 1000019102 8 [Wave 8 (2014)] 1 [Male]    2 [No]                 40     34    \n 4 1000031403 8 [Wave 8 (2014)] 1 [Male]   -5 [Does not use the i… 44     52    \n 5 1000032801 8 [Wave 8 (2014)] 2 [Female] -5 [Does not use the i… 44     58    \n 6 1000032802 8 [Wave 8 (2014)] 1 [Male]   -5 [Does not use the i… 43     62    \n 7 1000038201 8 [Wave 8 (2014)] 1 [Male]    1 [Yes]                43     61    \n 8 1000040003 8 [Wave 8 (2014)] 1 [Male]    2 [No]                 36     40    \n 9 1000051801 8 [Wave 8 (2014)] 2 [Female]  2 [No]                 31     44    \n10 1000053101 8 [Wave 8 (2014)] 1 [Male]    1 [Yes]                27     47    \n# ℹ 673 more rows\n\npend_kap5 %&gt;% \n  haven::zap_labels() # remove value labels\n\n# A tibble: 683 × 6\n          pnr welle zpsex PSM0100 azges1 palter\n        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 1000002601     8     2       2     22     34\n 2 1000010402     8     2       1     40     30\n 3 1000019102     8     1       2     40     34\n 4 1000031403     8     1      -5     44     52\n 5 1000032801     8     2      -5     44     58\n 6 1000032802     8     1      -5     43     62\n 7 1000038201     8     1       1     43     61\n 8 1000040003     8     1       2     36     40\n 9 1000051801     8     2       2     31     44\n10 1000053101     8     1       1     27     47\n# ℹ 673 more rows\n\n\n\n\n6.5.2 Creating labels in R and exporting to Stata\nIf we want to label a dataset for Stata, for example, {labelled} comes in handy again:\n\nlibrary(labelled)\n\nError in library(labelled): es gibt kein Paket namens 'labelled'\n\n\n\npend_kap5$zpsex_num2 &lt;- as.numeric(pend_kap5$zpsex)\nattributes(pend_kap5$zpsex_num2)\n\nNULL\n\nval_labels(pend_kap5$zpsex_num2) &lt;- c(\"Men\"=1,\"Women\"=2)\n\nError in val_labels(pend_kap5$zpsex_num2) &lt;- c(Men = 1, Women = 2): konnte Funktion \"val_labels&lt;-\" nicht finden\n\nattributes(pend_kap5$zpsex_num2)\n\nNULL\n\npend_kap5 %&gt;% count(zpsex_num2)\n\n# A tibble: 2 × 2\n  zpsex_num2     n\n       &lt;dbl&gt; &lt;int&gt;\n1          1   324\n2          2   359\n\n\n\npend_kap5 %&gt;% \n  select(zpsex_num2) %&gt;% \n  haven::write_dta(.,path = \"./data/pend_kap5.dta\")\n\n…in Stata:\n\nuse \"./data/pend_kap5.dta\" \ntab zpsex_num2 \n\n(PASS V3, 2006-2019, 21 Jul 2021, PENDDAT)\n\n\n zpsex_num2 |      Freq.     Percent        Cum.\n------------+-----------------------------------\n     Männer |        324       47.44       47.44\n     Frauen |        359       52.56      100.00\n------------+-----------------------------------\n      Total |        683      100.00\n\n\nMore on labels in {labelled}.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#footnotes",
    "href": "06_labels_factor.html#footnotes",
    "title": "6  Labels & factors",
    "section": "",
    "text": "Not to be confused with as.factor() from base R – the _ makes a difference!↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html",
    "href": "07_viz_translated.html",
    "title": "7  Visualization with {ggplot2}",
    "section": "",
    "text": "7.1 ggplot2 and the Grammar of Graphics\nggplot2 is the implementation of the concept of “layered grammar of graphics” in R. The idea of this visualization system is to break down data visualization into parameters: the underlying dataset, the variables to be displayed, the choice of display shapes, the coordinate system, scales, and statistical transformations. A standard command in ggplot2 looks something like this:\nggplot(data = dataset, aes(x = var1, y = var2, color = var3)) +\n  geom_point() +\n  labs(title= \"Title\", subtitle = \"Subtitle\") +\n  theme_minimal()\nSo we first call up a plot with ggplot(). Further arguments then define additional aspects:\nNow we will work through the individual layers of the graphic:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#ggplot2-and-the-grammar-of-graphics",
    "href": "07_viz_translated.html#ggplot2-and-the-grammar-of-graphics",
    "title": "7  Visualization with {ggplot2}",
    "section": "",
    "text": "With data =, we specify the data.frame we want to visualize.\nThe aesthetics aes() specify which variables are to be displayed: here var1 on the x-axis, var2 on the y-axis, and var3 for coloring.\nThe layers geom_.. specify the type of display, e.g., geom_point() for point plots and geom_bar() for bar charts.\nWith labs, we can add labels, such as a title or axis labels.\nThe themes theme_... set the design of the graphic, e.g., black and white axes and background colors with theme_bw().\n\n\n\n7.1.1 data =\nIn data =, we specify the data.frame that contains the information to be visualized. We start our ggplot with:\n\nggplot(data = pend_small)\n\n\n\n\n\n\n\n\n\n\n7.1.2 aes\nWe want to visualize these values in a scatterplot, with age on the x-axis and weekly working hours on the y-axis:\n\nggplot(data = pend_small, aes(x = palter, y = azges1))\n\n\n\n\n\n\n\n\n\n\n7.1.3 geom\nIf we only provide these details, we will get an empty coordinate system—why? Because we haven’t yet specified what form of display we want. For this, we must specify a geom_, such as geom_col() for bar charts, which we attach to the ggplot command with +:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point()\n\n\n\n\n\n\n\n\nWith color =, we can also change the color of the points:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point(color = \"orange\")\n\n\n\n\n\n\n\n\nHere is an overview of all color names that are recognized, though there are many more colors—see Appendix.\n\n\n7.1.4 aes() Part II\nThis already looks pretty good, but the points are not yet separated by gender. To do this, we need to include the gender information (zpsex) in aes(). In addition to the axes, aes() also specifies the variables for the appearance of the geom_s—this can include not only color but also shape, size, or transparency. Here’s an overview.\nGender should determine the color of the points, which we can specify in aes with color:\n\n# results in an error due to labels:\nggplot(data = pend_small, aes(x = palter, y = azges1, color = zpsex )) + \n  geom_point()\n\nError in UseMethod(\"rescale\"): nicht anwendbare Methode für 'rescale' auf Objekt der Klasse \"c('haven_labelled', 'vctrs_vctr', 'double')\" angewendet\n\n\nA numeric variable for color = results in a color gradient, while a factor/character variable results in a discrete color scale:\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.numeric(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.character(zpsex))) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also specify custom colors with scale_color_manual1, and a list of possible colors can be found here.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"))\n\n\n\n\n\n\n\n\n\n\n7.1.5 Labels\nWith the breaks and labels options, we can also edit the legend labels. To do this, we first specify the levels of the gender variable in breaks and then the corresponding labels in the same order:\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\n\n\n\n\n\n\n\n\nFinally, we adjust the labels with labs, where we have the following options:\n\ntitle: Title for the graphic\nsubtitle: Subtitle for the title\ncaption: Annotation below the graphic\nx: x-axis label\ny: y-axis label\nfill: Legend label when fill is specified in aes()\ncolor: Legend label when color is specified in aes()\nlinetype: Legend label when linetype is specified in aes()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#combination-of-all-options",
    "href": "07_viz_translated.html#combination-of-all-options",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.2 Combination of all options",
    "text": "7.2 Combination of all options\n\nggplot(data = pend_small, aes(x = palter, y = azges1, \n                               shape = as.factor(zpsex),\n                               color = as.factor(zpsex))) + \n  geom_point(size = 4) + \n  scale_color_manual(values = c(\"lightskyblue\",\"orange\"),\n                     breaks = c(1,2), labels = c(\"Men\", \"Women\")\n                     ) +\n  scale_shape_manual(values = c(18,20),\n                     breaks = c(1,2), labels = c(\"Men\", \"Women\")\n                     ) +\n  labs(color = \"Gender\", \n       shape = \"Gender\",\n       y = \"Hours/Week\",\n       x = \"Age\",\n       title = \"Working hours and age\",\n       subtitle = \"By Gender\",\n       caption = \"Soruce: PASS CF 0619\"\n       ) \n\n\n\n\n\n\n\n\nÜbersicht zu shapes",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#visualizing-distributions",
    "href": "07_viz_translated.html#visualizing-distributions",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.3 Visualizing distributions",
    "text": "7.3 Visualizing distributions\nWith the following syntax we can create a boxplot using ggplot2. Since we are only considering one variable, we only need to specify y = or x = depending on whether the box should be oriented vertically or horizontally.\nggplot(data = pend_small, aes(y = azges1)) + geom_boxplot()\nggplot(data = pend_small, aes(x = azges1)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also create separate boxplots for men and women by specifying a variable for the other axis:\n\nggplot(data = pend_small, aes(y = azges1, x = factor(zpsex))) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n7.3.1 Histogram\nWe can also describe distributions using a histogram using the geom_histogram() function. If we want to change the color, fill = is the correct option instead of color =:\nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram()  \nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram(fill = \"sienna1\")  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo split the histogram by gender, we can again specify fill as an aesthetic. With position = position_dodge(), we can place the bars side by side:\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram() \nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe scale_...manual commands still work here, but as scale_fill_manual instead of scale_color_manual:\n\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) +\n  scale_fill_manual(values = c(\"sienna1\",\"dodgerblue4\"),\n                    breaks = 1:2, labels = c(\"Männer\",\"Frauen\")) +\n  labs(fill = \"Geschlecht\")\n\n\n\n\n\n\n\n\n\n\n7.3.2 Exercise",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#categorical-variables",
    "href": "07_viz_translated.html#categorical-variables",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.4 Categorical variables",
    "text": "7.4 Categorical variables\nNext, we’ll look at a way to visualize the contingency table from Chapter 2:\n\npend_small$PD0400[pend_small$PD0400&lt;0] &lt;- NA # exclude missings\npend_small %&gt;% \n  count(zpsex, PD0400) \n\n# A tibble: 10 × 3\n   zpsex      PD0400                        n\n   &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                 &lt;int&gt;\n 1 1 [Male]    1 [Not at all religious]    40\n 2 1 [Male]    2 [Rather not religious]    41\n 3 1 [Male]    3 [Rather religious]        49\n 4 1 [Male]    4 [Very religious]          22\n 5 1 [Male]   NA                          780\n 6 2 [Female]  1 [Not at all religious]    26\n 7 2 [Female]  2 [Rather not religious]    34\n 8 2 [Female]  3 [Rather religious]        40\n 9 2 [Female]  4 [Very religious]          16\n10 2 [Female] NA                          816\n\n\nWith geom_bar(), we can create bars by setting the height as the count of observations with ..count.. for y:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = ..count..)) +\n  geom_bar(position = position_dodge()) \n\n\n\n\n\n\n\n\nHow do we get relative frequencies? We adjust our aes to y = (..count..)/sum(..count..). With scale_y_continuous(labels = scales::label_percent(accuracy = 1)), we can also display percentages on the y-axis. To create a bar chart instead of a column chart, simply swap x and y and adjust the percentage labels using scale_x_continuous:\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = (..count..)/sum(..count..) )) +\n  geom_bar(position = position_dodge()) +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1)) \npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(y = as_factor(PD0400), fill = factor(zpsex),\n                       x = (..count..)/sum(..count..) )) +\n  geom_bar(position = position_dodge()) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese charts can also be customized with scale_... and labeled in detail using labs()—all options are consistent across different types of visualizations. Additionally, we can label the categories ourselves with breaks = and labels = if we don’t like the default labels:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(y = PD0400, fill = factor(zpsex),\n                       x = (..count..)/sum(..count..) )) +\n  geom_bar(position=position_dodge()) +\n  scale_fill_manual(values = c(\"navajowhite\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\")) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  scale_y_continuous(breaks = 1:4, \n                     labels = c(\"Überhaupt nicht\",\n                                \"Eher nicht\",\n                                \"Eher schon\",\n                                \"Sehr\")) +\n  labs(title = \"Religiösität nach Geschlecht\",\n       subtitle = \"Relative Häufigkeiten\",\n       caption = \"Quelle: PASS-CF 0619\",\n       y = \"Religiösität\",\n       x = \"Relative Häufigkeit\",\n       fill = \"Geschlecht\" ) \n\n\n\n\n\n\n\n\n\n7.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#exercises",
    "href": "07_viz_translated.html#exercises",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.5 Exercises",
    "text": "7.5 Exercises\nFor all tasks, use the first 150 observations (pend_small) to keep the plot simple. Remember to exclude missing values with filter(); you can use the following command:\n\npend &lt;- \n  haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\", \n    col_select = c(\"zpsex\", \"welle\", \"bilzeit\", \"PA0445\", \"PG1270\", \"PEO0400c\")\n  )\n\n\n7.5.1 Exercise 1\n\npend_u41 &lt;- \n  pend %&gt;% \n  filter(welle == 13, bilzeit &gt; 0, PA0445 &gt; 0) \n\n\nCreate a scatter plot for the variables “Duration of total unemployment experience in months” (PA0445, y-axis) and “Duration of education” (bilzeit, x-axis).\nSet the color to differentiate between men and women (zpsex).\nChange the colors to goldenrod1 and dodgerblue4 (or any other from this list).\nLabel the axes and legend!\n\nBack to top\n\n\n7.5.2 Exercise 2\n\npend_u42 &lt;- \n  pend %&gt;% \n  filter(welle == 9, PG1270 &gt; 0) \n\n\nCreate a boxplot or histogram for the distribution of the number of cigarettes and cigarillos smoked per day (in the last week) (PG1270).\nCustomize this graphic so that the distributions for men and women are shown separately.\nHow can you also set the colors based on gender? (Remember color = and fill =).\nChange the bar colors using scale_fill_manual, scale_fill_brewer, or scale_fill_viridis (see the sections Colors, ColorBrewer, and viridis under “other options”).\n\nBack to top\n\n\n7.5.3 Exercise 3\n\npend_u43 &lt;- \n  pend %&gt;% \n  filter(welle == 11, PEO0400c &gt; 0) \n\n\nCreate a bar chart for the responses to the question, “A working mother can have just as close a relationship with her children as a mother who is not employed.” (PEO0400c).\nCreate a bar chart for PEO0400c separated by the migration variable, so set the bar colors based on migration. The migration variable captures whether the respondents have a migration background:\n\n\n\nVariablevaluelabel`PEO0400c`1Completely agree2Rather agree3Rather not agree4Do not agree at all`migration`1No migration background2Person is immigrated3At least one parent is immigrated4At least one grand-parent is immigrated, parents born in GER\n\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#more-options-for-ggplot2",
    "href": "07_viz_translated.html#more-options-for-ggplot2",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.6 More options for {ggplot2}",
    "text": "7.6 More options for {ggplot2}\n\n7.6.1 Aesthetics\n\n\n\n\n\n\n\n\n\n\n\n7.6.2 themes\nWith so-called themes, we can change the layout of the graphic. Other themes include theme_light(), theme_classic(), or theme_void(). A full list can be found here. Additionally, the {ggthemes} package (install.packages('ggthemes')) offers a wide selection.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) + \n  theme_minimal()\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) +\n  theme_dark()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.6.3 Farben\n\np1 &lt;- ggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 3) \n\nNeben den im Beispiel verwendeten Farben für fill können natürlich auch noch unzählige weitere Farben in scale_fill_manual und scale_color_manual verwendet werden:\n\nHier findet sich eine Übersicht mit allen Farbnamen, die verstanden werden\nAlternativ können auch sog. HEX-Codes angeben werden, die bspw. mit dem Adobe Color Wheel oder Color Hex erstellt werden können.\n\np1 +  scale_color_manual(values = c(\"dodgerblue4\",\"sienna1\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\np1 +  scale_color_manual(values = c(\"#005b96\",\"#6497b1\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.6.3.1 ColorBreweR\nAlternativ zur manuellen Auswahl der Farben mit scale_fill_manual und scale_color_manual können mit scale_fill_brewer() auch vorgegebene Farbpaletten des colorbrewer verwendet werden. Dazu muss lediglich scale_fill_brewer() anstelle von scale_fill_manual angeben werden und statt values eine der Paletten - eine Übersicht findet sich hier. Die Farbpaletten von ColorBreweR sind alle in ggplot2 integriert.\n\np1 +\n  scale_color_brewer(palette = \"RdYlBu\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n7.6.3.2 viridis\nAnalog dazu gibt es auch die {viridis}-Paletten, welche durchgängig “colorblind-safe” und ebenfalls in {ggplot2} integriert sind. Allerdings ist hier zu beachten, dass für Farbauswahlen basierend auf einer kategorialen Variable scale_color_viridis_d() zu verwenden ist. Soll die Farbe entlang einer numerischen/metrischen Variable bestimmt werden, dann ist scale_color_viridis_c() zu verwenden. Außerdem kann mit begin und end die Breite der Farbskala angepasst werden:\np1 +\n  scale_color_viridis_d(option=\"magma\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \np1 +\n  scale_color_viridis_d(option=\"magma\",begin = .65,end = .85,\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.6.3.3 Weitere Farbpaletten\nDarüber hinaus gibt es unzählige Pakete, die ebenfalls scale_color_ und scale_fill_-Funktionen bieten: Hier noch zwei Beispiele mit {scico} und {MetBrewer}, welches Farben aus Bildern im Metropolitan Museum of Art enthält:\n\ninstall.packages('scico')\ninstall.packages(\"MetBrewer\")\n\n{scico} Farbpaletten\n\n\n\n\n\n\n\n\n\n{MetBrewer} Farbpaletten\n\n\n\n\n\n\n\n\n\nlibrary(scico)\np1 +\n  scale_color_scico_d(palette = \"oslo\",begin = .5,end = .8,\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \nlibrary(MetBrewer)\np1 +\n  scale_color_met_d(name = \"Kandinsky\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparable packages also exist for:\n\n{DutchMasters} - Color palettes from paintings by Dutch masters.\n{wesanderson} - Color palettes based on various Wes Anderson films (e.g., The Grand Budapest Hotel).\n{ochRe} - Color palettes “inspired by Australian art, landscapes, and wildlife.”\n{paletteer} offers a vast selection of various color palettes.\n\nCheck out the interactive color picker here\n\n\n\n7.6.4 Shapes\n\n\n\n\n\n\n\n\n\nZusätzlicher Überblick\n\n\n7.6.5 Linetypes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\n\n\nShapes und Linetypes at a glance in the R Cookbook",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#useful-links",
    "href": "07_viz_translated.html#useful-links",
    "title": "7  Visualization with {ggplot2}",
    "section": "7.7 Useful links",
    "text": "7.7 Useful links\n\nThe Graphs chapter of the R Cookbook is an excellent resource for various options and a basic overview—for example, on adjusting the legend, line and point types, or the axes.\nAdjusting font size and color: This guide provides a good overview of how to modify font size and color in {ggplot2}.\nFrom Data to Viz offers a decision tree for various relationships and descriptions with example syntax.\n\n\n\n\n\n\n\n\n\n\n\nThe R Graph Gallery is even more extensive and offers additional visualization ideas.\nFor those who want to learn more about effective (and beautiful) data visualizations with {ggplot2}, Cédric Scherer’s tutorial is an excellent introduction. This workshop is great for further exploration.\nThis workshop offers additional insights on how to make data visualizations more appealing with {ggplot2}.\nA list of extensions for ggplot2.\nThe book on {ggplot2}.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#footnotes",
    "href": "07_viz_translated.html#footnotes",
    "title": "7  Visualization with {ggplot2}",
    "section": "",
    "text": "If we had specified color in aes, the corresponding command would be scale_color_manual.↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "09_reg.html",
    "href": "09_reg.html",
    "title": "8  Regression models",
    "section": "",
    "text": "8.1 Regression Models with lm()\nRegression models in R can be created with lm(). Here, we specify the variable for the y-axis (the dependent variable) and, after a ~, the variable for the x-axis (the independent variable). We will discuss the interpretation of the results in the coming weeks.\nlm(var2 ~ var1, data = dat1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839\nThe value under var1 indicates how much the line changes up/down per “step to the right”. Thus, the line increases by 1.8389662 for each unit of var1. We can store the results under m1:\nm1 &lt;- lm(var2 ~ var1, data = dat1)\nWith summary(), we get a regression table:\nsummary(m1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.372 -3.613  0.162  2.234 10.789 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -2.3400     4.3454  -0.538   0.6096  \nvar1          1.8390     0.7727   2.380   0.0548 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.127 on 6 degrees of freedom\nMultiple R-squared:  0.4856,    Adjusted R-squared:  0.3999 \nF-statistic: 5.664 on 1 and 6 DF,  p-value: 0.05477\nm1 contains all the information about the model, and $coefficients is particularly helpful:\nm1$coefficients\n\n(Intercept)        var1 \n  -2.339960    1.838966 \n\nsummary(m1)$coefficients\n\n             Estimate Std. Error    t value   Pr(&gt;|t|)\n(Intercept) -2.339960  4.3453801 -0.5384938 0.60961706\nvar1         1.838966  0.7727028  2.3799139 0.05477457\nWe can view the individual values with View(m1):\nFor example, fitted.values contains the predicted values for each case.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#visualizing-regression-lines-and-data",
    "href": "09_reg.html#visualizing-regression-lines-and-data",
    "title": "8  Regression models",
    "section": "8.2 Visualizing Regression Lines and Data",
    "text": "8.2 Visualizing Regression Lines and Data\nWith geom_smooth(method = \"lm\"), we can also represent regression lines in {ggplot2}:\nWe can visualize our model with var1 and var2 as follows:\n\nlibrary(ggplot2)\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  \n\n\n\n\n\n\n\n\nHere, it appears we have an outlier. In our small dataset, it is easy to find. In larger datasets, geom_text() can help us:\n\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  +\n  geom_text(data = . %&gt;% filter(var2 &gt; 20), aes(y = var2 + 3, label = id), color = \"sienna1\")\n\n\n\n\n\n\n\n\nWe can also specify geom_ for just a subset by reassigning data = (not using the selection from the main ggplot() command) and applying a filter(). Additionally, we shift the label slightly above the point with var2 + 3.\n\n8.2.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#calculating-models-for-specific-cases",
    "href": "09_reg.html#calculating-models-for-specific-cases",
    "title": "8  Regression models",
    "section": "8.3 Calculating Models for Specific Cases",
    "text": "8.3 Calculating Models for Specific Cases\nIf we want to recalculate the model, we have two options:\n\n8.3.1 Create a New Data Frame\nWe can keep multiple data.frame objects in memory in R. Thus, we can easily create a new data.frame containing only observations with var2 &lt; 20 and use this for our lm() command:\n\ndat1_u20 &lt;- dat1 %&gt;% filter(var2 &lt; 20)\nm2a &lt;- lm(var2 ~ var1, data = dat1_u20)\nsummary(m2a)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1_u20)\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456\n\n\n\n\n8.3.2 Filter Directly in lm()\nWe can also incorporate the filter() command directly into the data= argument of lm():\n\nm2b &lt;- lm(var2 ~ var1, data = dat1 %&gt;% filter(var2 &lt; 20))\nsummary(m2b)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1 %&gt;% filter(var2 &lt; 20))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#regression-tables",
    "href": "09_reg.html#regression-tables",
    "title": "8  Regression models",
    "section": "8.4 Regression tables",
    "text": "8.4 Regression tables\nIf we want to compare these different models, a table is a good option.\nThere are numerous alternatives for creating regression tables, and my personal favorite is modelsummary() from the eponymous package {modelsummary}. It handles (almost) all types of models and offers a wide range of features, including Word output (more on this later) and coefficient plots (which we will also cover). Additionally, the documentation is excellent.\n\nfdz_install(\"modelsummary\")\n\n\nlibrary(modelsummary)\nmodelsummary(list(m1,m2a,m2b))\n\n \n\n  \n    \n    \n    tinytable_9nbqnwjw9l8j1ueg0fbu\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -2.340 \n                  1.138  \n                  1.138  \n                \n                \n                             \n                  (4.345)\n                  (1.922)\n                  (1.922)\n                \n                \n                  var1       \n                  1.839  \n                  0.668  \n                  0.668  \n                \n                \n                             \n                  (0.773)\n                  (0.388)\n                  (0.388)\n                \n                \n                  Num.Obs.   \n                  8      \n                  7      \n                  7      \n                \n                \n                  R2         \n                  0.486  \n                  0.372  \n                  0.372  \n                \n                \n                  R2 Adj.    \n                  0.400  \n                  0.247  \n                  0.247  \n                \n                \n                  AIC        \n                  55.4   \n                  36.6   \n                  36.6   \n                \n                \n                  BIC        \n                  55.6   \n                  36.5   \n                  36.5   \n                \n                \n                  Log.Lik.   \n                  -24.702\n                  -15.321\n                  -15.321\n                \n                \n                  F          \n                  5.664  \n                  2.967  \n                  2.967  \n                \n                \n                  RMSE       \n                  5.31   \n                  2.16   \n                  2.16   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nWe will delve a bit more into the customization options for {modelsummary} later, but here are two key options for now:\n\nBy using stars = T, we can display the significance levels with the common star codes (*: p &lt; .05, etc.)\nBy using gof_omit = \"IC|RM|Log\", we can hide the goodness of fit statistics that have IC, RM, or Log in their names (such as AIC, BIC, RMSE, and LogLikelihood)\nBy using \"Name\" = in list(), we can specify names:\n\n\nmodelsummary(list(\"m1\"=m1,\"m2a\"=m2a,\"m2b\"=m2b),stars = T,gof_omit = \"IC|RM|Log\")\n\n \n\n  \n    \n    \n    tinytable_jldljqt9301ky0wunxvl\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                m1\n                m2a\n                m2b\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  -2.340 \n                  1.138  \n                  1.138  \n                \n                \n                             \n                  (4.345)\n                  (1.922)\n                  (1.922)\n                \n                \n                  var1       \n                  1.839+ \n                  0.668  \n                  0.668  \n                \n                \n                             \n                  (0.773)\n                  (0.388)\n                  (0.388)\n                \n                \n                  Num.Obs.   \n                  8      \n                  7      \n                  7      \n                \n                \n                  R2         \n                  0.486  \n                  0.372  \n                  0.372  \n                \n                \n                  R2 Adj.    \n                  0.400  \n                  0.247  \n                  0.247  \n                \n                \n                  F          \n                  5.664  \n                  2.967  \n                  2.967  \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nThe output = option allows us to export the modelsummary as .docx-file:\n\nmodelsummary(list(\"m1\"=m1,\"m2a\"=m2a,\"m2b\"=m2b),stars = T,gof_omit = \"IC|RM|Log\",output = \"./results/Regression_table.docx\")\n\n\n8.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#categorical-independent-variables",
    "href": "09_reg.html#categorical-independent-variables",
    "title": "8  Regression models",
    "section": "8.5 Categorical Independent Variables",
    "text": "8.5 Categorical Independent Variables\nOf course, we can also include categorical independent variables in our model. However, we need to define the relevant variables as factors to inform R that the numeric values should not be interpreted numerically.\nFor instance, in our small example, educ represents education levels where 1 stands for basic education, 2 for intermediate, and 3 for high education.\n\ndat1\n\n  id var1 var2 educ gend  x\n1  1    2    2    3    2  2\n2  2    1    2    1    1  1\n3  3    2    1    2    1  2\n4  4    5    9    2    2  4\n5  5    7    7    1    1  1\n6  6    8    4    3    2 NA\n7  7    9   25    2    1 NA\n8  8    5    3   -1    2 NA\n\nm3 &lt;- lm(var2 ~ factor(educ), dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ factor(educ), data = dat1)\n\nResiduals:\n         1          2          3          4          5          6          7 \n-1.000e+00 -2.500e+00 -1.067e+01 -2.667e+00  2.500e+00  1.000e+00  1.333e+01 \n         8 \n-1.277e-15 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    3.000e+00  8.848e+00   0.339    0.752\nfactor(educ)1  1.500e+00  1.084e+01   0.138    0.897\nfactor(educ)2  8.667e+00  1.022e+01   0.848    0.444\nfactor(educ)3 -1.088e-15  1.084e+01   0.000    1.000\n\nResidual standard error: 8.848 on 4 degrees of freedom\nMultiple R-squared:  0.2848,    Adjusted R-squared:  -0.2516 \nF-statistic: 0.531 on 3 and 4 DF,  p-value: 0.685\n\n\nIt’s even better if we label educ beforehand:\n\ndat1$ed_fct &lt;- factor(dat1$educ, levels = 1:3,\n                        labels = c(\"basic\", \"medium\", \"high\"))\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   &lt;NA&gt;\n\n\nThen use the factor in the regression command:\n\nm3 &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     4.500      6.257   0.719    0.512\ned_fctmedium    7.167      8.077   0.887    0.425\ned_fcthigh     -1.500      8.848  -0.170    0.874\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nCompared to educ = basic, the predicted value for var2 when educ = medium is 7.17 higher.\nCompared to educ = basic, the predicted value for var2 when educ = high is -1.5 higher.\n\nWe can also change the reference category:\n\ndat1$ed_fct &lt;- relevel(dat1$ed_fct, ref = \"medium\")\nm3b &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3b)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   11.667      5.109   2.284   0.0844 .\ned_fctbasic   -7.167      8.077  -0.887   0.4251  \ned_fcthigh    -8.667      8.077  -1.073   0.3437  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nCompared to educ = medium, the predicted value for var2 when educ = basic is 7.17 lower.\nCompared to educ = medium, the predicted value for var2 when educ = high is 8.67 lower.\n\n\n8.5.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#multiple-independent-variables",
    "href": "09_reg.html#multiple-independent-variables",
    "title": "8  Regression models",
    "section": "8.6 Multiple Independent Variables",
    "text": "8.6 Multiple Independent Variables\nTo include multiple independent variables in our regression models, we specify them using +:\n\nm4 &lt;- lm(var2 ~ ed_fct + var1, dat1)\nsummary(m4)\n\n\nCall:\nlm(formula = var2 ~ ed_fct + var1, data = dat1)\n\nResiduals:\n     1      2      3      4      5      6      7 \n 4.258  2.758 -4.824 -2.082 -2.758 -4.258  6.907 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   2.3187     5.8227   0.398    0.717\ned_fctbasic  -4.8297     6.0381  -0.800    0.482\ned_fcthigh   -8.0824     5.9411  -1.360    0.267\nvar1          1.7527     0.8347   2.100    0.127\n\nResidual standard error: 6.501 on 3 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.7002,    Adjusted R-squared:  0.4003 \nF-statistic: 2.335 on 3 and 3 DF,  p-value: 0.2521",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#modelplot",
    "href": "09_reg.html#modelplot",
    "title": "8  Regression models",
    "section": "8.7 Coefficient Plots",
    "text": "8.7 Coefficient Plots\nIn addition to regression tables, {modelsummary} provides the modelplot() function, which makes it easy to create coefficient plots from one or more models:\n\nmodelplot(m4)\n\n\n\n\n\n\n\n\nFor model comparison, simply provide the models in a named list, and you can further customize the plot with the usual {ggplot2} commands:\n\nmodelplot(list(\"Model 1\" = m1,\n               \"Model 4\" = m4))\n\n\n\n\n\n\n\n\nWith coef_map, you can assign labels to the coefficients (note that (Intercept) does not get a name and is therefore omitted):\n\nmodelplot(list(\"Model 1\" = m1,\n               \"Model 4\" = m4),\n          coef_map = c(\"var1\" = \"Name for var1\",\n                       \"ed_fcthigh\" = \"Higher Education\",\n                       \"ed_fctbasic\" = \"Basic Education\"\n                          ))\n\n\n\n\n\n\n\n\nYou can also further customize the plot with the usual {ggplot2} commands:\n\nmodelplot(list(\"Model 1\" = m1,\n               \"Model 4\" = m4),\n          coef_map = c(\"var1\" = \"Name for var1\",\n                       \"ed_fcthigh\" = \"Higher Education\",\n                       \"ed_fctbasic\" = \"Basic\\nEducation\")) + # \\n inserts a line break\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"grey40\") +  # Add a 0 line\n  scale_color_manual(values = c(\"orange\", \"navy\")) +\n  theme_minimal(base_size = 15, base_family = \"mono\") \n\n\n\n\n\n\n\n\nWith {broom}, you can also create a data.frame from the regression results and create the ggplot entirely yourself - see appendix.\n\n8.7.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#exercises",
    "href": "09_reg.html#exercises",
    "title": "8  Regression models",
    "section": "8.8 Exercises",
    "text": "8.8 Exercises\nUse the following subset of the PASS CampusFile:\n\npend_ue08 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\") %&gt;% \n  filter(welle == 13, netges &gt; 0, azges1 &gt; 0, schul2 &gt; 1, palter &gt; 0)\n\n\n8.8.1 Exercise 1: Regression\n\nCreate an object mod1 with a linear regression model (lm) where netges (monthly net income in EUR) is the dependent variable and azges1 (working hours) is the independent variable! (see here)\nExamine the results of mod1 - what can you infer about the relationship between netges and azges1?\nVisualize your regression model with {ggplot2}.\nDo you see any outliers in the scatter plot? Mark them using the variable pnr and geom_text().\n\n\n\n8.8.2 Exercise 2: Only Some Observations\n\nCreate an lm() model mod2 that is based only on observations with a monthly income of less than 20,000 EUR.\nCreate a regression table that places this new model mod2 next to the model mod1 from Exercise 1.\n\n\n\n8.8.3 Exercise 3: Categorical Independent Variables\n\nCreate a regression model with the income of respondents (netges) as the dependent variable and the education level of the respondents schul as the independent variable:\n\n\n\n\n\n\n\n\n\nvalue\nlabel\n\n\n\n\n&lt;0 & 1\nNA\n\n\n3\nSchool incorporating physically or mentally disabled children (Sonderschulabschluss)\n\n\n4\nLower secondary school (Hauptschulabschluss)\n\n\n5\nIntermediate secondary school (Realschulabschluss, Mittlere Reife)\n\n\n6\nUpper secondary Fachoberschule, Fachhochschulreife)\n\n\n7\nGeneral/subject-specific upper secondary school (Hochschulreife)\n\n\n\n\n\n\n\n\nEnsure that schul2 is defined as a factor. Assign the labels “none”, “Special School”, “Secondary School”, “Intermediate Diploma”, “Vocational School”, “Abitur” to levels 2-7 and save the factor as a variable schul2_fct in your data.frame - see the code help below:\n\n\n\nCode\npend_ue08$schul2_fct &lt;-  \n  factor(pend_ue08$schul2, levels = 2:7, labels = c(\"none\", \"Special School\", \"Secondary School\", \"Intermediate Diploma\", \"Vocational School\", \"Abitur\"))\n\n\n\nCreate the regression model using this new factor variable for schul2_fct as the independent variable.\nChange the reference category to Intermediate Diploma (schul2 = 5) and estimate the model again.\n\n\n\n8.8.4 Exercise 4: Multiple Independent Variables & Coefficient Plot\n\nAdjust the lm() model mod1 (with all cases from pend_u08) to include the education level (schul2) as an additional independent variable.\nAlso create a graphical comparison of the two models with and without the education level.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#appendix",
    "href": "09_reg.html#appendix",
    "title": "8  Regression models",
    "section": "8.9 Appendix",
    "text": "8.9 Appendix\n\ndat1 &lt;- dat1 %&gt;% select(-matches(\"compl\"))\n\n\n8.9.1 Predicted Values\nThe predicted values from lm() can be found under $fitted.values:\n\nm1$fitted.values\n\n        1         2         3         4         5         6         7         8 \n 1.337972 -0.500994  1.337972  6.854871 10.532803 12.371769 14.210736  6.854871 \n\n\nThese predicted values are simply the sum of the value under Intercept and the value under var1 multiplied by the respective value for var1.\n\nm1\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839  \n\n\nFor the first row of dat1, the predicted value from m1 is: 2.1351 + 0.5811 * 1 =2.7162\nThe values under fitted.values follow the order in the dataset, so we can simply add them as a new column in dat1:\n\ndat1$lm_predictions &lt;- m1$fitted.values\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_predictions\n1  1    2    2    3    2  2   high       1.337972\n2  2    1    2    1    1  1  basic      -0.500994\n3  3    2    1    2    1  2 medium       1.337972\n4  4    5    9    2    2  4 medium       6.854871\n5  5    7    7    1    1  1  basic      10.532803\n6  6    8    4    3    2 NA   high      12.371769\n7  7    9   25    2    1 NA medium      14.210736\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871\n\n\nThe plot shows how predictions based on m1 look: They correspond to the values on the blue line (the so-called regression line) at the respective points for var1.\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) +\n  geom_point(size = 3) +      \n  geom_smooth(method = \"lm\", color = \"darkblue\", se = FALSE, size = .65) +\n  geom_point(aes(x = var1, y = lm_predictions), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8), y = c(0,8))\n\n\n\n\n\n\n\n\n\n\n\n8.9.2 Residuals\nThe light blue points (i.e., the predictions from m1) are close to the actual points. However, even the light blue points do not perfectly overlap with the actual values. These deviations between the predicted and actual values are called residuals: \\[Residual = observed\\, value \\; - \\; predicted\\, value\\] \\[\\varepsilon_{\\text{i}} = \\text{y}_{i} - \\hat{y}_{i}\\] We can calculate these manually as the difference between the actual and predicted value or simply call them using m1$residuals:\n\nm1$residuals\n\n         1          2          3          4          5          6          7 \n 0.6620278  2.5009940 -0.3379722  2.1451292 -3.5328032 -8.3717694 10.7892644 \n         8 \n-3.8548708 \n\n\nWe can also store the residuals for lm in dat1:\n\ndat1$lm_residuals &lt;- m1$residuals\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_predictions lm_residuals\n1  1    2    2    3    2  2   high       1.337972    0.6620278\n2  2    1    2    1    1  1  basic      -0.500994    2.5009940\n3  3    2    1    2    1  2 medium       1.337972   -0.3379722\n4  4    5    9    2    2  4 medium       6.854871    2.1451292\n5  5    7    7    1    1  1  basic      10.532803   -3.5328032\n6  6    8    4    3    2 NA   high      12.371769   -8.3717694\n7  7    9   25    2    1 NA medium      14.210736   10.7892644\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871   -3.8548708\n\n\nHere are the residuals for lm shown in light blue:\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_smooth(method = \"lm\", color = \"darkblue\", se = FALSE, size = .65) +\n  geom_segment(aes(x = var1, xend = var1, y = var2, yend = lm_predictions), color = \"dodgerblue3\", size = .65, linetype = 1) +\n  geom_point(size = 3) +\n  geom_point(aes(x = var1, y = lm_predictions), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8), y = c(0,8))\n\n\n\n\n\n\n\n\n\n\n\n8.9.3 Checking Assumptions\nModel Dashboard\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\n\nmodel_test &lt;- check_model(m4)\nplot(model_test)\n\n\n\n\n\n\n\n\n\n\n8.9.4 Test for Normal Distribution of Residuals\nGraphical check: Q-Q plot\n\nlibrary(ggfortify)\nautoplot(m1, which = 2)\n\n\n\n\n\n\n\n\n\n\nYou can check the normality assumption with the Shapiro-Wilk test & shapiro.test(). This tests the null hypothesis \\(H_0\\): “The residuals are normally distributed” against the alternative hypothesis \\(H_A\\): “The residuals significantly deviate from normal distribution.”\n\nshapiro.test(m1$residuals) \n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.95346, p-value = 0.746\n\n\n\n\n8.9.5 Test for Homoscedasticity\nHomoscedasticity is present when the predicted values are approximately equally distant from the actual values (m1\\$fitted.values) across the entire range of values. There is both a graphical method for checking this and a formal test. For the graphical check, the predicted values and the residuals are plotted as a scatterplot. The autoplot() function can be helpful here:\n\nautoplot(m1, which = 1)\n\n\n\n\n\n\n\n\n\n\nThe associated test is the Breusch-Pagan test. This test evaluates the null hypothesis (\\(H_0\\)) of “homoscedasticity” against the alternative hypothesis (\\(H_A\\)) of “heteroscedasticity.” The p-value indicates the probability with which we must reject the homoscedasticity assumption. In R, you can use bptest from the lmtest package for this:\n\ninstall.packages(\"lmtest\")\n\n\nlibrary(lmtest)\nbptest(m3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m3\nBP = 3.6069, df = 2, p-value = 0.1647\n\n\n\n\n8.9.6 Test for Multicollinearity\n\ninstall.packages(\"car\")\n\n\n# library(car)\npendx &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",n_max = 300)  %&gt;% filter(netges &gt;0, palter &gt;0 )\nmox &lt;- lm(netges ~ palter + azges1, data=pendx)\ncar::vif(mox)\n\n  palter   azges1 \n1.000133 1.000133 \n\n\n\nA common threshold for the Variance Inflation Factor (VIF) is 10. Values of VIF above 10 indicate a serious multicollinearity problem, and often measures are recommended starting from a stricter threshold of about 5.00. In this specific example, all independent variables are within acceptable limits according to both thresholds.\nIf multicollinearity is present, there are several ways to address it: We can exclude one or more independent variables from the model. This is ultimately a substantive question and cannot be resolved with a standard recipe. Alternatively, we can combine the collinear independent variables into index variables. For example, we could create a common index, such as the average of the respective independent variables.\n\n\n\n8.9.7 Comparing Regression Models\nWith the {performance} package, we can also perform a comprehensive model comparison:\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\ncompare_performance(m1, m4, metrics = c(\"R2\", \"R2_adj\"))\n\nWhen comparing models, please note that probably not all models were fit\n  from same data.\n\n\n# Comparison of Model Performance Indices\n\nName | Model |    R2 | R2 (adj.)\n--------------------------------\nm1   |    lm | 0.486 |     0.400\nm4   |    lm | 0.700 |     0.400\n\n\n\n\n8.9.8 Individual Coefficient Plots with {broom}\nmodelplot() offers a quick way to create coefficient plots, but I often use {broom}. Using broom::tidy(..., conf.int = TRUE), we get a data.frame with the results of the regression model, which we can then process further in {ggplot2}—if the standard solution from modelplot() doesn’t meet our needs or preferences:\n\nlibrary(broom) ## already loaded as part of the tidyverse\ntidy(m3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      4.5       6.26     0.719   0.512    -12.9      21.9\n2 ed_fctmedium     7.17      8.08     0.887   0.425    -15.3      29.6\n3 ed_fcthigh      -1.5       8.85    -0.170   0.874    -26.1      23.1\n\ntidy(m3, conf.int = TRUE) %&gt;% \n  mutate(term = str_replace(term, \"ed_fct\", \"Education: \")) %&gt;% \n  ggplot(aes(y = term, x = estimate)) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"navy\") +\n  geom_errorbarh(aes(xmin = conf.low, xmax  = conf.high), height = .1) + \n  geom_point(color = \"orange\", shape = 18, size = 7) +\n  theme_minimal(base_size = 16)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "references_translated.html",
    "href": "references_translated.html",
    "title": "Links & Further Reading",
    "section": "",
    "text": "%&gt;% vs. |&gt;\nIn this course, we have used the pipe %&gt;% from {tidyverse} (technically from the {magrittr} package). With the update to R 4.1, a pipe |&gt; was also introduced in base R, and help pages and other resources are slowly but surely replacing %&gt;% with |&gt;. For (almost) all applications we’ve learned, both pipes behave identically. Since older R versions are still installed at the IAB, we have stuck to the ‘old version’. However, there’s nothing wrong with switching to |&gt; after an update—or simply sticking with %&gt;%.\nYou can find more about the differences here between the two pipes. Additionally, this blog post offers a good overview of the pitfalls when switching from %&gt;% to |&gt;.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#anonymfun",
    "href": "references_translated.html#anonymfun",
    "title": "Links & Further Reading",
    "section": "Anonymous Functions: .x vs. \\(x)",
    "text": "Anonymous Functions: .x vs. \\(x)\nWith R 4.1.0, a new ‘anonymous function shorthand’ was introduced in base R, replacing the ‘formula syntax’ notation ~mean(.x) that we learned in Chapter 6. In the new base R, it would be written as \\(x) mean(x).\nFrom the {purrr} release notes for version 1.0.0 (December 2022): We believe that it’s better to use these new base tools because they work everywhere: the base pipe doesn’t require that you load magrittr and the new function shorthand works everywhere, not just in purrr functions. Additionally, being able to specify the argument name for the anonymous function can often lead to clearer code.\nAccordingly, the application in across() would look like this:\n\nsat_small &lt;- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",n_max = 16) %&gt;% \n    select(F1450_04,F1450_05,F1450_06) %&gt;% \n    slice(12:16)\n\n# formula syntax\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"), ~mean(.x)))\n# anonymous function shorthand\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"), \\(x) mean(x) ))\n\nIn this script, I have relied on the previous ‘formula syntax’ notation, as most help pages currently still use this syntax.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#introductions-to-r",
    "href": "references_translated.html#introductions-to-r",
    "title": "Links & Further Reading",
    "section": "Introductions to R",
    "text": "Introductions to R\nA collection of teaching scripts and materials from various contexts for self-learning:\nR for Data Science the standard work for data analysis with {tidyverse} - very intuitive introduction, focus on Data Science.\nProblem-oriented introductions to specific applications “do more with R”.\nTen simple rules for teaching yourself R.\nModern Data Analysis with R: A German-language introduction to {tidyverse}.\nR for the Rest of Us offers many tutorials and free courses, including many YouTube videos.\nStata 2 R is aimed at Stata users who want to switch to R. However, it shows the {data.table} package for data processing instead of {tidyverse}. {data.table} is very fast but has a somewhat more cumbersome syntax compared to {tidyverse}. For those working with very large datasets, it’s worth trying out {data.table}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#rmarkdown",
    "href": "references_translated.html#rmarkdown",
    "title": "Links & Further Reading",
    "section": "RMarkdown",
    "text": "RMarkdown\n{rmarkdown} allows you to combine formatted text elements with Markdown and R code or output. Unlike an R script, an RMarkdown document contains not only commands but also text that can be formatted using Markdown commands. This way, graphics, tables, etc., can be created directly alongside the accompanying text. With R Markdown, we can create HTML, PDF, Word documents, PowerPoint and HTML presentations, websites, and books. This entire website was created with {R Markdown} or the related package {Quarto}.\nThe help pages and documentation for R Markdown are extensive, and the tutorials and cheatsheets are excellent. Therefore, here’s just a brief overview.\n\nMarkdown Syntax\nAn RMarkdown document in its basic form looks something like this:\n---\ntitle: \"My First RMarkdown Document\"\nauthor: \"My Name\"\ndate: \"2022-09-11\"\noutput: pdf_document\n---\n  \n# Heading 1\n\n## Subheading 2\n\nThis is an R Markdown document. \nMarkdown is a simple syntax for creating HTML, PDF, and MS Word documents. \nText can be **bold** and *italic*. \n\nWhen we click the **Knit** button, a document is created.\nThat contains both the content and the output of any embedded R code chunks within the document. \nAn R code chunk looks like this:\n\n```{r cars}\n# this is where the R code goes\nsummary(mtcars$qsec)\n```\n\n\n\n\n\n\n\n\n\n\n\nExample\nPaper on a sample dataset, written entirely in R Markdown\nYou can find the source code here.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#cheatsheets",
    "href": "references_translated.html#cheatsheets",
    "title": "Links & Further Reading",
    "section": "Cheatsheets",
    "text": "Cheatsheets\nA collection of cheatsheets for a wide range of applications is available here.\n\nData visualization with {ggplot2}.\nData manipulation with {dplyr}.\nReshaping/creating datasets with {tidyr}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#ggplot2",
    "href": "references_translated.html#ggplot2",
    "title": "Links & Further Reading",
    "section": "{ggplot2}",
    "text": "{ggplot2}\nA significant strength of ggplot2 is the numerous extensions that allow you to\n\nCombine multiple plots with {patchwork}.\nCreate maps with sf, another link.\nUse advanced text formatting with {ggtext}.\nCreate animated graphics with {gganimate} - an introduction or here.\nInsert logos into {ggplot2} with {ggpath}.\n\nAn overview of extension packages for {ggplot2} can be found here.\nAlso, The R Graph Gallery provides an excellent overview of visualization possibilities with syntax examples for {ggplot2}.\n\nTutorial by Cédric Scherer.\nSession on more intuitive graphics by Cara Thompson.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#purrr",
    "href": "references_translated.html#purrr",
    "title": "Links & Further Reading",
    "section": "Advanced use of lapply()/map() with custom functions",
    "text": "Advanced use of lapply()/map() with custom functions\n\nComprehensive introduction to loops with map() and other functions from {purrr} Hendrik van Broekhuizen.\nModel series: Blog by Tim Tiefenbach on elegant possibilities.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#regex",
    "href": "references_translated.html#regex",
    "title": "Links & Further Reading",
    "section": "regex",
    "text": "regex\nFor working with text variables, regular expressions (regex) are a great help. They allow you to search for specific character sequences in text sections, replace them, etc. Joshua C. Fjelstul’s blog is a good starting point. There’s also a helpful cheatsheet for regex in R and the regex package {stringr}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#further-resources",
    "href": "references_translated.html#further-resources",
    "title": "Links & Further Reading",
    "section": "Further Resources",
    "text": "Further Resources\n{easystats} offers a collection of packages that make statistical analysis easier and more unified. However, this unification comes with somewhat limited flexibility—it’s a matter of taste and depends on the application. We have used {performance} and {effectsize} from the easystats universe.\nEvent History Models / Event History Modeling / Survival Analysis.",
    "crumbs": [
      "Links & Further Reading"
    ]
  }
]